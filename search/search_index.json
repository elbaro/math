{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Index Kim Chung Lee Tu Artin Kreyszig Stein","title":"Home"},{"location":"#index","text":"Kim Chung Lee Tu Artin Kreyszig Stein","title":"Index"},{"location":"artin/","text":"Artin Chapters Chapter 1 Chapter 2 Chapter 3","title":"Artin"},{"location":"artin/#artin","text":"","title":"Artin"},{"location":"artin/#chapters","text":"Chapter 1 Chapter 2 Chapter 3","title":"Chapters"},{"location":"artin/ch1/","text":"Chapter 1. Matrices Section 1. The Basic Operations 1.1. skip 1.2. skip 1.3. AB=skip. BA is undefined. 1.4. skip 1.5. lmn+lnp or lmp + mnp, the minimum of two 1.6. (Type 1) with a+b, and (Type 1) with an 1.7. [[1,n,n(n+1)/2],[0,1,n],[0,0,1]] 1.8. skip 1.9. (a) AB=BA (b) skip (A^3 + A^2 B + ABA +...) 1.10. DA scales each row of A by corresponding D's element. AD scales each col of A by corresponding D's element. 1.11. An upper triangle is a combination of (type 1) operations, which adds j-th row to i-th row only when \\(i<j\\) . The product preserves this property. 1.12. skip 1.13. (I+A)(I-A-A^2-..A^(k-1)) = I - A^k = I - 0 = I, hence I+A is invertible. 1.14. skip 1.15. \\(e_{ij}A\\) puts the j-th row of \\(A\\) on the i-th row, and zeros out the rest. \\(Ae_{ij}\\) puts the i-th col of \\(A\\) on the j-th col. \\(e_j^T A e_k\\) is \\(A_{jk}\\) . \\(e_{ii} A e_{jj}\\) extracts \\(A_{ij}\\) and zeros out the rest. \\(e_{ij} A e_{kl}\\) extracts \\(A_{jk}\\) and puts on the element \\((i,l)\\) . Section 2. Row Reduction 2.1. skip 2.2. skip 2.3. skip 2.4. skip 2.5. skip 2.6. 2.7. skip 2.8. \\(det(AB)\\ne 0\\) implies \\(det(A)\\ne 0\\) and \\(det(B)\\ne 0\\) . 2.9. (a) Since any linear combination of two solutions is also a solution, we can generate infinitely many solutions. (b) If a complex number is a solution, its conjugate is also a solution. Therefore their sum, which is real, is also a solution. 2.10. If AX=B has a unique solution for some \\(B\\) , \\(\\det(A)\\ne=0\\) , and \\(X=A^{-1}B\\) , therefore unique solution for all \\(B\\) . Section 3. The Matrix Transpose 3.1. skip 3.2. If \\(AB\\) is symmetric, \\(A\\) 3.3. \u3147 3.4. \u3147 Section 4. Determinants 4.1. skip 4.2. skip 4.3. skip 4.4 \\(\\det(-A)=(-1)^n \\det(A)\\) . 4.6. Section 5. Permutation Matrices 5.5 Section 6. Other Formulas for the Determinant 6.1 6.2 Miscellaneous Problems M.1.","title":"Chapter 1. Matrices"},{"location":"artin/ch1/#chapter-1-matrices","text":"","title":"Chapter 1. Matrices"},{"location":"artin/ch1/#section-1-the-basic-operations","text":"1.1. skip 1.2. skip 1.3. AB=skip. BA is undefined. 1.4. skip 1.5. lmn+lnp or lmp + mnp, the minimum of two 1.6. (Type 1) with a+b, and (Type 1) with an 1.7. [[1,n,n(n+1)/2],[0,1,n],[0,0,1]] 1.8. skip 1.9. (a) AB=BA (b) skip (A^3 + A^2 B + ABA +...) 1.10. DA scales each row of A by corresponding D's element. AD scales each col of A by corresponding D's element. 1.11. An upper triangle is a combination of (type 1) operations, which adds j-th row to i-th row only when \\(i<j\\) . The product preserves this property. 1.12. skip 1.13. (I+A)(I-A-A^2-..A^(k-1)) = I - A^k = I - 0 = I, hence I+A is invertible. 1.14. skip 1.15. \\(e_{ij}A\\) puts the j-th row of \\(A\\) on the i-th row, and zeros out the rest. \\(Ae_{ij}\\) puts the i-th col of \\(A\\) on the j-th col. \\(e_j^T A e_k\\) is \\(A_{jk}\\) . \\(e_{ii} A e_{jj}\\) extracts \\(A_{ij}\\) and zeros out the rest. \\(e_{ij} A e_{kl}\\) extracts \\(A_{jk}\\) and puts on the element \\((i,l)\\) .","title":"Section 1. The Basic Operations"},{"location":"artin/ch1/#section-2-row-reduction","text":"2.1. skip 2.2. skip 2.3. skip 2.4. skip 2.5. skip 2.6. 2.7. skip 2.8. \\(det(AB)\\ne 0\\) implies \\(det(A)\\ne 0\\) and \\(det(B)\\ne 0\\) . 2.9. (a) Since any linear combination of two solutions is also a solution, we can generate infinitely many solutions. (b) If a complex number is a solution, its conjugate is also a solution. Therefore their sum, which is real, is also a solution. 2.10. If AX=B has a unique solution for some \\(B\\) , \\(\\det(A)\\ne=0\\) , and \\(X=A^{-1}B\\) , therefore unique solution for all \\(B\\) .","title":"Section 2. Row Reduction"},{"location":"artin/ch1/#section-3-the-matrix-transpose","text":"3.1. skip 3.2. If \\(AB\\) is symmetric, \\(A\\) 3.3. \u3147 3.4. \u3147","title":"Section 3. The Matrix Transpose"},{"location":"artin/ch1/#section-4-determinants","text":"4.1. skip 4.2. skip 4.3. skip 4.4 \\(\\det(-A)=(-1)^n \\det(A)\\) . 4.6.","title":"Section 4. Determinants"},{"location":"artin/ch1/#section-5-permutation-matrices","text":"5.5","title":"Section 5. Permutation Matrices"},{"location":"artin/ch1/#section-6-other-formulas-for-the-determinant","text":"6.1 6.2","title":"Section 6. Other Formulas for the Determinant"},{"location":"artin/ch1/#miscellaneous-problems","text":"M.1.","title":"Miscellaneous Problems"},{"location":"artin/ch2/","text":"Chapter 2. Groups Checklist Group Group's order Subgroup Relation between left inverse / right inverse Cyclic Group Coset Section 1. Laws of Composition 1.1. \\(ab=a\\) , \\((ab)c=ac=a\\) , \\(a(bc)=ab=a\\) . 1.2. (Note: these properties are not true with non-associative operations.) - \\(la=ar=1, (lar)=l=r, ra=ar=1, a^{-1}=r\\) . - an inverse is unique, if not ( \\(b\\ne c\\) ), \\(ab=1, ac=1, cab=c(ab)=c=(ca)b=b, b=c\\) . - \\((ab)(b^{-1}a^{-1})=aa^{-1}=1, \\therefore (ab)^{-1}=b^{-1}a^{-1}\\) . - A counter-example is Exercise 1.3. 1.3. For right inverse, \\(ss^{-1}(n)=n\\) , \\(s^{-1}(n)=n-1\\) For left inverse, \\(s^{-1}s(n) = s^{-1}(n+1)=n\\) , however \\(s^{-1}(1)\\) is unspecified, hence infinitely many left ivnerses. Section 2. Groups and Subgroups 2.1. skip 2.2. The subset is closed under inverse, contains 1 because 1 is invertible, and if the subset has \\(a, b\\) , \\(ab\\) has the inverse \\(b^{-1}a^{-1}\\) , hence \\(ab\\) is the element of the subset as well. Therefore the subset is a subgroup. 2.3. . (a) \\(y=x^{-1}w^{-1}z\\) (b) \\(x(yz)=(yz)x=1\\) . \\(yxz\\) may be be \\(1\\) , since it is possible \\(xy\\ne yx\\) . 2.4. . (a) yes (b) yes (c) no, \\(H\\) is not closed under inverse. (d) yes (e) no, \\(I\\) is not in \\(H\\) . 2.5. If \\(G\\) has an identity \\(I_1\\) and \\(H\\) has an identity \\(I_2\\) , \\(I_1 I_2 = I_1 = I_2\\) . 2.6. \\(G^\\circle\\) is still assosiative, has the same identity, same inverse. Hence \\(G\\) is a group. Section 3. Subgroups of the Additive Group of Integers 3.1. skip 3.2. \\(a+b=p, gcd(a,b)=gcd(a,p-a)=gcd(a,p)=1\\) because \\(a\\) and \\(p\\) are coprime. 3.3. . (a) \\(gcd(a_1,a_2,..a_n)=gcd(gcd(a_1,..a_{n-1}, a_n)\\) , then a linear combination of linear combinations is a linear combination. (b) if \\(gcd(a_1/d, a_2/d, .. a_n/d) = d'\\) , then \\(d*d'\\) is a linear combination of \\(a_1, .., a_n\\) , and \\(d*d'\\) divides \\(d\\) , so \\(d'=1\\) . Section 4. Cyclic Groups 4.1. \\(a^7=1, a^3b = ba^3, ba^3b^{-1}=a^3\\) , squaring the both sides, \\(ba^6b^{-1}=a^6, ba^{-1}b^{-1}=a^{-1}\\) , then \\(ab=ba\\) . 4.2. . (a) skip (use \\(e^{in/(2\\pi)}\\) ) (b) if \\(n\\) is even, the sum of power is 0 (modular n), thus the product \\(1\\) . if \\(n\\) is odd, all terms except \\(1\\) cancel out, and the product is \\(1\\) . 4.3. \\((ab)^k=1 \\iff a((ba)^k)a^{-1}=1 \\iff (ba)^k=1\\) , hence the order of two are the same. 4.4. Any group with order greater than 1 has a trivial proper subgroup \\({1}\\) and it is the smallest group. Only \\({1}\\) has no proper subgroup. 4.5. If a subgroup is a trivial \\({1}\\) , it is cyclic. Otherwise the subgroup of a group \\(<x>\\) consists of \\(x^k\\) and let \\(m\\) be the smallest positive \\(k\\) . For any element of the subgroup \\(x^l\\) , \\(l=mq+r\\) by the division theorem. Since the subgroup has \\(x^{mq}\\) and \\(x^{mq+r}\\) , it also has \\(x^{-mq}\\) (inverse) and \\(x^r\\) . If \\(r\\) is not \\(0\\) , it contradicts that \\(m\\) is the smallest positive \\(k\\) . Hence \\(r\\) is zero, \\(l\\) is a multiple of \\(m\\) . This proves the subgroup is a cyclic, \\(<x^m>\\) . 4.6. . (a) skip (b) \\(x^k\\) generates a cyclic group \\(<x>\\) of order \\(n\\) if and only if \\(gcd(k,n)=1\\) . The answer is \\(\\phi(n)\\) , which is the euler phi function. 4.7. \\(H\\) is closed under the composition because \\(xx=1, yy=1, (xy)(xy)=1\\) , \\(xy\\) is in \\(H\\) , \\(yx=y^{-1} x^{-1} = (xy)^{-1} = xy\\) is in \\(H\\) , \\(xxy=xy\\) , \\(yxy=x^{-1}=x, xyx=y^{-1}=y, xyy=x\\) . \\(H\\) also has \\(1\\) and all inverses (the inverse of an element is itself). Hence \\(H\\) is a subgroup. It is of order \\(4\\) because \\(x, y, xy\\) are all different. If \\(x=y\\) , \\(xy=1\\) , so the order of \\(xy\\) is \\(1\\) , contradicts. If \\(x=xy\\) , then \\(y\\) is an identity, \\(y=1\\) , the order of \\(y\\) is \\(2\\) , contradicts. Therefore they are all different. 4.8. . (a) (Type 2) can be represented as (Type 1) and (Type 3). Suppose two rows are \\((r1,r2)\\) . Then \\((r1,r2)\\Rightarrow (r1+r2,r2)\\Rightarrow (r1+r2,-r1)\\Rightarrow (r1+r2,r1)\\Rightarrow (r2,r1)\\) . Therefore only (Type1) and (Type3) are enough to generate \\(GL_n(\\R)\\) . (b) Without (Type3) we can make a matrix similar to a row echelon one, except each row's leading non-zero element is not 1. Any product of (Type 1) matrices has the determinant \\(1\\) hence it is in \\(SL_n(\\R)\\) . Any element in \\(SL_n(\\R)\\) has the determinant \\(1\\) , and can be reduced to an upper triangle matrix using only (Type 1). The first \\(n-1\\) diagonal elements also can be reduced to 1 using (Type 1). The last diagonal element is automatically \\(1\\) since the product of diagonal elements is the determinant. Hence it is possible to reduce any element of \\(SL_n(\\R)\\) to \\(I\\) , and taking the inverse of a sequence of (Type 1) operations used, we have a product of (Type 1) which is equal to the element. Therefore (Type 1) operations exactly generates \\(SL_n(\\R)\\) . 4.9. skip 4.10. 4.11. . (a) (b) Section 5. Homomorphisms 5.5 Section 6. Isomorphisms 6.1 6.2 Section 7. Equivalence Relations and Partitions Section 8. Cosets Section 9. Modular Arithmetic Section 10. The Correspondence Theorem Section 11. Product Groups Section 12. Quotient Groups Miscellaneous Problems M.1.","title":"Chapter 2. Groups"},{"location":"artin/ch2/#chapter-2-groups","text":"","title":"Chapter 2. Groups"},{"location":"artin/ch2/#checklist","text":"Group Group's order Subgroup Relation between left inverse / right inverse Cyclic Group Coset","title":"Checklist"},{"location":"artin/ch2/#section-1-laws-of-composition","text":"1.1. \\(ab=a\\) , \\((ab)c=ac=a\\) , \\(a(bc)=ab=a\\) . 1.2. (Note: these properties are not true with non-associative operations.) - \\(la=ar=1, (lar)=l=r, ra=ar=1, a^{-1}=r\\) . - an inverse is unique, if not ( \\(b\\ne c\\) ), \\(ab=1, ac=1, cab=c(ab)=c=(ca)b=b, b=c\\) . - \\((ab)(b^{-1}a^{-1})=aa^{-1}=1, \\therefore (ab)^{-1}=b^{-1}a^{-1}\\) . - A counter-example is Exercise 1.3. 1.3. For right inverse, \\(ss^{-1}(n)=n\\) , \\(s^{-1}(n)=n-1\\) For left inverse, \\(s^{-1}s(n) = s^{-1}(n+1)=n\\) , however \\(s^{-1}(1)\\) is unspecified, hence infinitely many left ivnerses.","title":"Section 1. Laws of Composition"},{"location":"artin/ch2/#section-2-groups-and-subgroups","text":"2.1. skip 2.2. The subset is closed under inverse, contains 1 because 1 is invertible, and if the subset has \\(a, b\\) , \\(ab\\) has the inverse \\(b^{-1}a^{-1}\\) , hence \\(ab\\) is the element of the subset as well. Therefore the subset is a subgroup. 2.3. . (a) \\(y=x^{-1}w^{-1}z\\) (b) \\(x(yz)=(yz)x=1\\) . \\(yxz\\) may be be \\(1\\) , since it is possible \\(xy\\ne yx\\) . 2.4. . (a) yes (b) yes (c) no, \\(H\\) is not closed under inverse. (d) yes (e) no, \\(I\\) is not in \\(H\\) . 2.5. If \\(G\\) has an identity \\(I_1\\) and \\(H\\) has an identity \\(I_2\\) , \\(I_1 I_2 = I_1 = I_2\\) . 2.6. \\(G^\\circle\\) is still assosiative, has the same identity, same inverse. Hence \\(G\\) is a group.","title":"Section 2. Groups and Subgroups"},{"location":"artin/ch2/#section-3-subgroups-of-the-additive-group-of-integers","text":"3.1. skip 3.2. \\(a+b=p, gcd(a,b)=gcd(a,p-a)=gcd(a,p)=1\\) because \\(a\\) and \\(p\\) are coprime. 3.3. . (a) \\(gcd(a_1,a_2,..a_n)=gcd(gcd(a_1,..a_{n-1}, a_n)\\) , then a linear combination of linear combinations is a linear combination. (b) if \\(gcd(a_1/d, a_2/d, .. a_n/d) = d'\\) , then \\(d*d'\\) is a linear combination of \\(a_1, .., a_n\\) , and \\(d*d'\\) divides \\(d\\) , so \\(d'=1\\) .","title":"Section 3. Subgroups of the Additive Group of Integers"},{"location":"artin/ch2/#section-4-cyclic-groups","text":"4.1. \\(a^7=1, a^3b = ba^3, ba^3b^{-1}=a^3\\) , squaring the both sides, \\(ba^6b^{-1}=a^6, ba^{-1}b^{-1}=a^{-1}\\) , then \\(ab=ba\\) . 4.2. . (a) skip (use \\(e^{in/(2\\pi)}\\) ) (b) if \\(n\\) is even, the sum of power is 0 (modular n), thus the product \\(1\\) . if \\(n\\) is odd, all terms except \\(1\\) cancel out, and the product is \\(1\\) . 4.3. \\((ab)^k=1 \\iff a((ba)^k)a^{-1}=1 \\iff (ba)^k=1\\) , hence the order of two are the same. 4.4. Any group with order greater than 1 has a trivial proper subgroup \\({1}\\) and it is the smallest group. Only \\({1}\\) has no proper subgroup. 4.5. If a subgroup is a trivial \\({1}\\) , it is cyclic. Otherwise the subgroup of a group \\(<x>\\) consists of \\(x^k\\) and let \\(m\\) be the smallest positive \\(k\\) . For any element of the subgroup \\(x^l\\) , \\(l=mq+r\\) by the division theorem. Since the subgroup has \\(x^{mq}\\) and \\(x^{mq+r}\\) , it also has \\(x^{-mq}\\) (inverse) and \\(x^r\\) . If \\(r\\) is not \\(0\\) , it contradicts that \\(m\\) is the smallest positive \\(k\\) . Hence \\(r\\) is zero, \\(l\\) is a multiple of \\(m\\) . This proves the subgroup is a cyclic, \\(<x^m>\\) . 4.6. . (a) skip (b) \\(x^k\\) generates a cyclic group \\(<x>\\) of order \\(n\\) if and only if \\(gcd(k,n)=1\\) . The answer is \\(\\phi(n)\\) , which is the euler phi function. 4.7. \\(H\\) is closed under the composition because \\(xx=1, yy=1, (xy)(xy)=1\\) , \\(xy\\) is in \\(H\\) , \\(yx=y^{-1} x^{-1} = (xy)^{-1} = xy\\) is in \\(H\\) , \\(xxy=xy\\) , \\(yxy=x^{-1}=x, xyx=y^{-1}=y, xyy=x\\) . \\(H\\) also has \\(1\\) and all inverses (the inverse of an element is itself). Hence \\(H\\) is a subgroup. It is of order \\(4\\) because \\(x, y, xy\\) are all different. If \\(x=y\\) , \\(xy=1\\) , so the order of \\(xy\\) is \\(1\\) , contradicts. If \\(x=xy\\) , then \\(y\\) is an identity, \\(y=1\\) , the order of \\(y\\) is \\(2\\) , contradicts. Therefore they are all different. 4.8. . (a) (Type 2) can be represented as (Type 1) and (Type 3). Suppose two rows are \\((r1,r2)\\) . Then \\((r1,r2)\\Rightarrow (r1+r2,r2)\\Rightarrow (r1+r2,-r1)\\Rightarrow (r1+r2,r1)\\Rightarrow (r2,r1)\\) . Therefore only (Type1) and (Type3) are enough to generate \\(GL_n(\\R)\\) . (b) Without (Type3) we can make a matrix similar to a row echelon one, except each row's leading non-zero element is not 1. Any product of (Type 1) matrices has the determinant \\(1\\) hence it is in \\(SL_n(\\R)\\) . Any element in \\(SL_n(\\R)\\) has the determinant \\(1\\) , and can be reduced to an upper triangle matrix using only (Type 1). The first \\(n-1\\) diagonal elements also can be reduced to 1 using (Type 1). The last diagonal element is automatically \\(1\\) since the product of diagonal elements is the determinant. Hence it is possible to reduce any element of \\(SL_n(\\R)\\) to \\(I\\) , and taking the inverse of a sequence of (Type 1) operations used, we have a product of (Type 1) which is equal to the element. Therefore (Type 1) operations exactly generates \\(SL_n(\\R)\\) . 4.9. skip 4.10. 4.11. . (a) (b)","title":"Section 4. Cyclic Groups"},{"location":"artin/ch2/#section-5-homomorphisms","text":"5.5","title":"Section 5. Homomorphisms"},{"location":"artin/ch2/#section-6-isomorphisms","text":"6.1 6.2","title":"Section 6. Isomorphisms"},{"location":"artin/ch2/#section-7-equivalence-relations-and-partitions","text":"","title":"Section 7. Equivalence Relations and Partitions"},{"location":"artin/ch2/#section-8-cosets","text":"","title":"Section 8. Cosets"},{"location":"artin/ch2/#section-9-modular-arithmetic","text":"","title":"Section 9. Modular Arithmetic"},{"location":"artin/ch2/#section-10-the-correspondence-theorem","text":"","title":"Section 10. The Correspondence Theorem"},{"location":"artin/ch2/#section-11-product-groups","text":"","title":"Section 11. Product Groups"},{"location":"artin/ch2/#section-12-quotient-groups","text":"","title":"Section 12. Quotient Groups"},{"location":"artin/ch2/#miscellaneous-problems","text":"M.1.","title":"Miscellaneous Problems"},{"location":"artin/ch3/","text":"3. Vector Spaces","title":"3. Vector Spaces"},{"location":"artin/ch3/#3-vector-spaces","text":"","title":"3. Vector Spaces"},{"location":"chung/","text":"Chung Chapters Chapter 1 Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Notes convergence random_generator","title":"Chung"},{"location":"chung/#chung","text":"","title":"Chung"},{"location":"chung/#chapters","text":"Chapter 1 Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9","title":"Chapters"},{"location":"chung/#notes","text":"convergence random_generator","title":"Notes"},{"location":"chung/ch1/","text":"1. Distribution function 1 Monotone functions . The floor function \\(f(x)=[x]\\) is such a function. This function cannot be represented as \\(\\sum_{n=1} b_n\\delta_n(x)\\) because it does not handle the negative domain. A slight modification would be \\(\\sum_{n=1}^\\infty b_n\\delta_n(x) - \\sum_{n=0}^\\infty c_n\\delta_n(-x)\\) with \\(b_n=c_n=1\\) . Since the sum of jump sizes ( \\(f(x+)-f(x-)\\) ) is at most \\(B-A\\) , if there are more than \\((B-A)/\\epsilon\\) jumps whose the size exceeds \\(\\epsilon\\) , then there sum is greater than \\(B-A\\) , contradicts. Hence the first statement is proved. Now for a monotone bounded \\(f\\) , there are a finite number of jumps by what we just proved, hence (iv) is true. To extend this to a general monotone \\(f\\) , consider \\(f_n\\) , a function that restricts \\(f\\) on \\([-n,n]\\) . \\(f_n\\) is bounded, and has countable jumps. Let \\(J_n\\) the jumps of \\(f_n\\) , and \\(J\\) for \\(f\\) . Any discontinuous point of \\(f\\) is a member of \\(J_k\\) for some \\(k\\) , hence \\(\\cup J_n = J\\) . Each \\(J_n\\) is countable, so \\(J\\) is countable. Hence (iv) is true for general monotone functions. . Note: \\(D\\) is dense in \\((-\\infty,\\infty)\\) . Otherwise define \\(f(x)=0\\) on \\([-1,1]\\) . \\(f\\) is continuous, \\(\\tilde f(x)=\\infty\\) for \\(x\\ge 1\\) and \\(\\tilde f(x)=0\\) for \\(x<1\\) . \\(f\\) is continuous and uniformly continuous but \\(\\tilde f\\) is discontinuous at \\(x=1\\) . For continuity: let \\(f\\) be the floor function, then \\(f\\) is continuous on \\(\\R\\setminus\\Z\\) , and \\(\\tilde f\\) is discontinuous at the points of \\(\\Z\\) . For uniformly continuity: suppose \\(f\\) is uniformly continuous on D. For any \\(\\epsilon>0\\) , there exists \\(\\delta>0\\) s.t. \\(|f(t_0)-f(t_1)|<\\epsilon/2\\) for all \\(t_0, t_1\\in D\\) satisfying \\(|t_0-t_1|<\\delta\\) . For \\(x_0, x_1 \\in \\R\\) , \\(x_0<x_1, x_1-x_0<\\delta\\) , there exists \\(t_0 \\in D\\) s.t. \\(t_0>x_0, f(t_0)-\\epsilon/2\\le\\tilde f(x_0)\\le\\tilde f(x_1)\\le f(t_0+\\delta)\\) . The last inequality comes from \\(x_1< x_0+\\delta\\le t_0+\\delta\\) . Since the length of interval \\([f(t_0)-\\epsilon/2, f(t_0+\\delta)]\\) is less than \\(\\epsilon\\) , \\(|\\tilde f(x_0)-\\tilde f(x_1)|<\\epsilon\\) . \\(\\therefore\\) \\(\\tilde f\\) is uniformly continuous. . 2. Distribution functions \\(\\lim F(x+\\epsilon) = F(x+) = F(x)\\) and \\(\\lim F(x-\\epsilon) = F(x-) = F(x)\\) , therefore \\(\\lim F(x+\\epsilon)-F(x-\\epsilon) = F(x+)-F(x-)\\) . If \\(x\\) is not a point of jump, \\(F(x+)-F(x-)=0\\) . If \\(x\\) is a point of jump, \\(F(x+)-F(x-)\\) is the size of the jump. If \\(x\\) is a point of jump, the given sum is at most \\(F(x-)-F(x-\\epsilon)\\) , which converges to 0. If \\(x\\) is not a point of jump, the given sum is at most \\(F(x)-F(x-\\epsilon)\\) , which converges to 0 because \\(F(x)=F(x-)\\) . . . . If \\(x\\) is a point of jump, for any \\(\\epsilon>0\\) , \\(F(x-\\epsilon)\\le F(x-)<F(x+)\\le F(x+\\epsilon)\\) , hence \\(x\\) belongs to the support. Let \\(S\\) the support. If \\(x\\) is an isolated point of \\(x\\) , there exists \\(\\epsilon\\) s.t. \\((x-\\epsilon, x+\\epsilon)\\setminus\\{x\\} \\sub S^C\\) . This means that \\(F\\) is constant on two intervals \\((x-\\epsilon, x)\\) and \\((x, x+\\epsilon)\\) , and the values of two intervals are different. The value for the first interval is \\(f(x-)\\) and one for the latter is \\(f(x+)\\) , hence \\(f(x-)\\ne f(x+)\\) . Therefore \\(x\\) is a point of jump. Note: the definition of support in this problem is from Prob 6. Other definitions inherently implies the closedness. Let \\(S\\) the support of a d.f. \\(f\\) . For \\(x\\in S^C\\) , there exists \\(\\epsilon\\) s.t. \\(F(x+\\epsilon)-F(x-\\epsilon)=0\\) . Since \\(F\\) is monotone, \\(F\\) is constant on a range \\((x-\\epsilon, x+\\epsilon)\\) , and this range is a subset of \\(S^C\\) . Hence \\(x\\) is an interior point of \\(S^C\\) and \\(S^C\\) is open, \\(S\\) is closed. By Prob 6, any isolated point of \\(S\\) is a point of jump, hence if \\(f\\) is continuous d.f., \\(S\\) has no point of jump and no isolated point. Therefore \\(S\\) is perfect. 3. Absolutely continuous and singular distributions Part 1 If \\(F\\) is singular, then \\(F'(x)=0\\) a.e. and \\(F_{ac}=0\\) , hence \\(F=F_s\\) . If \\(F=F_s\\) , then \\(F_{ac}=F-F_s=0\\) , and \\(F_{ac}'=0=F'\\) a.e., \\(F\\) is not zero because \\(F(+\\infty)=1\\) , hence \\(F\\) is singular. If \\(F\\) is absolutely continuous, then \\(F(x)=\\int_{-\\infty}^x F'(t)dt=F_{ac}(x)\\) , hence \\(F=F_ac\\) . If \\(F=F_ac\\) , then \\(F(x')-F(x)=F_{ac}(x')=F_{ac}(x)=\\int_x^{x'} f(t)dt\\) , so by definition \\(F\\) is absolutely continuous. . \\(F(x+\\epsilon)-F(x-\\epsilon)=0\\) for all \\(\\epsilon>0\\) a.e \\(x\\) . This means \\(F'(x)=0\\) a.e. Hence \\(F_{ac}(x)=0\\) for all \\(x\\) . \\(F=F_s\\) and from Prob 1, \\(F\\) is singular. Conversely if \\(F\\) is singular, \\(F_{ac}=0\\) . However \\(F\\) does not need to be zero a.e. An example is \\(F=F_s=F_d\\) where \\(F_d\\) is any discrete d.f. Since \\(f\\le 0\\) a.e and \\(f\\) is continuous, \\(f\\le 0\\) everywhere. By the first fundamental theorem of calculus, \\(F'(x)=f(x)\\) everywhere. Let \\(S\\) the support of \\(F\\) and \\(S_0=\\{t|f(t)=0\\}\\) . We show the second statement and derive the first from it. If \\(x\\in S^C\\) , \\(f(x+\\epsilon)-f(x-\\epsilon)=0\\) for some \\(\\epsilon\\) . \\(F\\) is constant on \\((x-\\epsilon, x+\\epsilon)\\) , \\(f\\) is zero on \\((x-\\epsilon, x+\\epsilon)\\) , \\(x\\) is an interior point of \\(S_0\\) . Conversely, if \\(x\\) is an interior point of \\(S_0\\) , \\(f\\) is zero on \\((x-\\epsilon, x+\\epsilon)\\) for some \\(\\epsilon\\) , and \\(F\\) is constant on this interval, hence \\(x\\in S^C\\) . Therefore \\(S^C\\) is equal to the interior of \\(S_0\\) and the second statement is proved. Since \\(S^C\\) is the interior of \\(S_0\\) , \\(S\\) is automatically the closure of \\(S_0^C\\) , which proves the first statement. . . Part 2 A point \\(x\\) in \\(C\\) is an end-point of one of removed intervals, hence the left points of \\(x\\) and right points of \\(x\\) belong to different intervals. Since the belonged interval determines the value of \\(F\\) , \\(F(x-)\\ne F(x+)\\) and \\(x\\) is in the support of \\(F\\) . Note that the value of \\(f(x)\\) does not matter. A point \\(x\\) not in \\(C\\) belongs to an open interval \\(J_{n,k}\\) , thus it has a neighborhood that has a constant value of \\(F\\) . Hence \\(F(x-)=F(x+)\\) and \\(x\\) is not in the support of \\(F\\) . . . . (a) Let A= \\(\\int_0^1 x dF(x), B=\\int_0^{1/3} x dF(x), C=\\int_{2/3}^1 x dF(x)\\) . \\(\\int_{1/3}^{2/3} x dF(x) = 0\\) because \\(F(x)\\) is constant on this interval. For \\(B\\) , we have \\(A = \\int_0^1 x dF(x) = 2\\int_0^1 x dF(x/3) = 6\\int_0^1 x/3 dF(x/3) = 6B\\) . For \\(C\\) , we have \\(A = \\int_0^1 x dF(x) = 2\\int_0^1 x dF(2/3+x/3) = 6\\int_0^1 x/3 dF(2/3+x/3) = 6(\\int_0^1 (2/3+x/3) dF(2/3+x/3)-2/3)=6C-4\\) . Now putting these into \\(A=B+C\\) , \\(A=A/6+(A/6+2/3)\\) , we get \\(A=1/2\\) . (b) Same as in (a). Let D= \\(\\int_0^1 x^2 dF(x), E=\\int_0^{1/3} x^2 dF(x), F=\\int_{2/3}^1 x^2 dF(x)\\) . \\(\\int_{1/3}^{2/3} x^2 dF(x) = 0\\) because \\(F(x)\\) is constant on this interval. For \\(E\\) , we have \\(D = \\int_0^1 x^2 dF(x) = 2\\int_0^1 x^2 dF(x/3) = 18\\int_0^1 (x/3)^2 dF(x/3) = 18E\\) . For \\(F\\) , we have \\(D = \\int_0^1 x^2 dF(x) = 2\\int_0^1 x^2 dF(2/3+x/3) = 6\\int_0^1 (3(2/3+x/3)^2-(2/3+2/3x)) dF(2/3+x/3) = 18F - 6C\\) . Now putting these into \\(D=D/18+D/18+C/3\\) , \\(D=3/8 * C= 3/8 * 3/4 = 9/32\\) , we get \\(D=9/32\\) . (c) .. . [incomplete] Define a new \\(F_0^{-1}(x)\\) as \\(\\inf F^{-1}(x)\\) . Then \\(F_0^{-1}\\) is single-valued . .","title":"1. Distribution function"},{"location":"chung/ch1/#1-distribution-function","text":"","title":"1. Distribution function"},{"location":"chung/ch1/#1-monotone-functions","text":". The floor function \\(f(x)=[x]\\) is such a function. This function cannot be represented as \\(\\sum_{n=1} b_n\\delta_n(x)\\) because it does not handle the negative domain. A slight modification would be \\(\\sum_{n=1}^\\infty b_n\\delta_n(x) - \\sum_{n=0}^\\infty c_n\\delta_n(-x)\\) with \\(b_n=c_n=1\\) . Since the sum of jump sizes ( \\(f(x+)-f(x-)\\) ) is at most \\(B-A\\) , if there are more than \\((B-A)/\\epsilon\\) jumps whose the size exceeds \\(\\epsilon\\) , then there sum is greater than \\(B-A\\) , contradicts. Hence the first statement is proved. Now for a monotone bounded \\(f\\) , there are a finite number of jumps by what we just proved, hence (iv) is true. To extend this to a general monotone \\(f\\) , consider \\(f_n\\) , a function that restricts \\(f\\) on \\([-n,n]\\) . \\(f_n\\) is bounded, and has countable jumps. Let \\(J_n\\) the jumps of \\(f_n\\) , and \\(J\\) for \\(f\\) . Any discontinuous point of \\(f\\) is a member of \\(J_k\\) for some \\(k\\) , hence \\(\\cup J_n = J\\) . Each \\(J_n\\) is countable, so \\(J\\) is countable. Hence (iv) is true for general monotone functions. . Note: \\(D\\) is dense in \\((-\\infty,\\infty)\\) . Otherwise define \\(f(x)=0\\) on \\([-1,1]\\) . \\(f\\) is continuous, \\(\\tilde f(x)=\\infty\\) for \\(x\\ge 1\\) and \\(\\tilde f(x)=0\\) for \\(x<1\\) . \\(f\\) is continuous and uniformly continuous but \\(\\tilde f\\) is discontinuous at \\(x=1\\) . For continuity: let \\(f\\) be the floor function, then \\(f\\) is continuous on \\(\\R\\setminus\\Z\\) , and \\(\\tilde f\\) is discontinuous at the points of \\(\\Z\\) . For uniformly continuity: suppose \\(f\\) is uniformly continuous on D. For any \\(\\epsilon>0\\) , there exists \\(\\delta>0\\) s.t. \\(|f(t_0)-f(t_1)|<\\epsilon/2\\) for all \\(t_0, t_1\\in D\\) satisfying \\(|t_0-t_1|<\\delta\\) . For \\(x_0, x_1 \\in \\R\\) , \\(x_0<x_1, x_1-x_0<\\delta\\) , there exists \\(t_0 \\in D\\) s.t. \\(t_0>x_0, f(t_0)-\\epsilon/2\\le\\tilde f(x_0)\\le\\tilde f(x_1)\\le f(t_0+\\delta)\\) . The last inequality comes from \\(x_1< x_0+\\delta\\le t_0+\\delta\\) . Since the length of interval \\([f(t_0)-\\epsilon/2, f(t_0+\\delta)]\\) is less than \\(\\epsilon\\) , \\(|\\tilde f(x_0)-\\tilde f(x_1)|<\\epsilon\\) . \\(\\therefore\\) \\(\\tilde f\\) is uniformly continuous. .","title":"1 Monotone functions"},{"location":"chung/ch1/#2-distribution-functions","text":"\\(\\lim F(x+\\epsilon) = F(x+) = F(x)\\) and \\(\\lim F(x-\\epsilon) = F(x-) = F(x)\\) , therefore \\(\\lim F(x+\\epsilon)-F(x-\\epsilon) = F(x+)-F(x-)\\) . If \\(x\\) is not a point of jump, \\(F(x+)-F(x-)=0\\) . If \\(x\\) is a point of jump, \\(F(x+)-F(x-)\\) is the size of the jump. If \\(x\\) is a point of jump, the given sum is at most \\(F(x-)-F(x-\\epsilon)\\) , which converges to 0. If \\(x\\) is not a point of jump, the given sum is at most \\(F(x)-F(x-\\epsilon)\\) , which converges to 0 because \\(F(x)=F(x-)\\) . . . . If \\(x\\) is a point of jump, for any \\(\\epsilon>0\\) , \\(F(x-\\epsilon)\\le F(x-)<F(x+)\\le F(x+\\epsilon)\\) , hence \\(x\\) belongs to the support. Let \\(S\\) the support. If \\(x\\) is an isolated point of \\(x\\) , there exists \\(\\epsilon\\) s.t. \\((x-\\epsilon, x+\\epsilon)\\setminus\\{x\\} \\sub S^C\\) . This means that \\(F\\) is constant on two intervals \\((x-\\epsilon, x)\\) and \\((x, x+\\epsilon)\\) , and the values of two intervals are different. The value for the first interval is \\(f(x-)\\) and one for the latter is \\(f(x+)\\) , hence \\(f(x-)\\ne f(x+)\\) . Therefore \\(x\\) is a point of jump. Note: the definition of support in this problem is from Prob 6. Other definitions inherently implies the closedness. Let \\(S\\) the support of a d.f. \\(f\\) . For \\(x\\in S^C\\) , there exists \\(\\epsilon\\) s.t. \\(F(x+\\epsilon)-F(x-\\epsilon)=0\\) . Since \\(F\\) is monotone, \\(F\\) is constant on a range \\((x-\\epsilon, x+\\epsilon)\\) , and this range is a subset of \\(S^C\\) . Hence \\(x\\) is an interior point of \\(S^C\\) and \\(S^C\\) is open, \\(S\\) is closed. By Prob 6, any isolated point of \\(S\\) is a point of jump, hence if \\(f\\) is continuous d.f., \\(S\\) has no point of jump and no isolated point. Therefore \\(S\\) is perfect.","title":"2. Distribution functions"},{"location":"chung/ch1/#3-absolutely-continuous-and-singular-distributions","text":"","title":"3. Absolutely continuous and singular distributions"},{"location":"chung/ch1/#part-1","text":"If \\(F\\) is singular, then \\(F'(x)=0\\) a.e. and \\(F_{ac}=0\\) , hence \\(F=F_s\\) . If \\(F=F_s\\) , then \\(F_{ac}=F-F_s=0\\) , and \\(F_{ac}'=0=F'\\) a.e., \\(F\\) is not zero because \\(F(+\\infty)=1\\) , hence \\(F\\) is singular. If \\(F\\) is absolutely continuous, then \\(F(x)=\\int_{-\\infty}^x F'(t)dt=F_{ac}(x)\\) , hence \\(F=F_ac\\) . If \\(F=F_ac\\) , then \\(F(x')-F(x)=F_{ac}(x')=F_{ac}(x)=\\int_x^{x'} f(t)dt\\) , so by definition \\(F\\) is absolutely continuous. . \\(F(x+\\epsilon)-F(x-\\epsilon)=0\\) for all \\(\\epsilon>0\\) a.e \\(x\\) . This means \\(F'(x)=0\\) a.e. Hence \\(F_{ac}(x)=0\\) for all \\(x\\) . \\(F=F_s\\) and from Prob 1, \\(F\\) is singular. Conversely if \\(F\\) is singular, \\(F_{ac}=0\\) . However \\(F\\) does not need to be zero a.e. An example is \\(F=F_s=F_d\\) where \\(F_d\\) is any discrete d.f. Since \\(f\\le 0\\) a.e and \\(f\\) is continuous, \\(f\\le 0\\) everywhere. By the first fundamental theorem of calculus, \\(F'(x)=f(x)\\) everywhere. Let \\(S\\) the support of \\(F\\) and \\(S_0=\\{t|f(t)=0\\}\\) . We show the second statement and derive the first from it. If \\(x\\in S^C\\) , \\(f(x+\\epsilon)-f(x-\\epsilon)=0\\) for some \\(\\epsilon\\) . \\(F\\) is constant on \\((x-\\epsilon, x+\\epsilon)\\) , \\(f\\) is zero on \\((x-\\epsilon, x+\\epsilon)\\) , \\(x\\) is an interior point of \\(S_0\\) . Conversely, if \\(x\\) is an interior point of \\(S_0\\) , \\(f\\) is zero on \\((x-\\epsilon, x+\\epsilon)\\) for some \\(\\epsilon\\) , and \\(F\\) is constant on this interval, hence \\(x\\in S^C\\) . Therefore \\(S^C\\) is equal to the interior of \\(S_0\\) and the second statement is proved. Since \\(S^C\\) is the interior of \\(S_0\\) , \\(S\\) is automatically the closure of \\(S_0^C\\) , which proves the first statement. . .","title":"Part 1"},{"location":"chung/ch1/#part-2","text":"A point \\(x\\) in \\(C\\) is an end-point of one of removed intervals, hence the left points of \\(x\\) and right points of \\(x\\) belong to different intervals. Since the belonged interval determines the value of \\(F\\) , \\(F(x-)\\ne F(x+)\\) and \\(x\\) is in the support of \\(F\\) . Note that the value of \\(f(x)\\) does not matter. A point \\(x\\) not in \\(C\\) belongs to an open interval \\(J_{n,k}\\) , thus it has a neighborhood that has a constant value of \\(F\\) . Hence \\(F(x-)=F(x+)\\) and \\(x\\) is not in the support of \\(F\\) . . . . (a) Let A= \\(\\int_0^1 x dF(x), B=\\int_0^{1/3} x dF(x), C=\\int_{2/3}^1 x dF(x)\\) . \\(\\int_{1/3}^{2/3} x dF(x) = 0\\) because \\(F(x)\\) is constant on this interval. For \\(B\\) , we have \\(A = \\int_0^1 x dF(x) = 2\\int_0^1 x dF(x/3) = 6\\int_0^1 x/3 dF(x/3) = 6B\\) . For \\(C\\) , we have \\(A = \\int_0^1 x dF(x) = 2\\int_0^1 x dF(2/3+x/3) = 6\\int_0^1 x/3 dF(2/3+x/3) = 6(\\int_0^1 (2/3+x/3) dF(2/3+x/3)-2/3)=6C-4\\) . Now putting these into \\(A=B+C\\) , \\(A=A/6+(A/6+2/3)\\) , we get \\(A=1/2\\) . (b) Same as in (a). Let D= \\(\\int_0^1 x^2 dF(x), E=\\int_0^{1/3} x^2 dF(x), F=\\int_{2/3}^1 x^2 dF(x)\\) . \\(\\int_{1/3}^{2/3} x^2 dF(x) = 0\\) because \\(F(x)\\) is constant on this interval. For \\(E\\) , we have \\(D = \\int_0^1 x^2 dF(x) = 2\\int_0^1 x^2 dF(x/3) = 18\\int_0^1 (x/3)^2 dF(x/3) = 18E\\) . For \\(F\\) , we have \\(D = \\int_0^1 x^2 dF(x) = 2\\int_0^1 x^2 dF(2/3+x/3) = 6\\int_0^1 (3(2/3+x/3)^2-(2/3+2/3x)) dF(2/3+x/3) = 18F - 6C\\) . Now putting these into \\(D=D/18+D/18+C/3\\) , \\(D=3/8 * C= 3/8 * 3/4 = 9/32\\) , we get \\(D=9/32\\) . (c) .. . [incomplete] Define a new \\(F_0^{-1}(x)\\) as \\(\\inf F^{-1}(x)\\) . Then \\(F_0^{-1}\\) is single-valued . .","title":"Part 2"},{"location":"chung/ch2/","text":"2. Measure theory 2.1. Classes of sets 1. (1) \\(x\\in(\\cup A_j)\\setminus(\\cup B_j)\\Longrightarrow \\exists a, x\\in A_a, \\forall b, x\\notin B_b\\Longrightarrow x\\in(A_a\\setminus B_a)\\Longrightarrow x\\in\\cup (A_j\\setminus B_j)\\) . For the converse to be true, \\(B_1=B_2=\\cdots\\) . (2) $x\\in(\\cap A_j)\\setminus(\\cap B_j)\\Longrightarrow\\forall a, x\\in A_a, \\exists b, x\\notin B_b\\Longrightarrow x\\in A_b\\setminus B_b\\Longrightarrow x\\in\\cup(A_j\\setminus B_j)$. For the converse to be true, $A_1=A_2=\\cdots$. ?? ?? . Suppose it is not maximal, \\(\\exists E, \\cap_{\\alpha\\in A}\\mathscr F_\\alpha\\sub E, \\forall \\alpha\\in A, E\\sub \\mathscr F_\\alpha\\) , but \\(E\\sub \\cap_{\\alpha\\in A}\\mathscr F_\\alpha\\) , therefore \\(E=\\cap_{\\alpha\\in A}\\mathscr F_\\alpha\\) , contradicts.","title":"2. Measure theory"},{"location":"chung/ch2/#2-measure-theory","text":"","title":"2. Measure theory"},{"location":"chung/ch2/#21-classes-of-sets","text":"1. (1) \\(x\\in(\\cup A_j)\\setminus(\\cup B_j)\\Longrightarrow \\exists a, x\\in A_a, \\forall b, x\\notin B_b\\Longrightarrow x\\in(A_a\\setminus B_a)\\Longrightarrow x\\in\\cup (A_j\\setminus B_j)\\) . For the converse to be true, \\(B_1=B_2=\\cdots\\) . (2) $x\\in(\\cap A_j)\\setminus(\\cap B_j)\\Longrightarrow\\forall a, x\\in A_a, \\exists b, x\\notin B_b\\Longrightarrow x\\in A_b\\setminus B_b\\Longrightarrow x\\in\\cup(A_j\\setminus B_j)$. For the converse to be true, $A_1=A_2=\\cdots$. ?? ?? . Suppose it is not maximal, \\(\\exists E, \\cap_{\\alpha\\in A}\\mathscr F_\\alpha\\sub E, \\forall \\alpha\\in A, E\\sub \\mathscr F_\\alpha\\) , but \\(E\\sub \\cap_{\\alpha\\in A}\\mathscr F_\\alpha\\) , therefore \\(E=\\cap_{\\alpha\\in A}\\mathscr F_\\alpha\\) , contradicts.","title":"2.1. Classes of sets"},{"location":"chung/ch3/","text":"3. Random Variable. Expectation. Independence 3.1. General Definitions f d Define r.v. X as the identity, so \\(X(B)=B\\) for \\(B\\in\\mathscr B_1\\) . Then \\(\\mu(X^{-1}(B))=\\mu(B)\\) . An identity mapping may be not continuous in some spaces, which means there exists an open set \\(B\\) such that \\(X^{-1}(B)\\) is not open, thus \\(\\mu\\circ X^{-1}\\) is not defined at \\(B\\) . We need to show \\(\\mathscr P\\{G(\\theta)\\le x\\}=F(x)\\) for all \\(x\\in\\R\\) . This is equivalent to \\(\\mathscr P\\{\\sup\\{y;F(y)\\le\\theta(\\omega)\\}\\le x\\}=F(x)\\) for all \\(x\\) . \\(\\sup\\{y;F(y)\\le\\theta\\}\\le x \\iff F(x)\\ge \\theta\\) , and \\(\\mathscr P\\{F(x)\\ge\\theta(\\omega)\\}=P\\{\\theta(\\omega)\\le F(x)\\}=D(F(x))=F(x)\\) where \\(D\\) is a d.f. of uniform distribution on \\([0,1]\\) . Hence it is proved. Let \\(G\\) the d.f. of of \\(F(X)\\) . Then for \\(k\\in[0,1]\\) , \\(G(k)=\\mathscr P\\{F(x)\\le k\\}=\\mathscr P\\{x\\le F^{-1}(k)\\}=F(F^{-1}(k))=k\\) where \\(x\\le F^{-1}(k)\\) means \\(x\\) is equal to or smaller than any element of \\(F^{-1}(\\{k\\})\\) . Hence \\(F(X)\\) has the uniform distribution on \\([0,1]\\) . The continuity is used for \\(F^{-1}(k)\\neq\\varnothing\\) . If \\(F\\) is not continuous, for example \\(F\\) jumps from \\(0.2\\) to \\(0.3\\) at \\(x_0\\) , \\(G(k)\\) is not defined on \\((0.2,0.3)\\) . Clearly this is not uniform distribution. 6.. 7.. 8.. 9.. 10.. ( \\(X\\) is r.v.) Since \\(X\\) is measurable, \\(X^{-1}(B)\\in \\mathscr F\\{X\\}\\) . Conversely, \\(\\mathscr F\\{X\\}\\) is generated by a collection of \\(X^{-1}(B)\\) for \\(B\\in\\mathscr B^1\\) . Any element of \\(\\mathscr F\\{X\\}\\) is made of complement/union/intersection of basis elements, and the inverse is commutative with complement/union/intersection, hence \\(\\Lambda\\in\\mathscr F\\{X\\}\\Longrightarrow \\Lambda=X^ {-1}(B)\\) for some \\(B\\) . \\(B\\) is not unique if \\(x\\) is not surjective. 3.2. Properties of mathematical expectation (46p) From \\(X\\ge 0\\) a.e., there exists a null set \\(N\\) such that \\(X\\ge 0\\) on \\Lambda\\setminus N \\(. Consider a set \\) E_n={X\\ge 1/n} \\(. Then \\) \\mathscr P(E_n)=0 \\( because if not, \\) \\mathscr P(E_n)>0, \\int_\\Lambda Xd\\mathscr P=\\int_{\\Lambda\\setminus N} Xd\\mathscr P\\ge \\int_{E_n} Xd\\mathscr P\\ge \\mathscr P(E_n)*1/n>0 \\(, which contradicts. Let \\) E=\\cup_n E_n={X>0} \\(, then \\) \\mathscr P(E)=0 \\(. Hence \\) X=0 \\( on \\) \\Lambda\\setminus E\\setminus N \\( whose the measure is 1. Therefore \\) X=0$ almost everywhere. (The statement is wrong in a case of direc-delta function?) [WIP] In particular, suppose \\(\\lim_{n\\Longrightarrow\\infty}\\mathscr P(|X|>n)=k>0\\) . Then it is a contradiction that \\(\\int_X Xd\\mathscr P\\ge nk\\) for all \\(n\\) and thus \\(\\int_X Xd\\mathscr P=\\infty\\) . Therefore \\(\\lim_{n\\Longrightarrow\\infty}\\mathscr P(|X|>n)=0\\) . (Or, more easily, use Theorem 3.2.1) Using the first statement in the problem, \\(\\lim_{n\\longrightarrow\\infty}\\int_{|X|>n}Xd\\mathscr P=0\\) . We show three conditions on page 21. (iii) \\(\\nu(\\Omega)=1d\\) , (i) \\(X\\ge 0\\Longrightarrow \\nu(\\Lambda)\\ge 0\\) , (ii) the additivity from the additivity of integral. Therefore \\(\\nu\\) is a p.m. \\(\\sum_{n=1}^\\infty \\mathscr P(|X|\\ge cn)=\\sum_{n=1}^\\infty \\mathscr P(|X|/c\\ge n)<\\infty \\iff \\mathscr E(|X|/c)<infty \\iff \\mathscr E(|X|)<infty\\) . ? Let \\(Z_n=Y-X_n\\) and apply Fatou's lemma on \\(Z_n\\) . Since \\(Y-\\limsup X_n=\\liminf Z_n\\) , we get the desired inequality. Without the condition on \\(Y\\) , it's equivalent to claim Fatou's lemma without non-negativity, which is known false. (TODO: Counterexample) (This problem is equivalent to Folland 2.26) We use the dominated convergence theorem. First let \\(X=X^+-X^-\\) . For \\(X^+\\) , there exists a sequence of simple rv.s \\((\\phi^+_n)\\) that pointwise converges to \\(X^+\\) . \\(|\\phi^+_n-X^+|\\) converges to \\(0\\) . Also \\(|\\phi^+_n-X^+|\\le|\\phi^+_n|+|X^+|\\le 2|X^+|\\) and since \\(|X^+|\\) is integrable, \\(|\\phi^+_n-X^+|\\) is bounded by an integral function. Now we apply the dominated convergence theorem on \\(|\\phi^+_n-X^+|\\) and get \\(\\int |\\phi^+_n-X^+| \\longrightarrow \\int \\lim |\\phi^+_n-X^+| = 0\\) . This means that for any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(\\int |\\phi^+_n-X^+| < \\epsilon/2\\) . We can do the same for \\(X^-\\) , and combining them to get the desired result.d 8. Part 2 9.. Let \\(\\phi(x)=x^{r'/r}\\) . Then \\(\\phi\\) is convex. By Jensen inequality, \\(\\phi(\\int |X|^{r})\\le \\int \\phi(|X|^{r})=\\int |X|^{r'}<\\infty\\) . For the second statement, when \\(p\\ge 1\\) and \\(\\mathscr E(|X|^r)<\\infty\\) , using Minkowski, \\(\\mathscr E(|X-a|^r)^{1/r} < \\mathscr E(|X|^r)^{1/r} + \\mathscr E(|a|^r)^{1/r} < \\infty\\) . For the other direction, \\(\\mathscr E(|X|^r)^{1/r}=\\mathscr E(|X-a+a|^r)^{1/r}<E(|X-a|^r)^{1/r}+E(|a|^r)^{1/r}<\\infty\\) . For \\(0<p<1\\) , \\(|X-a|^r\\le |(|X|+|a|)|^r\\le |X|^r+|a|^r\\) since \\(f(x)=x^r\\) is concave and the subadditivity holds. Similarily, \\(|X|^r=|X-a+a|^r\\le |X-a|^r+|a|^r\\) . Applying integrals on both sides, this proves the second statement.d 11.. 12.. 13.. 14.. 15.. \\(\\int_{-\\infty}^{\\infty}[F(x+a)-F(x)]dx=\\int_{-\\infty}^{\\infty}\\int_{x}^{x+a} f(t) dt dx=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} f(t) \\chi_E(x,t) dt dx\\) where \\(E=\\{x\\le t\\le x+a\\}\\) . By Fubini, This is equal to \\(\\int\\int f(t)\\chi_E(x,t)dxdt = \\int f(t) \\int \\chi_E(x,t) dxdt = \\int f(t)*a \\,dt=a\\int_{-\\infty}^\\infty f(t)dt = a*1 = a\\) . \\(\\int_0^\\infty (1-F(x)) dx=\\int_0^\\infty \\mathscr P(X>x)dx=\\int_0^\\infty \\int_x^\\infty \\mathscr f(t) \\,dt \\,dx\\) . By Tonelli, this is \\(=\\int_0^\\infty \\int_0^t \\mathscr f(t) \\,dx \\,dt=\\int_0^\\infty t*f(t)\\,dt=\\mathscr E(X)\\) . Since \\(\\mathscr P(X=x)=0\\) , \\(\\mathscr P(X>x)=\\mathscr P(X\\ge x)\\) . 18.. 19. ??? 20.. 3.3. Independence [WIP] Let \\(\\mathscr F=\\{\\varnothing,\\{a\\},\\{b\\},\\{a,b\\}\\}, \\mathscr P_1(\\{a\\})=0.5, \\mathscr P_1(\\{b\\})=0.5, \\mathscr P_1(\\{a,b\\})=1, X_1(a)=1, X_1(b)=2, X_2(a)=1, X_2(b)=1\\) . Then \\(\\mathscr P(X_1=1)=0.5, P(X_2=1)=1\\) \b It can be easily checked that they are pairwise independent. They are not totally independent because \\(P(X_1X_2=1,X_1=1,X_2=1)=1/4\\neq P(X_1=1)P(X_1=1)P(X_1X_2=1)=1/8\\) . \\(\\mathscr F=\\{X_1,X_2,\\dots,X_{n-1},X_1X_2X_3\\dots X_{n-1}\\}\\) is an example that every \\(n-1\\) of them are independent but not all of them. Let \\(\\Lambda_1=\\{b,c\\},\\Lambda_2=\\{a,b\\},\\Lambda_3=\\{c,d\\}, P(b)=1/4=P(ab)P(bc)=1/2*1/2\\) and \\(P(c)=1/4=P(bc)P(cd)=1/2*1/2\\) . Then \\(\\Lambda_1\\) and \\(\\Lambda_2\\cup\\Lambda_3=\\{a,b,c,d\\}\\) are not independent. 3.. 4.. 5.. 6.. 7.. 8.. \\(\\int_{Y\\in B}Xd\\mathscr P=\\int X\\Delta_B(Y)d\\mathscr P=\\mathscr E(X\\Delta_B(Y))=\\mathscr E(X) \\mathscr E(\\Delta_B(Y))=\\mathscr E(X) \\mathscr P(Y\\in B)\\) . \\(X\\) and \\(\\Delta_B(Y)\\) are independent because the identity is measurable and an indicator of a borel set is measurable, so by Theorem 3.3.1 they are independent. Let any possible value of \\(Y\\) be \\(y\\) . By Fubini, \\(\\mathscr E(|X+y|^p)<\\infty\\) . There exists a constant \\(c\\in(0,\\infty)\\) such that \\(|a+b|^p\\le c(|a|^p+|b|^p)\\) for all \\(a, b\\) . Then \\(\\mathscr E(|X|^p)=E(|X+y-y|^p)\\le \\mathscr E((|X+y|+|y|)^p)\\le\\mathscr E(c(|X+y|^p+|y|^p))=\\mathscr cE(|X+y|^p)+|y|^p<\\infty\\) . The similar proof for \\(\\mathscr E(Y)\\) holds. link 11.. 12.. 13.. 14.. 15.. 16.. 17.. 18.. 19.. 20..","title":"3. Random Variable. Expectation. Independence"},{"location":"chung/ch3/#3-random-variable-expectation-independence","text":"","title":"3. Random Variable. Expectation. Independence"},{"location":"chung/ch3/#31-general-definitions","text":"f d Define r.v. X as the identity, so \\(X(B)=B\\) for \\(B\\in\\mathscr B_1\\) . Then \\(\\mu(X^{-1}(B))=\\mu(B)\\) . An identity mapping may be not continuous in some spaces, which means there exists an open set \\(B\\) such that \\(X^{-1}(B)\\) is not open, thus \\(\\mu\\circ X^{-1}\\) is not defined at \\(B\\) . We need to show \\(\\mathscr P\\{G(\\theta)\\le x\\}=F(x)\\) for all \\(x\\in\\R\\) . This is equivalent to \\(\\mathscr P\\{\\sup\\{y;F(y)\\le\\theta(\\omega)\\}\\le x\\}=F(x)\\) for all \\(x\\) . \\(\\sup\\{y;F(y)\\le\\theta\\}\\le x \\iff F(x)\\ge \\theta\\) , and \\(\\mathscr P\\{F(x)\\ge\\theta(\\omega)\\}=P\\{\\theta(\\omega)\\le F(x)\\}=D(F(x))=F(x)\\) where \\(D\\) is a d.f. of uniform distribution on \\([0,1]\\) . Hence it is proved. Let \\(G\\) the d.f. of of \\(F(X)\\) . Then for \\(k\\in[0,1]\\) , \\(G(k)=\\mathscr P\\{F(x)\\le k\\}=\\mathscr P\\{x\\le F^{-1}(k)\\}=F(F^{-1}(k))=k\\) where \\(x\\le F^{-1}(k)\\) means \\(x\\) is equal to or smaller than any element of \\(F^{-1}(\\{k\\})\\) . Hence \\(F(X)\\) has the uniform distribution on \\([0,1]\\) . The continuity is used for \\(F^{-1}(k)\\neq\\varnothing\\) . If \\(F\\) is not continuous, for example \\(F\\) jumps from \\(0.2\\) to \\(0.3\\) at \\(x_0\\) , \\(G(k)\\) is not defined on \\((0.2,0.3)\\) . Clearly this is not uniform distribution. 6.. 7.. 8.. 9.. 10.. ( \\(X\\) is r.v.) Since \\(X\\) is measurable, \\(X^{-1}(B)\\in \\mathscr F\\{X\\}\\) . Conversely, \\(\\mathscr F\\{X\\}\\) is generated by a collection of \\(X^{-1}(B)\\) for \\(B\\in\\mathscr B^1\\) . Any element of \\(\\mathscr F\\{X\\}\\) is made of complement/union/intersection of basis elements, and the inverse is commutative with complement/union/intersection, hence \\(\\Lambda\\in\\mathscr F\\{X\\}\\Longrightarrow \\Lambda=X^ {-1}(B)\\) for some \\(B\\) . \\(B\\) is not unique if \\(x\\) is not surjective.","title":"3.1. General Definitions"},{"location":"chung/ch3/#32-properties-of-mathematical-expectation","text":"(46p) From \\(X\\ge 0\\) a.e., there exists a null set \\(N\\) such that \\(X\\ge 0\\) on \\Lambda\\setminus N \\(. Consider a set \\) E_n={X\\ge 1/n} \\(. Then \\) \\mathscr P(E_n)=0 \\( because if not, \\) \\mathscr P(E_n)>0, \\int_\\Lambda Xd\\mathscr P=\\int_{\\Lambda\\setminus N} Xd\\mathscr P\\ge \\int_{E_n} Xd\\mathscr P\\ge \\mathscr P(E_n)*1/n>0 \\(, which contradicts. Let \\) E=\\cup_n E_n={X>0} \\(, then \\) \\mathscr P(E)=0 \\(. Hence \\) X=0 \\( on \\) \\Lambda\\setminus E\\setminus N \\( whose the measure is 1. Therefore \\) X=0$ almost everywhere. (The statement is wrong in a case of direc-delta function?) [WIP] In particular, suppose \\(\\lim_{n\\Longrightarrow\\infty}\\mathscr P(|X|>n)=k>0\\) . Then it is a contradiction that \\(\\int_X Xd\\mathscr P\\ge nk\\) for all \\(n\\) and thus \\(\\int_X Xd\\mathscr P=\\infty\\) . Therefore \\(\\lim_{n\\Longrightarrow\\infty}\\mathscr P(|X|>n)=0\\) . (Or, more easily, use Theorem 3.2.1) Using the first statement in the problem, \\(\\lim_{n\\longrightarrow\\infty}\\int_{|X|>n}Xd\\mathscr P=0\\) . We show three conditions on page 21. (iii) \\(\\nu(\\Omega)=1d\\) , (i) \\(X\\ge 0\\Longrightarrow \\nu(\\Lambda)\\ge 0\\) , (ii) the additivity from the additivity of integral. Therefore \\(\\nu\\) is a p.m. \\(\\sum_{n=1}^\\infty \\mathscr P(|X|\\ge cn)=\\sum_{n=1}^\\infty \\mathscr P(|X|/c\\ge n)<\\infty \\iff \\mathscr E(|X|/c)<infty \\iff \\mathscr E(|X|)<infty\\) . ? Let \\(Z_n=Y-X_n\\) and apply Fatou's lemma on \\(Z_n\\) . Since \\(Y-\\limsup X_n=\\liminf Z_n\\) , we get the desired inequality. Without the condition on \\(Y\\) , it's equivalent to claim Fatou's lemma without non-negativity, which is known false. (TODO: Counterexample) (This problem is equivalent to Folland 2.26) We use the dominated convergence theorem. First let \\(X=X^+-X^-\\) . For \\(X^+\\) , there exists a sequence of simple rv.s \\((\\phi^+_n)\\) that pointwise converges to \\(X^+\\) . \\(|\\phi^+_n-X^+|\\) converges to \\(0\\) . Also \\(|\\phi^+_n-X^+|\\le|\\phi^+_n|+|X^+|\\le 2|X^+|\\) and since \\(|X^+|\\) is integrable, \\(|\\phi^+_n-X^+|\\) is bounded by an integral function. Now we apply the dominated convergence theorem on \\(|\\phi^+_n-X^+|\\) and get \\(\\int |\\phi^+_n-X^+| \\longrightarrow \\int \\lim |\\phi^+_n-X^+| = 0\\) . This means that for any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(\\int |\\phi^+_n-X^+| < \\epsilon/2\\) . We can do the same for \\(X^-\\) , and combining them to get the desired result.d 8.","title":"3.2. Properties of mathematical expectation"},{"location":"chung/ch3/#part-2","text":"9.. Let \\(\\phi(x)=x^{r'/r}\\) . Then \\(\\phi\\) is convex. By Jensen inequality, \\(\\phi(\\int |X|^{r})\\le \\int \\phi(|X|^{r})=\\int |X|^{r'}<\\infty\\) . For the second statement, when \\(p\\ge 1\\) and \\(\\mathscr E(|X|^r)<\\infty\\) , using Minkowski, \\(\\mathscr E(|X-a|^r)^{1/r} < \\mathscr E(|X|^r)^{1/r} + \\mathscr E(|a|^r)^{1/r} < \\infty\\) . For the other direction, \\(\\mathscr E(|X|^r)^{1/r}=\\mathscr E(|X-a+a|^r)^{1/r}<E(|X-a|^r)^{1/r}+E(|a|^r)^{1/r}<\\infty\\) . For \\(0<p<1\\) , \\(|X-a|^r\\le |(|X|+|a|)|^r\\le |X|^r+|a|^r\\) since \\(f(x)=x^r\\) is concave and the subadditivity holds. Similarily, \\(|X|^r=|X-a+a|^r\\le |X-a|^r+|a|^r\\) . Applying integrals on both sides, this proves the second statement.d 11.. 12.. 13.. 14.. 15.. \\(\\int_{-\\infty}^{\\infty}[F(x+a)-F(x)]dx=\\int_{-\\infty}^{\\infty}\\int_{x}^{x+a} f(t) dt dx=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} f(t) \\chi_E(x,t) dt dx\\) where \\(E=\\{x\\le t\\le x+a\\}\\) . By Fubini, This is equal to \\(\\int\\int f(t)\\chi_E(x,t)dxdt = \\int f(t) \\int \\chi_E(x,t) dxdt = \\int f(t)*a \\,dt=a\\int_{-\\infty}^\\infty f(t)dt = a*1 = a\\) . \\(\\int_0^\\infty (1-F(x)) dx=\\int_0^\\infty \\mathscr P(X>x)dx=\\int_0^\\infty \\int_x^\\infty \\mathscr f(t) \\,dt \\,dx\\) . By Tonelli, this is \\(=\\int_0^\\infty \\int_0^t \\mathscr f(t) \\,dx \\,dt=\\int_0^\\infty t*f(t)\\,dt=\\mathscr E(X)\\) . Since \\(\\mathscr P(X=x)=0\\) , \\(\\mathscr P(X>x)=\\mathscr P(X\\ge x)\\) . 18.. 19. ??? 20..","title":"Part 2"},{"location":"chung/ch3/#33-independence","text":"[WIP] Let \\(\\mathscr F=\\{\\varnothing,\\{a\\},\\{b\\},\\{a,b\\}\\}, \\mathscr P_1(\\{a\\})=0.5, \\mathscr P_1(\\{b\\})=0.5, \\mathscr P_1(\\{a,b\\})=1, X_1(a)=1, X_1(b)=2, X_2(a)=1, X_2(b)=1\\) . Then \\(\\mathscr P(X_1=1)=0.5, P(X_2=1)=1\\) \b It can be easily checked that they are pairwise independent. They are not totally independent because \\(P(X_1X_2=1,X_1=1,X_2=1)=1/4\\neq P(X_1=1)P(X_1=1)P(X_1X_2=1)=1/8\\) . \\(\\mathscr F=\\{X_1,X_2,\\dots,X_{n-1},X_1X_2X_3\\dots X_{n-1}\\}\\) is an example that every \\(n-1\\) of them are independent but not all of them. Let \\(\\Lambda_1=\\{b,c\\},\\Lambda_2=\\{a,b\\},\\Lambda_3=\\{c,d\\}, P(b)=1/4=P(ab)P(bc)=1/2*1/2\\) and \\(P(c)=1/4=P(bc)P(cd)=1/2*1/2\\) . Then \\(\\Lambda_1\\) and \\(\\Lambda_2\\cup\\Lambda_3=\\{a,b,c,d\\}\\) are not independent. 3.. 4.. 5.. 6.. 7.. 8.. \\(\\int_{Y\\in B}Xd\\mathscr P=\\int X\\Delta_B(Y)d\\mathscr P=\\mathscr E(X\\Delta_B(Y))=\\mathscr E(X) \\mathscr E(\\Delta_B(Y))=\\mathscr E(X) \\mathscr P(Y\\in B)\\) . \\(X\\) and \\(\\Delta_B(Y)\\) are independent because the identity is measurable and an indicator of a borel set is measurable, so by Theorem 3.3.1 they are independent. Let any possible value of \\(Y\\) be \\(y\\) . By Fubini, \\(\\mathscr E(|X+y|^p)<\\infty\\) . There exists a constant \\(c\\in(0,\\infty)\\) such that \\(|a+b|^p\\le c(|a|^p+|b|^p)\\) for all \\(a, b\\) . Then \\(\\mathscr E(|X|^p)=E(|X+y-y|^p)\\le \\mathscr E((|X+y|+|y|)^p)\\le\\mathscr E(c(|X+y|^p+|y|^p))=\\mathscr cE(|X+y|^p)+|y|^p<\\infty\\) . The similar proof for \\(\\mathscr E(Y)\\) holds. link 11.. 12.. 13.. 14.. 15.. 16.. 17.. 18.. 19.. 20..","title":"3.3. Independence"},{"location":"chung/ch4/","text":"4. Convergence concepts 4.1. Various modes of convergence 4.2. Almost sure convergence; Borel-Cantelli lemma 1.. 2.. 3.. 4. ??? 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12. ??? (Ref: Kolmogorov's zero-one law) 13.. 14.. 15. From the given condition, \\(\\mathscr P(|X_n|>n \\,\\text{ i.o.})=0\\) . In other words, almost everywhere, for large enough \\(n\\) , \\(|X_n|\\le n\\) . Hence \\(\\limsup \\frac{|X_n|}{n}\\le 1\\) a.e. 16.. 17.. 18.. 19.. 20.. 4.3. Vague convergence 1.. 2.. 3.. 4.. 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12.. 13.. 14.. 15.. 16.. 17.. 18.. 19.. 20.. 4.4. Continuation 1.. 2.. 3.. 4.. 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12.. 13.. 14.. 15.. 16.. 17.. 18.. 19.. 20.. 4.5. Uniform integrability; convergence of moments 1.. 2.. 3.. 4.. 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12.. 13.. 14.. 15.. 16.. 17.. 18.. 19.. 20..","title":"4. Convergence concepts"},{"location":"chung/ch4/#4-convergence-concepts","text":"","title":"4. Convergence concepts"},{"location":"chung/ch4/#41-various-modes-of-convergence","text":"","title":"4.1. Various modes of convergence"},{"location":"chung/ch4/#42-almost-sure-convergence-borel-cantelli-lemma","text":"1.. 2.. 3.. 4. ??? 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12. ??? (Ref: Kolmogorov's zero-one law) 13.. 14.. 15. From the given condition, \\(\\mathscr P(|X_n|>n \\,\\text{ i.o.})=0\\) . In other words, almost everywhere, for large enough \\(n\\) , \\(|X_n|\\le n\\) . Hence \\(\\limsup \\frac{|X_n|}{n}\\le 1\\) a.e. 16.. 17.. 18.. 19.. 20..","title":"4.2. Almost sure convergence; Borel-Cantelli lemma"},{"location":"chung/ch4/#43-vague-convergence","text":"1.. 2.. 3.. 4.. 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12.. 13.. 14.. 15.. 16.. 17.. 18.. 19.. 20..","title":"4.3. Vague convergence"},{"location":"chung/ch4/#44-continuation","text":"1.. 2.. 3.. 4.. 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12.. 13.. 14.. 15.. 16.. 17.. 18.. 19.. 20..","title":"4.4. Continuation"},{"location":"chung/ch4/#45-uniform-integrability-convergence-of-moments","text":"1.. 2.. 3.. 4.. 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12.. 13.. 14.. 15.. 16.. 17.. 18.. 19.. 20..","title":"4.5. Uniform integrability; convergence of moments"},{"location":"chung/ch5/","text":"5. Law of large numbers. Random series 5.1. Simple limit theorems 5.2. Weak law of large numbers 1.. 2.. 3.. 4. Let \\(\\{X_n\\}\\) independent r.v.'s Bernoulli with a probability \\(p\\) . Then the summand is \\(\\mathscr P(S_n=k)\\) and the given statement becomes \\(\\lim_n \\mathscr P(|S_n-n\\delta|> np)=0\\) . By Theorem 5.2.2, \\(S_n/n\\longrightarrow p\\) in pr. This means \\(\\mathscr P(|S_n/n-p|> \\epsilon)\\longrightarrow 0\\) for any \\(\\epsilon\\) . Substituting \\(\\epsilon=p\\) we prove the assertion. 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12.. 13.. 14.. 5.3. Convergence of series 5.4. Strong law of large numbers 5.5. Applications","title":"5. Law of large numbers. Random series"},{"location":"chung/ch5/#5-law-of-large-numbers-random-series","text":"","title":"5. Law of large numbers. Random series"},{"location":"chung/ch5/#51-simple-limit-theorems","text":"","title":"5.1. Simple limit theorems"},{"location":"chung/ch5/#52-weak-law-of-large-numbers","text":"1.. 2.. 3.. 4. Let \\(\\{X_n\\}\\) independent r.v.'s Bernoulli with a probability \\(p\\) . Then the summand is \\(\\mathscr P(S_n=k)\\) and the given statement becomes \\(\\lim_n \\mathscr P(|S_n-n\\delta|> np)=0\\) . By Theorem 5.2.2, \\(S_n/n\\longrightarrow p\\) in pr. This means \\(\\mathscr P(|S_n/n-p|> \\epsilon)\\longrightarrow 0\\) for any \\(\\epsilon\\) . Substituting \\(\\epsilon=p\\) we prove the assertion. 5.. 6.. 7.. 8.. 9.. 10.. 11.. 12.. 13.. 14..","title":"5.2. Weak law of large numbers"},{"location":"chung/ch5/#53-convergence-of-series","text":"","title":"5.3. Convergence of series"},{"location":"chung/ch5/#54-strong-law-of-large-numbers","text":"","title":"5.4. Strong law of large numbers"},{"location":"chung/ch5/#55-applications","text":"","title":"5.5. Applications"},{"location":"chung/ch6/","text":"6. Characteristic function 6.1. General properties; convolutions 6.2. Uniqueness and inversion 6.3. Convergence theorems 6.4. Simple applications 6.5. Representation theorems 6.6. Multidimensional case; Laplace transforms","title":"6. Characteristic function"},{"location":"chung/ch6/#6-characteristic-function","text":"","title":"6. Characteristic function"},{"location":"chung/ch6/#61-general-properties-convolutions","text":"","title":"6.1. General properties; convolutions"},{"location":"chung/ch6/#62-uniqueness-and-inversion","text":"","title":"6.2. Uniqueness and inversion"},{"location":"chung/ch6/#63-convergence-theorems","text":"","title":"6.3. Convergence theorems"},{"location":"chung/ch6/#64-simple-applications","text":"","title":"6.4. Simple applications"},{"location":"chung/ch6/#65-representation-theorems","text":"","title":"6.5. Representation theorems"},{"location":"chung/ch6/#66-multidimensional-case-laplace-transforms","text":"","title":"6.6. Multidimensional case; Laplace transforms"},{"location":"chung/ch7/","text":"7. Central limit theorem and its ramifications 7.1. Liapounov's theorem 7.2. Lindeberg-Feller theorem 7.3. Ramifications of the central limit theorem 7.4. Error estimation 7.5. Law of the iterated logarithm 7.6. Infinite divisibility","title":"7. Central limit theorem and its ramifications"},{"location":"chung/ch7/#7-central-limit-theorem-and-its-ramifications","text":"","title":"7. Central limit theorem and its ramifications"},{"location":"chung/ch7/#71-liapounovs-theorem","text":"","title":"7.1. Liapounov's theorem"},{"location":"chung/ch7/#72-lindeberg-feller-theorem","text":"","title":"7.2. Lindeberg-Feller theorem"},{"location":"chung/ch7/#73-ramifications-of-the-central-limit-theorem","text":"","title":"7.3. Ramifications of the central limit theorem"},{"location":"chung/ch7/#74-error-estimation","text":"","title":"7.4. Error estimation"},{"location":"chung/ch7/#75-law-of-the-iterated-logarithm","text":"","title":"7.5. Law of the iterated logarithm"},{"location":"chung/ch7/#76-infinite-divisibility","text":"","title":"7.6. Infinite divisibility"},{"location":"chung/ch8/","text":"8. Random Walk 8.1. Zero-or-one laws 8.2. Basic notions 8.3. Recurrence 8.4. Fine structure 8.5. Continuation","title":"8. Random Walk"},{"location":"chung/ch8/#8-random-walk","text":"","title":"8. Random Walk"},{"location":"chung/ch8/#81-zero-or-one-laws","text":"","title":"8.1. Zero-or-one laws"},{"location":"chung/ch8/#82-basic-notions","text":"","title":"8.2. Basic notions"},{"location":"chung/ch8/#83-recurrence","text":"","title":"8.3. Recurrence"},{"location":"chung/ch8/#84-fine-structure","text":"","title":"8.4. Fine structure"},{"location":"chung/ch8/#85-continuation","text":"","title":"8.5. Continuation"},{"location":"chung/ch9/","text":"9. Conditioning. Markov Property. Martingale 9.1. Basic properties of conditional expectation 9.2. Conditional independence; Markov property 9.3. Basic properties of smartingales 9.4. Inequalities and convergence 9.5. Applications","title":"9. Conditioning. Markov Property. Martingale"},{"location":"chung/ch9/#9-conditioning-markov-property-martingale","text":"","title":"9. Conditioning. Markov Property. Martingale"},{"location":"chung/ch9/#91-basic-properties-of-conditional-expectation","text":"","title":"9.1. Basic properties of conditional expectation"},{"location":"chung/ch9/#92-conditional-independence-markov-property","text":"","title":"9.2. Conditional independence; Markov property"},{"location":"chung/ch9/#93-basic-properties-of-smartingales","text":"","title":"9.3. Basic properties of smartingales"},{"location":"chung/ch9/#94-inequalities-and-convergence","text":"","title":"9.4. Inequalities and convergence"},{"location":"chung/ch9/#95-applications","text":"","title":"9.5. Applications"},{"location":"chung/note.convergence/","text":"Note on convergence \\(F_n, F\\) : cdf \\(X_n, X\\) : random variables Relations For more properties, see Wikipedia . pr. => subseq is a.e. Convergence in dist. \\(\\forall x, F_n(x)\\longrightarrow F(x)\\) = converge in law = converge weakly = \\(F_n\\xrightarrow d F\\) = \\(F_n\\rightsquigarrow F\\) Convergence in pr. \\(\\lim \\Pr(|X_n-X|>\\epsilon)=0\\) = \\(\\forall \\epsilon>0, \\delta>0, \\exists N, \\forall n>N, \\lim \\Pr(|X_n-X|<\\epsilon)<\\delta\\) = \\(F_n\\xrightarrow p F\\) = \\(\\operatorname{plim}_{n\\longrightarrow\\infty} X_n = X\\) Convergence in \\(L^r (r\\ge 1)\\) \\(\\lim E(|X_n-X|^r)=0 (r\\ge 1)\\) = \\(X_n\\xrightarrow{L^r} X\\) This implies = \\(\\lim E(|X_n|^r)=E(|X|^r)\\) Almost surely convergence (a.s.) \\(\\Pr(\\lim_n X_n = X)=1\\) = almost everywhere (a.e.) = converge strongly = with probability 1 = \\(X_n\\xrightarrow{a.s.} X\\) = \\(X_n\\xrightarrow{a.e.} X\\) \bSure convergence \\(\\forall \\omega, X_n(\\omega)\\longrightarrow X(\\omega)\\) = everywhere = pointwise Vaguely convergence pp.85 \\(a<b \\Longrightarrow \\{\\mu_n((a,b])\\longrightarrow\\mu((a,b])\\}\\) s.p.m. \\(\\mu_n\\) \\(\\xrightarrow[v]{}\\) s.p.m. \\(\\mu\\) 4.3.3. any seq of spm has a convergent subseq 4.3.4. all vaguely convergent subseq of a spm seq have the same limit","title":"Note on convergence"},{"location":"chung/note.convergence/#note-on-convergence","text":"\\(F_n, F\\) : cdf \\(X_n, X\\) : random variables","title":"Note on convergence"},{"location":"chung/note.convergence/#relations","text":"For more properties, see Wikipedia . pr. => subseq is a.e.","title":"Relations"},{"location":"chung/note.convergence/#convergence-in-dist","text":"\\(\\forall x, F_n(x)\\longrightarrow F(x)\\) = converge in law = converge weakly = \\(F_n\\xrightarrow d F\\) = \\(F_n\\rightsquigarrow F\\)","title":"Convergence in dist."},{"location":"chung/note.convergence/#convergence-in-pr","text":"\\(\\lim \\Pr(|X_n-X|>\\epsilon)=0\\) = \\(\\forall \\epsilon>0, \\delta>0, \\exists N, \\forall n>N, \\lim \\Pr(|X_n-X|<\\epsilon)<\\delta\\) = \\(F_n\\xrightarrow p F\\) = \\(\\operatorname{plim}_{n\\longrightarrow\\infty} X_n = X\\)","title":"Convergence in pr."},{"location":"chung/note.convergence/#convergence-in-lr-rge-1","text":"\\(\\lim E(|X_n-X|^r)=0 (r\\ge 1)\\) = \\(X_n\\xrightarrow{L^r} X\\) This implies = \\(\\lim E(|X_n|^r)=E(|X|^r)\\)","title":"Convergence in \\(L^r (r\\ge 1)\\)"},{"location":"chung/note.convergence/#almost-surely-convergence-as","text":"\\(\\Pr(\\lim_n X_n = X)=1\\) = almost everywhere (a.e.) = converge strongly = with probability 1 = \\(X_n\\xrightarrow{a.s.} X\\) = \\(X_n\\xrightarrow{a.e.} X\\)","title":"Almost surely convergence (a.s.)"},{"location":"chung/note.convergence/#sure-convergence","text":"\\(\\forall \\omega, X_n(\\omega)\\longrightarrow X(\\omega)\\) = everywhere = pointwise","title":"\bSure convergence"},{"location":"chung/note.convergence/#vaguely-convergence","text":"pp.85 \\(a<b \\Longrightarrow \\{\\mu_n((a,b])\\longrightarrow\\mu((a,b])\\}\\) s.p.m. \\(\\mu_n\\) \\(\\xrightarrow[v]{}\\) s.p.m. \\(\\mu\\) 4.3.3. any seq of spm has a convergent subseq 4.3.4. all vaguely convergent subseq of a spm seq have the same limit","title":"Vaguely convergence"},{"location":"chung/note.random_generator/","text":"Note on Random Number Generation Given a rnd generator from \\(U[0,1]\\) , From 0, one can generate Logistic distribution \\(L(\\mu, \\sigma)\\) From 0, one can generate \\(Exp(\\sigma)\\) From 0, one can generate \\(N(0,1)\\)","title":"Note on Random Number Generation"},{"location":"chung/note.random_generator/#note-on-random-number-generation","text":"Given a rnd generator from \\(U[0,1]\\) , From 0, one can generate Logistic distribution \\(L(\\mu, \\sigma)\\) From 0, one can generate \\(Exp(\\sigma)\\) From 0, one can generate \\(N(0,1)\\)","title":"Note on Random Number Generation"},{"location":"kim/","text":"Kim Chapters Chapter 1 Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Chapter 10 Chapter 11","title":"Kim"},{"location":"kim/#kim","text":"","title":"Kim"},{"location":"kim/#chapters","text":"Chapter 1 Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Chapter 10 Chapter 11","title":"Chapters"},{"location":"kim/ch1/","text":"Chapter 1. \ud655\ub960\ubd84\ud3ec Notes mgf= \\(M_X(t) = E(e^{tX})\\) , \\(-h<t<h\\) for some \\(h>0\\) (if \\(M_x(t)\\in \\R\\) ) k-th moment = \\(m_k=E(X^k)\\) mgf exists \\(\\Longrightarrow\\) \\(m_k\\) exists \\(\\Longrightarrow\\) \\(m_k=E(X^k)=M^{(k)}(0), M(t)=\\sum_0^\\infty \\frac{E(X^k)}{k!}t^k\\) cgf= \\(C_X(t)=\\log M_X(t)\\) r-th cumulant = \\(c_r=C^{(r)}(0)\\) cgf exists \\(\\Longrightarrow\\) \\(c_r\\) exist? \\(\\Longrightarrow\\) \\(C(t)=\\sum_{r=1}^\\infty \\frac{c_r(X)}{r!}t^r\\) Problems 1.20 - Scailing: \\(C_X(at)=log E(e^{(at)X})=log E(e^{t(aX)})=C_{aX}(t)\\) Hence $c_r(aX)=C_{aX}^{(r)}(0)=a^r C_X^{(r)}(at)=a^r c_r(X)$. Shift: \\(C_{X-a}(t)=log E(e^{t(X-a)})=log E_X(e^{tX}e^{-at})=log E(e^{tX})+ log e^{-at} = C_X(t)-at\\) The last term \\(-at\\) goes away in \\(c_r(X-a)\\) for \\(r\\ge 2\\) . Hence for \\(r\\ge 2, c_r(X-a)=c_r(X)\\) . Combining these two properties, \\(c_r(\\frac{X-\\mu}{\\sigma})=c_r(X-\\mu)/\\sigma^r=c_r(X)/\\sigma^r\\) for \\(r\\ge 2\\) . (TODO: The problem requires \\(r\\ge 3\\) . Is it correct for \\(r=2\\) ?)","title":"Chapter 1. \ud655\ub960\ubd84\ud3ec"},{"location":"kim/ch1/#chapter-1","text":"","title":"Chapter 1. \ud655\ub960\ubd84\ud3ec"},{"location":"kim/ch1/#notes","text":"mgf= \\(M_X(t) = E(e^{tX})\\) , \\(-h<t<h\\) for some \\(h>0\\) (if \\(M_x(t)\\in \\R\\) ) k-th moment = \\(m_k=E(X^k)\\) mgf exists \\(\\Longrightarrow\\) \\(m_k\\) exists \\(\\Longrightarrow\\) \\(m_k=E(X^k)=M^{(k)}(0), M(t)=\\sum_0^\\infty \\frac{E(X^k)}{k!}t^k\\) cgf= \\(C_X(t)=\\log M_X(t)\\) r-th cumulant = \\(c_r=C^{(r)}(0)\\) cgf exists \\(\\Longrightarrow\\) \\(c_r\\) exist? \\(\\Longrightarrow\\) \\(C(t)=\\sum_{r=1}^\\infty \\frac{c_r(X)}{r!}t^r\\)","title":"Notes"},{"location":"kim/ch1/#problems","text":"1.20 - Scailing: \\(C_X(at)=log E(e^{(at)X})=log E(e^{t(aX)})=C_{aX}(t)\\) Hence $c_r(aX)=C_{aX}^{(r)}(0)=a^r C_X^{(r)}(at)=a^r c_r(X)$. Shift: \\(C_{X-a}(t)=log E(e^{t(X-a)})=log E_X(e^{tX}e^{-at})=log E(e^{tX})+ log e^{-at} = C_X(t)-at\\) The last term \\(-at\\) goes away in \\(c_r(X-a)\\) for \\(r\\ge 2\\) . Hence for \\(r\\ge 2, c_r(X-a)=c_r(X)\\) . Combining these two properties, \\(c_r(\\frac{X-\\mu}{\\sigma})=c_r(X-\\mu)/\\sigma^r=c_r(X)/\\sigma^r\\) for \\(r\\ge 2\\) . (TODO: The problem requires \\(r\\ge 3\\) . Is it correct for \\(r=2\\) ?)","title":"Problems"},{"location":"kim/ch10/","text":"10\uc7a5. \ubd84\uc0b0\ubd84\uc11d\uacfc \ud68c\uadc0\ubd84\uc11d 10.2 10.4 10.6 10.8 10.10 10.12","title":"10\uc7a5. \ubd84\uc0b0\ubd84\uc11d\uacfc \ud68c\uadc0\ubd84\uc11d"},{"location":"kim/ch10/#10","text":"10.2 10.4 10.6 10.8 10.10 10.12","title":"10\uc7a5. \ubd84\uc0b0\ubd84\uc11d\uacfc \ud68c\uadc0\ubd84\uc11d"},{"location":"kim/ch11/","text":"11\uc7a5. \ubca0\uc774\uc9c0\uc548 \ucd94\ub860 11.2 11.4 11.6 11.8 11.10 11.12 11.14","title":"11\uc7a5. \ubca0\uc774\uc9c0\uc548 \ucd94\ub860"},{"location":"kim/ch11/#11","text":"11.2 11.4 11.6 11.8 11.10 11.12 11.14","title":"11\uc7a5. \ubca0\uc774\uc9c0\uc548 \ucd94\ub860"},{"location":"kim/ch2/","text":"2\uc7a5. \ub2e4\ucc28\uc6d0 \ud655\ub960\ubcc0\uc218\uc758 \ud655\ub960\ubd84\ud3ec Notes joint moment = \\(M(t_1,t_2)=E(e^{t_1X+t_2Y})\\) joint cumulant = \\(C(t_1,t_2)=\\log M(t_1,t_2)\\) independence => cdf = cdf*cdf pdf = pdf*pdf mgf = mgf*mgf g_1(X) and g_2(Y) are independent E[g_1(X)g_2(Y)] = E[g_1(X)]E[g_2(Y)] Cov(X,Y)=0 pdf=g1(x)g2(y) => independent same for cdf, mgf. - Var(X+Y)=Var(X)+Var(Y)=2Cov(X,Y) Var(matrix X)=E[(X-mean)(X-mean)^T] Cov(matrix X, matrix Y)=E[(X-Xmean)(Y-Ymean)^T] Var(AX+b)=AVar(X)A^T Cov(AX+b,CY+d)=ACov(X,Y)C^T Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z) Cov(X,Y+Z)=Cov(X,Y)+Cov(X,Z) Var(X+Y)=Var(X)+Var(Y)+Cov(X,Y)+Cov(Y,X) For multi-dim cgf, see page. 95 multi-dim independence => Cov(X,Y)=0 Var(X1+..+Xn) = Var(X_1)+..Var(Xn) mgf_{X_1+..}(t)=mgf_{X_1}(t)mgf_{X_2}(t).. - Problems 2.1 (a) \\(P(Y\\le 1/2)=\\int_0^1\\int_x^1 10xy^2 dy dx\\) (b) \\(P(X+Y\\le 1)=\\int_0^1\\int_x^{1-x} 10xy^2 dy dx\\) 2.2 (a) \\(\\int_0^1\\int_x^1 cx^2y dydx=1\\) (b) similar to 2.1 (a) (c) \\(\\int_0^1\\int_x^{\\min(1,2x)} cx^2y dydx=1\\) 2.4 (a) \\(f_1(x)=\\int_x^1 2 dy=2(1-x)\\) (b) \\(f_1(x)=\\int_x^\\infty e^{-y} dy=e^{-x}\\) 2.6 \\(E[X] = \\int_0^\\infty x \\int_x^\\infty xe^{-y} dy dx\\) \\(E[Y] = \\int_0^\\infty y \\int_0^y xe^-y dx dy\\) \\(\\operatorname{Cov}(X,Y) = E[(X-E[X])(Y-E[Y])]\\) 2.8 (a) \\(f_2(y)=\\int_0^y 10xy^2 dx=5y^4\\) (b) \\(f_{1,2}(x,y)/f_2(y)=2x/y^2\\) (c) \\(E(X|Y)=2y/3, Var(X|Y)=E((X-E(X|Y))^2|Y)=\\int_0^y (X-E(X|Y))P(X|Y)dx=\\int_0^y (x-2y/3)(2x/y^2)dx\\) (d) \\(\\operatorname{Var[E(X|Y)]}=\\) , E[\\operatorname{Var}(X|Y)] \\( (e) \\) f_1(x)=\\int_x^1 10xy^2 dy \\(, \\) E[X]=.. \\(, \\) \\operatorname{Var(X)}=E[(X-E[X])^2]=..$ 2.10 (a) Var[E(X|Y)]= , E[Var(X|Y)] (b) d .. 2.12 2.14 2.16","title":"2\uc7a5. \ub2e4\ucc28\uc6d0 \ud655\ub960\ubcc0\uc218\uc758 \ud655\ub960\ubd84\ud3ec"},{"location":"kim/ch2/#2","text":"","title":"2\uc7a5. \ub2e4\ucc28\uc6d0 \ud655\ub960\ubcc0\uc218\uc758 \ud655\ub960\ubd84\ud3ec"},{"location":"kim/ch2/#notes","text":"joint moment = \\(M(t_1,t_2)=E(e^{t_1X+t_2Y})\\) joint cumulant = \\(C(t_1,t_2)=\\log M(t_1,t_2)\\) independence => cdf = cdf*cdf pdf = pdf*pdf mgf = mgf*mgf g_1(X) and g_2(Y) are independent E[g_1(X)g_2(Y)] = E[g_1(X)]E[g_2(Y)] Cov(X,Y)=0 pdf=g1(x)g2(y) => independent same for cdf, mgf.","title":"Notes"},{"location":"kim/ch2/#-varxyvarxvary2covxy","text":"Var(matrix X)=E[(X-mean)(X-mean)^T] Cov(matrix X, matrix Y)=E[(X-Xmean)(Y-Ymean)^T] Var(AX+b)=AVar(X)A^T Cov(AX+b,CY+d)=ACov(X,Y)C^T Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z) Cov(X,Y+Z)=Cov(X,Y)+Cov(X,Z) Var(X+Y)=Var(X)+Var(Y)+Cov(X,Y)+Cov(Y,X) For multi-dim cgf, see page. 95 multi-dim independence => Cov(X,Y)=0 Var(X1+..+Xn) = Var(X_1)+..Var(Xn) mgf_{X_1+..}(t)=mgf_{X_1}(t)mgf_{X_2}(t).. -","title":"- Var(X+Y)=Var(X)+Var(Y)=2Cov(X,Y)"},{"location":"kim/ch2/#problems","text":"2.1 (a) \\(P(Y\\le 1/2)=\\int_0^1\\int_x^1 10xy^2 dy dx\\) (b) \\(P(X+Y\\le 1)=\\int_0^1\\int_x^{1-x} 10xy^2 dy dx\\) 2.2 (a) \\(\\int_0^1\\int_x^1 cx^2y dydx=1\\) (b) similar to 2.1 (a) (c) \\(\\int_0^1\\int_x^{\\min(1,2x)} cx^2y dydx=1\\) 2.4 (a) \\(f_1(x)=\\int_x^1 2 dy=2(1-x)\\) (b) \\(f_1(x)=\\int_x^\\infty e^{-y} dy=e^{-x}\\) 2.6 \\(E[X] = \\int_0^\\infty x \\int_x^\\infty xe^{-y} dy dx\\) \\(E[Y] = \\int_0^\\infty y \\int_0^y xe^-y dx dy\\) \\(\\operatorname{Cov}(X,Y) = E[(X-E[X])(Y-E[Y])]\\) 2.8 (a) \\(f_2(y)=\\int_0^y 10xy^2 dx=5y^4\\) (b) \\(f_{1,2}(x,y)/f_2(y)=2x/y^2\\) (c) \\(E(X|Y)=2y/3, Var(X|Y)=E((X-E(X|Y))^2|Y)=\\int_0^y (X-E(X|Y))P(X|Y)dx=\\int_0^y (x-2y/3)(2x/y^2)dx\\) (d) \\(\\operatorname{Var[E(X|Y)]}=\\) , E[\\operatorname{Var}(X|Y)] \\( (e) \\) f_1(x)=\\int_x^1 10xy^2 dy \\(, \\) E[X]=.. \\(, \\) \\operatorname{Var(X)}=E[(X-E[X])^2]=..$ 2.10 (a) Var[E(X|Y)]= , E[Var(X|Y)] (b) d .. 2.12 2.14 2.16","title":"Problems"},{"location":"kim/ch3/","text":"3\uc7a5. \uc5ec\ub7ec \uac00\uc9c0 \ud655\ub960\ubd84\ud3ec 3.2 Consider \\(n\\) numbered balls. Each ball is colored with prob. \\(p\\) . Event X represents a specific coloring. r.v. Y represents a number of permutations of \\(r\\) colored balls. Then \\(E[Y|C]=X(X-1)..(X-r+1)\\) . Hence \\(E[X(X-1)..(X-r+1)]=E_C[E[Y|C]]=E[Y]=n(n-1)...(n-r+1)p^r\\) . 3.4 ; 3.6 \\(f(x)\\ge f(x-1)\\) gives \\(x\\le (r-1)/p+1\\) . For \\(x\\) to be the maximum, \\(f(x+1)\\le f(x)\\Longrightarrow x+1\\ge (r-1)/p+1\\) . From \\(\\frac{r-1}{p}\\le x \\le \\frac{r-1}{p}+1\\) , we have \\(x=\\operatorname{floor}((r-1)/p)+1\\) . 3.8 \\(Cov(W_1,W_r)=Cov(W_1,W_r-W_{r-1})+Cov(W_1,W_{r-1})=Cov(W_1,W_{r-1})=\\cdots=Cov(W_1,W_1)=Var(W_1)=(1-p)/p^2\\) 3.10 ; 3.12 ; 3.14 ; 3.16 mgf = \\(\\sum_{k=0}^\\infty \\frac{E(X^k)}{k!}t^k=\\sum \\frac{t^{2k}}{2^k k!}\\) pdf = 3.18 ;q b","title":"3\uc7a5. \uc5ec\ub7ec \uac00\uc9c0 \ud655\ub960\ubd84\ud3ec"},{"location":"kim/ch3/#3","text":"3.2 Consider \\(n\\) numbered balls. Each ball is colored with prob. \\(p\\) . Event X represents a specific coloring. r.v. Y represents a number of permutations of \\(r\\) colored balls. Then \\(E[Y|C]=X(X-1)..(X-r+1)\\) . Hence \\(E[X(X-1)..(X-r+1)]=E_C[E[Y|C]]=E[Y]=n(n-1)...(n-r+1)p^r\\) . 3.4 ; 3.6 \\(f(x)\\ge f(x-1)\\) gives \\(x\\le (r-1)/p+1\\) . For \\(x\\) to be the maximum, \\(f(x+1)\\le f(x)\\Longrightarrow x+1\\ge (r-1)/p+1\\) . From \\(\\frac{r-1}{p}\\le x \\le \\frac{r-1}{p}+1\\) , we have \\(x=\\operatorname{floor}((r-1)/p)+1\\) . 3.8 \\(Cov(W_1,W_r)=Cov(W_1,W_r-W_{r-1})+Cov(W_1,W_{r-1})=Cov(W_1,W_{r-1})=\\cdots=Cov(W_1,W_1)=Var(W_1)=(1-p)/p^2\\) 3.10 ; 3.12 ; 3.14 ; 3.16 mgf = \\(\\sum_{k=0}^\\infty \\frac{E(X^k)}{k!}t^k=\\sum \\frac{t^{2k}}{2^k k!}\\) pdf = 3.18 ;q b","title":"3\uc7a5. \uc5ec\ub7ec \uac00\uc9c0 \ud655\ub960\ubd84\ud3ec"},{"location":"kim/ch4/","text":"4\uc7a5. \ud45c\ubcf8\ubd84\ud3ec Problems 4.1 \\(\\operatorname{pdf}_Y(y)=1/\\pi * \\cos^2(x)=1 / ({\\pi(y^2+1)})\\) 4.2 \\(g(y_1,y_2)=f(x_1=y_1,x_2=y_1+y_2)=2e^{-2y_1-y_2} I_{(0<y_1,0<y_2)}\\) \\(g_1(y_1)=2e^{-2y_1}\\) , \\(g_2(y_2)=e^{-y_2}\\) , hence independent. 4.4 \\(g(y_1,y_2,y_3)=f(x_1=y_1,x_2=y_1+y_2,x_3=y_1+y_2+y_3)=6e^{-3y_1-2y_2-y_3} I_{(0<y_1,0<y_2,0<y_3)}\\) \\(g_1(y_1)=3e^{-3y_1}\\) , \\(g_2(y_2)=2e^{-2y_2}\\) , \\(g_3(y_3)=e^{-y_3}\\) , hence independent. 4.6 \\(g(y_1,y_2)=f(y_1y_2,y_2)=2e^{-y_1y_2-y_2} I_{(0<y_1<1,0<y_2)}\\) (a) \\(g_1(y_1)=2e^{-y_1}/y_1\\) (b) \\(g(y_2|y_1)=g(y_1,y_2)/g(y_1)=e^{y_1-y_1y_2-y_2}y_1\\) \\(E(Y_2|Y_1)=\\int_0^\\infty y_2 g(y_2|y_1)dy_2 = ..\\) \\(Var(Y_2|Y_1)=\\int_0^\\infty (y_2-E(Y_2|Y_1))^2 dy\\) =.. 4.8 (a) \\(g(y)=\\sum f(x_i) |dy/dx|^{-1}=1/4 |1/2x| * 2 = 1/(4\\sqrt y)\\) (b) this margin is too narrow to contain the demonstration. 4.10 (a) Let \\(W_i=X_1+\\cdots+X_i\\) . Then \\(X_i \\sim \\operatorname{Gamma}(1,1/\\lambda)\\) and these \\(X_i\\) are independent. Hence \\(f(y_1,\\cdots,y_k)\\) is Dirichlet with \\(c=k!\\) . We get \\(f(y_1,\\cdots,y_k)=k!\\) . (b) Let \\(V_1=X, V_2=Y-X\\) . Then \\(f_{XY}(X,Y)=f_{XY}(V_1,V_1+V_2)=g_V(V_1,V_2) |J|^{-1}=g_V(V_1,V_2)\\) and \\(V_1=W_2/W_5, V_2=(W_4-W_2)/W_5\\) . Since \\(W_2, (W_4-W_2)\\sim \\operatorname{Gamma}(2,1/\\lambda)\\) and \\((W_5-W_4)\\sim \\operatorname{Gamma}(1,1/\\lambda)\\) , this is again Dirichlet with \\(\\alpha_1=\\alpha_2=2,\\alpha_3=1\\) . \\(g_V(V_1,V_2)=5! V_1 V_2=5! X(Y-X)\\) where \\(0<X<Y<1\\) . 4.12 (a) \\(F(x)=x\\) . \\(F_Y(y)=1-(1-y)^n, f_Y(y)=n(1-y)^{n-1}\\) . (b) \\(F_Y(y)=y^n, f_Y(y)=ny^{n-1}\\) . 4.14 Let \\(Y=(U_1,..U_n)\\) and \\(Z=(U_1,U_2/U_1,..U_n/U_{n-1})\\) . Then \\(y_1=z_1, y_2=z_1z_2, y_3=z_1z_2z_3, \\cdots\\) . \\(\\operatorname{pdf}_Z(z) = \\operatorname{pdf}_U(u) |\\frac{\\partial y}{\\partial z}|=n!*1*z_1*z_1z_2*z_1z_2z_3*\\cdots\\) . Marginalize \\(z_1\\) out: \\(\\int_0^1 \\operatorname{pdf}_Z(z)dz_1=n!/(n+1)*z_2^{n-1}z_3^{n-2}\\cdots z_n\\) . Hence \\(f(U_2/U_1,\\cdots,U_n/U_{n-1})=n!/(n+1)*(U_2/U_1)^{n-1}(U_3/U_2)^{n-2}\\cdots (U_n/U_{n-1})=n!/(n+1)*\\frac{U_2U_3\\cdots U_n}{U_1^{n-1}}\\) . 4.16 \\(f(U_1,U_n)=n!/(n-2)!*(U_n-U_1)^{n-2}\\) \\(f(U_n-U_1=\\Delta)=\\int_{U_1=0}^{1-\\Delta} f(u_1,u_1+\\Delta)du_1=\\int_{U_1=0}^{1-\\Delta} n!/(n-2)! \\Delta^{n-2} du_1=n(n-1)(1-\\Delta)\\Delta^{n-2}\\) 4.18 (a) \\(X\\) increases as \\(U\\) increases. \\(U=1-e^{-(X^\\alpha)/\\beta^\\alpha}\\) . Hence \\(g(u)=f(x) |du/dx|^{-1}, f(x)=g(u)|du/dx|=e^{-x^\\alpha/\\beta^\\alpha}(\\alpha/\\beta^\\alpha)x^{\\alpha-1}\\) . (b) \\(F(x)=P(X\\le x)=P(U\\le u)=u=1-e^{-(x^\\alpha)/\\beta^\\alpha}\\) , and \\(f(x)/(1-F(x))=(\\alpha/\\beta^\\alpha)x^{\\alpha-1}\\) . 4.20 \\(X=\\tan((U-1/2)\\pi)\\) The problem asks to prove \\(\\operatorname{pdf}_X(x)=1/(\\pi(1+x^2))\\) for \\(-\\infty<x<\\infty\\) . Replace \\(x=tan \\theta\\) . Then \\(\\operatorname{pdf}_X(x)=\\operatorname{pdf}_\\Theta(\\theta)(dx/d\\theta)^{-1}=\\operatorname{pdf}_U(u)(d\\theta/du)^{-1}(dx/d\\theta)^{-1}=(1/\\pi)(sec^2 \\theta)^{-1}=(1/\\pi)(1+\\tan^2 \\theta)^{-1}=1/(\\pi(1+x^2))\\) . 4.22 Using a polar coordinate, \\(f(x,y)=(1/2\\pi) e^{-0.5r^2}(1+r^2 cos\\theta sin\\theta e^{-0.5r^2+1})=g(r,\\theta) |dr\\theta/dxy|^{-1}=g(r,\\theta)/r\\) \\(\\int_0^\\infty \\int_0^{2\\pi} g(r,\\theta) d\\theta dr=\\int_0^\\infty r e^{-0.5r^2}dr=[-e^{-0.5r^2}]_0^\\infty=1\\) . Hence this is a distribution. \\(f(x)=\\int_{-\\infty}^{+\\infty} \\frac{1}{2\\pi}e^{-\\frac{1}{2}(x^2+y^2)}+\\frac{1}{2\\pi}xye^{-x^2-y^2+1} dy\\) , using \\(\\int_{-\\infty}^\\infty e^{-y^2}dy=\\sqrt \\pi\\) and \\(\\int_{-\\infty}^\\infty ye^{-y^2}dy=0\\) , we have \\(f(x)=\\frac{1}{2\\pi}e^{-0.5x^2} \\sqrt{2\\pi}=\\frac{e^{-0.5x^2}}{\\sqrt{2\\pi}}=N(0,1)\\) . In the same way, \\(f_2(y)=N(0,1)\\) . 4.24 (a) \\(Y_1=(X_1-X_2+X_3,2X_1+X_2-X_3,0)^T=\\begin{bmatrix} 1 & -1 & 1 \\\\ 2 & 1 & -1 \\\\ 0 & 0 & 0 \\end{bmatrix}(AZ+\\mu)=(\\begin{bmatrix} 1 & -1 & 1 \\\\ 2 & 1 & -1 \\\\ 0 & 0 & 0 \\end{bmatrix}A) Z + \\begin{bmatrix} 2 \\\\ 1 \\\\ 0 \\end{bmatrix}\\) The new mean is \\([2,1,0]^T\\) and new variance matrix is \\((MA)(MA)^t=MAA^tM^t=M\\Sigma M^t=\\begin{bmatrix} 5 & 1 & 0 \\\\ 1 & 2 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}\\) . Ditching the last one, the original \\(Y\\) follows \\(N([2,1]^T,\\begin{bmatrix} 5 & 1 \\\\ 1 & 2 \\end{bmatrix})\\) .","title":"4\uc7a5. \ud45c\ubcf8\ubd84\ud3ec"},{"location":"kim/ch4/#4","text":"","title":"4\uc7a5. \ud45c\ubcf8\ubd84\ud3ec"},{"location":"kim/ch4/#problems","text":"4.1 \\(\\operatorname{pdf}_Y(y)=1/\\pi * \\cos^2(x)=1 / ({\\pi(y^2+1)})\\) 4.2 \\(g(y_1,y_2)=f(x_1=y_1,x_2=y_1+y_2)=2e^{-2y_1-y_2} I_{(0<y_1,0<y_2)}\\) \\(g_1(y_1)=2e^{-2y_1}\\) , \\(g_2(y_2)=e^{-y_2}\\) , hence independent. 4.4 \\(g(y_1,y_2,y_3)=f(x_1=y_1,x_2=y_1+y_2,x_3=y_1+y_2+y_3)=6e^{-3y_1-2y_2-y_3} I_{(0<y_1,0<y_2,0<y_3)}\\) \\(g_1(y_1)=3e^{-3y_1}\\) , \\(g_2(y_2)=2e^{-2y_2}\\) , \\(g_3(y_3)=e^{-y_3}\\) , hence independent. 4.6 \\(g(y_1,y_2)=f(y_1y_2,y_2)=2e^{-y_1y_2-y_2} I_{(0<y_1<1,0<y_2)}\\) (a) \\(g_1(y_1)=2e^{-y_1}/y_1\\) (b) \\(g(y_2|y_1)=g(y_1,y_2)/g(y_1)=e^{y_1-y_1y_2-y_2}y_1\\) \\(E(Y_2|Y_1)=\\int_0^\\infty y_2 g(y_2|y_1)dy_2 = ..\\) \\(Var(Y_2|Y_1)=\\int_0^\\infty (y_2-E(Y_2|Y_1))^2 dy\\) =.. 4.8 (a) \\(g(y)=\\sum f(x_i) |dy/dx|^{-1}=1/4 |1/2x| * 2 = 1/(4\\sqrt y)\\) (b) this margin is too narrow to contain the demonstration. 4.10 (a) Let \\(W_i=X_1+\\cdots+X_i\\) . Then \\(X_i \\sim \\operatorname{Gamma}(1,1/\\lambda)\\) and these \\(X_i\\) are independent. Hence \\(f(y_1,\\cdots,y_k)\\) is Dirichlet with \\(c=k!\\) . We get \\(f(y_1,\\cdots,y_k)=k!\\) . (b) Let \\(V_1=X, V_2=Y-X\\) . Then \\(f_{XY}(X,Y)=f_{XY}(V_1,V_1+V_2)=g_V(V_1,V_2) |J|^{-1}=g_V(V_1,V_2)\\) and \\(V_1=W_2/W_5, V_2=(W_4-W_2)/W_5\\) . Since \\(W_2, (W_4-W_2)\\sim \\operatorname{Gamma}(2,1/\\lambda)\\) and \\((W_5-W_4)\\sim \\operatorname{Gamma}(1,1/\\lambda)\\) , this is again Dirichlet with \\(\\alpha_1=\\alpha_2=2,\\alpha_3=1\\) . \\(g_V(V_1,V_2)=5! V_1 V_2=5! X(Y-X)\\) where \\(0<X<Y<1\\) . 4.12 (a) \\(F(x)=x\\) . \\(F_Y(y)=1-(1-y)^n, f_Y(y)=n(1-y)^{n-1}\\) . (b) \\(F_Y(y)=y^n, f_Y(y)=ny^{n-1}\\) . 4.14 Let \\(Y=(U_1,..U_n)\\) and \\(Z=(U_1,U_2/U_1,..U_n/U_{n-1})\\) . Then \\(y_1=z_1, y_2=z_1z_2, y_3=z_1z_2z_3, \\cdots\\) . \\(\\operatorname{pdf}_Z(z) = \\operatorname{pdf}_U(u) |\\frac{\\partial y}{\\partial z}|=n!*1*z_1*z_1z_2*z_1z_2z_3*\\cdots\\) . Marginalize \\(z_1\\) out: \\(\\int_0^1 \\operatorname{pdf}_Z(z)dz_1=n!/(n+1)*z_2^{n-1}z_3^{n-2}\\cdots z_n\\) . Hence \\(f(U_2/U_1,\\cdots,U_n/U_{n-1})=n!/(n+1)*(U_2/U_1)^{n-1}(U_3/U_2)^{n-2}\\cdots (U_n/U_{n-1})=n!/(n+1)*\\frac{U_2U_3\\cdots U_n}{U_1^{n-1}}\\) . 4.16 \\(f(U_1,U_n)=n!/(n-2)!*(U_n-U_1)^{n-2}\\) \\(f(U_n-U_1=\\Delta)=\\int_{U_1=0}^{1-\\Delta} f(u_1,u_1+\\Delta)du_1=\\int_{U_1=0}^{1-\\Delta} n!/(n-2)! \\Delta^{n-2} du_1=n(n-1)(1-\\Delta)\\Delta^{n-2}\\) 4.18 (a) \\(X\\) increases as \\(U\\) increases. \\(U=1-e^{-(X^\\alpha)/\\beta^\\alpha}\\) . Hence \\(g(u)=f(x) |du/dx|^{-1}, f(x)=g(u)|du/dx|=e^{-x^\\alpha/\\beta^\\alpha}(\\alpha/\\beta^\\alpha)x^{\\alpha-1}\\) . (b) \\(F(x)=P(X\\le x)=P(U\\le u)=u=1-e^{-(x^\\alpha)/\\beta^\\alpha}\\) , and \\(f(x)/(1-F(x))=(\\alpha/\\beta^\\alpha)x^{\\alpha-1}\\) . 4.20 \\(X=\\tan((U-1/2)\\pi)\\) The problem asks to prove \\(\\operatorname{pdf}_X(x)=1/(\\pi(1+x^2))\\) for \\(-\\infty<x<\\infty\\) . Replace \\(x=tan \\theta\\) . Then \\(\\operatorname{pdf}_X(x)=\\operatorname{pdf}_\\Theta(\\theta)(dx/d\\theta)^{-1}=\\operatorname{pdf}_U(u)(d\\theta/du)^{-1}(dx/d\\theta)^{-1}=(1/\\pi)(sec^2 \\theta)^{-1}=(1/\\pi)(1+\\tan^2 \\theta)^{-1}=1/(\\pi(1+x^2))\\) . 4.22 Using a polar coordinate, \\(f(x,y)=(1/2\\pi) e^{-0.5r^2}(1+r^2 cos\\theta sin\\theta e^{-0.5r^2+1})=g(r,\\theta) |dr\\theta/dxy|^{-1}=g(r,\\theta)/r\\) \\(\\int_0^\\infty \\int_0^{2\\pi} g(r,\\theta) d\\theta dr=\\int_0^\\infty r e^{-0.5r^2}dr=[-e^{-0.5r^2}]_0^\\infty=1\\) . Hence this is a distribution. \\(f(x)=\\int_{-\\infty}^{+\\infty} \\frac{1}{2\\pi}e^{-\\frac{1}{2}(x^2+y^2)}+\\frac{1}{2\\pi}xye^{-x^2-y^2+1} dy\\) , using \\(\\int_{-\\infty}^\\infty e^{-y^2}dy=\\sqrt \\pi\\) and \\(\\int_{-\\infty}^\\infty ye^{-y^2}dy=0\\) , we have \\(f(x)=\\frac{1}{2\\pi}e^{-0.5x^2} \\sqrt{2\\pi}=\\frac{e^{-0.5x^2}}{\\sqrt{2\\pi}}=N(0,1)\\) . In the same way, \\(f_2(y)=N(0,1)\\) . 4.24 (a) \\(Y_1=(X_1-X_2+X_3,2X_1+X_2-X_3,0)^T=\\begin{bmatrix} 1 & -1 & 1 \\\\ 2 & 1 & -1 \\\\ 0 & 0 & 0 \\end{bmatrix}(AZ+\\mu)=(\\begin{bmatrix} 1 & -1 & 1 \\\\ 2 & 1 & -1 \\\\ 0 & 0 & 0 \\end{bmatrix}A) Z + \\begin{bmatrix} 2 \\\\ 1 \\\\ 0 \\end{bmatrix}\\) The new mean is \\([2,1,0]^T\\) and new variance matrix is \\((MA)(MA)^t=MAA^tM^t=M\\Sigma M^t=\\begin{bmatrix} 5 & 1 & 0 \\\\ 1 & 2 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}\\) . Ditching the last one, the original \\(Y\\) follows \\(N([2,1]^T,\\begin{bmatrix} 5 & 1 \\\\ 1 & 2 \\end{bmatrix})\\) .","title":"Problems"},{"location":"kim/ch5/","text":"5\uc7a5. \ud45c\ubcf8\ubd84\ud3ec\uc758 \uadfc\uc0ac 5.2 \\(Z=(X-25)/5=X/5-5\\sim N(0,1)\\) (a) \\(P(19<X\\le 33)=P(-6/5<Z\\le 8/5)\\) (b) \\(P(19.5<X\\le 33.5)=P(-5.5/<Z\\le 8.5/5)\\) 5.4 \\(P(Y_n\\le x)=P(X_1\\le x)^n=I_x(1,\\alpha)^n=(1-(1-x)^\\alpha)^n\\) \\(P(n^{1/\\alpha}(1-Y_n)\\le x)=P(1-xn^{-1/\\alpha}\\le Y_n)=1-P(Y_n\\le 1-xn^{-1/\\alpha})=1-(1-(1-(1-xn^{-1/\\alpha}))^\\alpha)^n=1-(1-(xn^{-1/\\alpha})^\\alpha)^n=1-(1-(xn^{-1/\\alpha})^\\alpha)^n=1-(1-x^\\alpha n^{-1})^n\\) Using \\((1-x^\\alpha n^{-1})^n=(1-x^\\alpha/n)^{n/x^\\alpha*x^\\alpha}\\Longrightarrow (1/e)^{x^\\alpha}\\) , The last term is \\(1-e^{-x^\\alpha}\\) . If \\(Z\\sim \\exp(1)\\) , then \\(P(Z\\le x^\\alpha)=1-e^{-x^\\alpha}=P(Z^{1/\\alpha}\\le x)\\) . Therefore the given quantity has the same distribution as \\(Z^{1/\\alpha}\\) where \\(Z\\sim \\exp(1)\\) . 5.6 \\(P(Y_n\\le x)=P(X_1\\le x)^n=(1-e^{-x})^n\\) \\(P(Y_n-\\log n\\le x)=P(Y_n\\le x+\\log n)=(1-e^{-x}/n)^{n/e^{-x}*e^{-x}}\\Longrightarrow e^{-x-1}\\) 5.8 (a) \\(\\operatorname{plim} (X_n,Y_n)^t=(\\operatorname{plim} X_n, \\operatorname{plim} Y_n)^t=(0,1)^t\\) (b) \\(\\operatorname{pdf}(X_n\\ge x, Y_n\\le y)=(y-x)^n\\) \\(\\operatorname{pdf}(X_n=x,Y_n=y)=\\frac{\\partial}{\\partial x}\\frac{\\partial}{\\partial y} (y-x)^n = \\frac{\\partial}{\\partial x}n(y-x)^{n-1}=n(n-1)(y-x)^{n-2}\\) \\(\\operatorname{pdf}(R_n=r)=\\int_{x=0}^{1-r} P(x_n=x,y_n=r+x) dx=n(n-1)r^{n-2}(1-r)\\) \\(\\operatorname{pdf}(n(1-R_n)=x)=\\operatorname{pdf}(R_n=1-x/n)=n(n-1)(1-x/n)^{n-2}(x/n)=(n-1)(1-x/n)^{n-2}x\\) 5.10 (a) \\(\\limsup P(|X_n+Y_n|>k) = \\limsup P(|X_n+Y_n|>2k) \\le \\limsup P(|X_n|>k)+\\limsup P(|Y_n|>k)=0\\) (b) \\(\\limsup P(|X_nY_n|>k)\\le\\limsup P(|X_n|>\\sqrt k)+\\limsup P(|Y_n|>\\sqrt k)=0\\) (c) We want to show \\(\\forall \\epsilon>0, \\lim_{n\\longrightarrow \\infty} P(|Z_nX_n|>\\epsilon)=0\\) . For any \\(\\epsilon>0, \\delta>0\\) , there exists \\(K>0\\) such that \\(\\forall k>K, \\sup P(|X_n|>k)<\\delta/2\\) . Also there exists \\(N>0\\) such that \\(\\forall n>N, P(|Z_n|>\\epsilon/K)<\\delta/2\\) . Since \\(\\{ |Z_nX_n|>\\epsilon \\}\\sub \\{ |Z_n|>\\epsilon/k \\}\\cup \\{ |X_n|>k \\}\\) , we have for \\(n>N\\) , \\(P(|Z_nX_n|>\\epsilon)\\le P(|Z_n|>\\epsilon/K)+P(|X_n|>K)\\le P(|Z_n|>\\epsilon/K)+\\sup_i P(|X_i|>K)<\\delta\\) , which proves the statement. (d) \\(\\sup P(|Z_n|>k)\\) is a non-increasing function of \\(k\\) and bounded below by \\(0\\) , hence \\(\\lim \\sup P(|Z_n|>k)\\) exists and is non-negative. Suppose this value is not \\(0\\) , i.e. \\(\\lim_{k\\longrightarrow \\infty} \\sup_n P(|Z_n|>k) = c>0\\) . This implies \\(\\forall k>0, \\sup_n P(|Z_n|>k)\\ge c\\) . Since a supremum is at least \\(c\\) , all \\(P\\) values are at least \\(c/2\\) . Hence \\(\\forall k>0, \\forall n>0, P(|Z_n|>k)\\ge c/2>0\\) . This contradicts to the assumption \\(Z_n=o_P(1)\\) , i.e. \\(\\forall k>0, \\lim_n P(|Z_n|>k)=0\\) . 5.12 By the CLT, \\(\\sqrt n (\\overline X - \\lambda)\\sim N(0,\\lambda)\\) . With \\(g(X_i)=X_i/\\sqrt \\lambda\\) , \\(\\sqrt n (g(\\overline {X_n})-g(\\lambda))\\sim N(0,1)\\) . We can estimate a confidence interval, for example, \\(P(-3\\le \\sqrt n (g(\\overline{X_n})-\\sqrt \\lambda)\\le 3)\\approx 0.9973\\) . 5.14 (a) By the CLT, \\(\\sqrt n \\overline X \\sim N(0,1)\\) . For every \\(\\epsilon>0\\) we have \\(\\lim_{n\\longrightarrow \\infty} P(\\sqrt n \\overline X \\overline Y>\\epsilon)\\le \\lim P(n^{1/4} \\overline X>\\sqrt \\epsilon)+\\lim P(n^{1/4} \\overline Y>\\sqrt \\epsilon)=\\lim P(\\sqrt n \\overline X>n^{1/4} \\sqrt \\epsilon)+\\lim P(\\sqrt n \\overline Y>n^{1/4} \\sqrt \\epsilon)=0+0=0\\) . Hence \\(\\operatorname{plim} \\sqrt n \\overline X \\overline Y = 0\\) . We get the 'therefore' part from canceling \\(\\overline{XY}\\) and multiplying both sides by \\(\\sqrt n\\) . (b) With \\(m_1=\\overline X, m_2=\\overline{X^2}\\) , the statement is \\(\\sqrt{m_2-m_1^2}-\\sqrt{m_2}=-m_1^2/(\\sqrt{m_2-m_1^2}+\\sqrt{m_2})\\) , which can be easily proven by manipulation. [TODO: Prove 'therefore' part] (c) By the CLT, \\(\\sqrt n (\\overline{X^2}-1)/\\sigma_{\\overline{X^2}}\\sim N(0,1)\\) . With \\(g(x)=(\\sqrt x-1)^2\\) , we have \\(\\sqrt n (g(\\overline{X^2})-g(1))/\\sigma_{\\overline{X^2}}\\sim g'(1) N(0,1)\\) , which simplifies to \\(\\sqrt n (\\sqrt{\\overline{X^2}}-1)^2/\\sigma_{\\overline{X^2}}\\sim 0\\) . The condition required for this is \\(\\sigma_{\\overline{X^2}}<\\infty\\) . From the given assumption \\(E[X^4]<\\infty\\) , we have \\(E[\\overline{X^2}^2]<\\infty, \\operatorname{Var}[\\overline{X^2}]=E[\\overline{X^2}^2]-E[\\overline{X^2}]^2<\\infty - 1, \\sigma_{\\overline{X^2}}<\\infty\\) . \\(\\sqrt n r_{3n} = -\\frac{1}{2}\\sqrt n (\\overline{X^2}-2\\sqrt{\\overline{X^2}}+1)=-\\frac{1}{2}\\sqrt n (\\sqrt{\\overline{X^2}}-1)^2\\sim 0\\) . (d) (e) 5.16 [TODO]","title":"5\uc7a5. \ud45c\ubcf8\ubd84\ud3ec\uc758 \uadfc\uc0ac"},{"location":"kim/ch5/#5","text":"5.2 \\(Z=(X-25)/5=X/5-5\\sim N(0,1)\\) (a) \\(P(19<X\\le 33)=P(-6/5<Z\\le 8/5)\\) (b) \\(P(19.5<X\\le 33.5)=P(-5.5/<Z\\le 8.5/5)\\) 5.4 \\(P(Y_n\\le x)=P(X_1\\le x)^n=I_x(1,\\alpha)^n=(1-(1-x)^\\alpha)^n\\) \\(P(n^{1/\\alpha}(1-Y_n)\\le x)=P(1-xn^{-1/\\alpha}\\le Y_n)=1-P(Y_n\\le 1-xn^{-1/\\alpha})=1-(1-(1-(1-xn^{-1/\\alpha}))^\\alpha)^n=1-(1-(xn^{-1/\\alpha})^\\alpha)^n=1-(1-(xn^{-1/\\alpha})^\\alpha)^n=1-(1-x^\\alpha n^{-1})^n\\) Using \\((1-x^\\alpha n^{-1})^n=(1-x^\\alpha/n)^{n/x^\\alpha*x^\\alpha}\\Longrightarrow (1/e)^{x^\\alpha}\\) , The last term is \\(1-e^{-x^\\alpha}\\) . If \\(Z\\sim \\exp(1)\\) , then \\(P(Z\\le x^\\alpha)=1-e^{-x^\\alpha}=P(Z^{1/\\alpha}\\le x)\\) . Therefore the given quantity has the same distribution as \\(Z^{1/\\alpha}\\) where \\(Z\\sim \\exp(1)\\) . 5.6 \\(P(Y_n\\le x)=P(X_1\\le x)^n=(1-e^{-x})^n\\) \\(P(Y_n-\\log n\\le x)=P(Y_n\\le x+\\log n)=(1-e^{-x}/n)^{n/e^{-x}*e^{-x}}\\Longrightarrow e^{-x-1}\\) 5.8 (a) \\(\\operatorname{plim} (X_n,Y_n)^t=(\\operatorname{plim} X_n, \\operatorname{plim} Y_n)^t=(0,1)^t\\) (b) \\(\\operatorname{pdf}(X_n\\ge x, Y_n\\le y)=(y-x)^n\\) \\(\\operatorname{pdf}(X_n=x,Y_n=y)=\\frac{\\partial}{\\partial x}\\frac{\\partial}{\\partial y} (y-x)^n = \\frac{\\partial}{\\partial x}n(y-x)^{n-1}=n(n-1)(y-x)^{n-2}\\) \\(\\operatorname{pdf}(R_n=r)=\\int_{x=0}^{1-r} P(x_n=x,y_n=r+x) dx=n(n-1)r^{n-2}(1-r)\\) \\(\\operatorname{pdf}(n(1-R_n)=x)=\\operatorname{pdf}(R_n=1-x/n)=n(n-1)(1-x/n)^{n-2}(x/n)=(n-1)(1-x/n)^{n-2}x\\) 5.10 (a) \\(\\limsup P(|X_n+Y_n|>k) = \\limsup P(|X_n+Y_n|>2k) \\le \\limsup P(|X_n|>k)+\\limsup P(|Y_n|>k)=0\\) (b) \\(\\limsup P(|X_nY_n|>k)\\le\\limsup P(|X_n|>\\sqrt k)+\\limsup P(|Y_n|>\\sqrt k)=0\\) (c) We want to show \\(\\forall \\epsilon>0, \\lim_{n\\longrightarrow \\infty} P(|Z_nX_n|>\\epsilon)=0\\) . For any \\(\\epsilon>0, \\delta>0\\) , there exists \\(K>0\\) such that \\(\\forall k>K, \\sup P(|X_n|>k)<\\delta/2\\) . Also there exists \\(N>0\\) such that \\(\\forall n>N, P(|Z_n|>\\epsilon/K)<\\delta/2\\) . Since \\(\\{ |Z_nX_n|>\\epsilon \\}\\sub \\{ |Z_n|>\\epsilon/k \\}\\cup \\{ |X_n|>k \\}\\) , we have for \\(n>N\\) , \\(P(|Z_nX_n|>\\epsilon)\\le P(|Z_n|>\\epsilon/K)+P(|X_n|>K)\\le P(|Z_n|>\\epsilon/K)+\\sup_i P(|X_i|>K)<\\delta\\) , which proves the statement. (d) \\(\\sup P(|Z_n|>k)\\) is a non-increasing function of \\(k\\) and bounded below by \\(0\\) , hence \\(\\lim \\sup P(|Z_n|>k)\\) exists and is non-negative. Suppose this value is not \\(0\\) , i.e. \\(\\lim_{k\\longrightarrow \\infty} \\sup_n P(|Z_n|>k) = c>0\\) . This implies \\(\\forall k>0, \\sup_n P(|Z_n|>k)\\ge c\\) . Since a supremum is at least \\(c\\) , all \\(P\\) values are at least \\(c/2\\) . Hence \\(\\forall k>0, \\forall n>0, P(|Z_n|>k)\\ge c/2>0\\) . This contradicts to the assumption \\(Z_n=o_P(1)\\) , i.e. \\(\\forall k>0, \\lim_n P(|Z_n|>k)=0\\) . 5.12 By the CLT, \\(\\sqrt n (\\overline X - \\lambda)\\sim N(0,\\lambda)\\) . With \\(g(X_i)=X_i/\\sqrt \\lambda\\) , \\(\\sqrt n (g(\\overline {X_n})-g(\\lambda))\\sim N(0,1)\\) . We can estimate a confidence interval, for example, \\(P(-3\\le \\sqrt n (g(\\overline{X_n})-\\sqrt \\lambda)\\le 3)\\approx 0.9973\\) . 5.14 (a) By the CLT, \\(\\sqrt n \\overline X \\sim N(0,1)\\) . For every \\(\\epsilon>0\\) we have \\(\\lim_{n\\longrightarrow \\infty} P(\\sqrt n \\overline X \\overline Y>\\epsilon)\\le \\lim P(n^{1/4} \\overline X>\\sqrt \\epsilon)+\\lim P(n^{1/4} \\overline Y>\\sqrt \\epsilon)=\\lim P(\\sqrt n \\overline X>n^{1/4} \\sqrt \\epsilon)+\\lim P(\\sqrt n \\overline Y>n^{1/4} \\sqrt \\epsilon)=0+0=0\\) . Hence \\(\\operatorname{plim} \\sqrt n \\overline X \\overline Y = 0\\) . We get the 'therefore' part from canceling \\(\\overline{XY}\\) and multiplying both sides by \\(\\sqrt n\\) . (b) With \\(m_1=\\overline X, m_2=\\overline{X^2}\\) , the statement is \\(\\sqrt{m_2-m_1^2}-\\sqrt{m_2}=-m_1^2/(\\sqrt{m_2-m_1^2}+\\sqrt{m_2})\\) , which can be easily proven by manipulation. [TODO: Prove 'therefore' part] (c) By the CLT, \\(\\sqrt n (\\overline{X^2}-1)/\\sigma_{\\overline{X^2}}\\sim N(0,1)\\) . With \\(g(x)=(\\sqrt x-1)^2\\) , we have \\(\\sqrt n (g(\\overline{X^2})-g(1))/\\sigma_{\\overline{X^2}}\\sim g'(1) N(0,1)\\) , which simplifies to \\(\\sqrt n (\\sqrt{\\overline{X^2}}-1)^2/\\sigma_{\\overline{X^2}}\\sim 0\\) . The condition required for this is \\(\\sigma_{\\overline{X^2}}<\\infty\\) . From the given assumption \\(E[X^4]<\\infty\\) , we have \\(E[\\overline{X^2}^2]<\\infty, \\operatorname{Var}[\\overline{X^2}]=E[\\overline{X^2}^2]-E[\\overline{X^2}]^2<\\infty - 1, \\sigma_{\\overline{X^2}}<\\infty\\) . \\(\\sqrt n r_{3n} = -\\frac{1}{2}\\sqrt n (\\overline{X^2}-2\\sqrt{\\overline{X^2}}+1)=-\\frac{1}{2}\\sqrt n (\\sqrt{\\overline{X^2}}-1)^2\\sim 0\\) . (d) (e) 5.16 [TODO]","title":"5\uc7a5. \ud45c\ubcf8\ubd84\ud3ec\uc758 \uadfc\uc0ac"},{"location":"kim/ch6/","text":"6\uc7a5. \ucd94\uc815 6.2 6.4 6.6 6.8 6.10 6.12 6.14 6.16 6.18 6.20 6.22","title":"6\uc7a5. \ucd94\uc815"},{"location":"kim/ch6/#6","text":"6.2 6.4 6.6 6.8 6.10 6.12 6.14 6.16 6.18 6.20 6.22","title":"6\uc7a5. \ucd94\uc815"},{"location":"kim/ch7/","text":"7\uc7a5. \uac80\uc815 Notes 7.1: \\(P(\uae30\uae31\uc5ed|H_0)\\le\\alpha\\) \uc73c\ub85c \uc720\uc758\uc218\uc900 \uacb0\uc815 - \ub79c\ub364\ud654 \uac80\uc815 (randomized test): \ud2b9\uc815 \uc870\uac74\uc740 ,\ud655\ub960\uc801\uc73c\ub85c \uae30\uac01 - \uac80\uc815\ub825 \ud568\uc218 test function: \\(f(observation X_1,X_2..)\\) =\uc774 \uad00\uce21\uc744 \ud560 \uc2dc \uae30\uac01\ud560 \ud655\ub960 7.2 (ML ratio test): \\(P(\uae30\uae31\uc5ed|H_1 \\cup H_0)/P(\uae30\uae31\uc5ed|H_0)\\le\\) \ub85c \uc720\uc758\uc218\uc900 \uacb0\uc815 7.3: \\(P(\uae30\uae31\uc5ed(n)|H_0\\cup H_1)/P(\uae30\uae31\uc5ed(n)|H_0)\\) as \\(n\\longrightarrow\\infty\\) \ub85c \uc720\uc758\uc218\uc900 \uacb0\uc815 - Wald's \uac80\uc815\ud1b5\uacc4\ub7c9 - Rao's \uac80\uc815\ud1b5\uacc4\ub7c9 - \ubd84\ud560\ud45c Problems 7.2 7.4 (a) \\(P(X_1+..X_7\\ge c|H_0)\\le 10\\%\\) \uc560 \ub54c \\(E[sum]=3.5, V[sum]=7*0.5*0.5=1.75, \\sigma\\sim =1.322\\) , \\(\\sqrt 7((X_1+..X_7)/7-3.5)/\\sigma=((X_1+..X_7)/7-3.5)/0.5 \\sim N(0,1)\\) \\(\\Phi(1.28)\\sim=0.8997, \\Phi(1.29)\\sim=0.9015\\) \\(P(X_1+..X_7\\le (0.5*1.28+3.5)*7=28.9800)\\sim=0.8997\\) \\(P(X_1+..X_7\\le (0.5*1.29+3.5)*7=29.0150)\\sim=0.9015\\) \\(P(X_1+..X_7\\ge 28.9800)\\sim=0.1003\\) \\(P(X_1+..X_7\\ge 29.0100)\\sim=0.0885 \\Longrightarrow c\\in \\{29,30\\}\\) For \\(c=29\\) , \\(z=(29/7-3.5)/0.5=1.285714285\\) , \\(P(..>c)\\sim=0.0993\\) Hence the answer is 29. (b) c=29\uba74 \uae30\uac01, c=30\uc774\uba74 \\(\\gamma\\) \ud655\ub960\ub85c \uae30\uac01 (c) 7.6 7.8 7.10 7.12 7.14 7.16 7.18 7.20","title":"7\uc7a5. \uac80\uc815"},{"location":"kim/ch7/#7","text":"","title":"7\uc7a5. \uac80\uc815"},{"location":"kim/ch7/#notes","text":"7.1: \\(P(\uae30\uae31\uc5ed|H_0)\\le\\alpha\\) \uc73c\ub85c \uc720\uc758\uc218\uc900 \uacb0\uc815 - \ub79c\ub364\ud654 \uac80\uc815 (randomized test): \ud2b9\uc815 \uc870\uac74\uc740 ,\ud655\ub960\uc801\uc73c\ub85c \uae30\uac01 - \uac80\uc815\ub825 \ud568\uc218 test function: \\(f(observation X_1,X_2..)\\) =\uc774 \uad00\uce21\uc744 \ud560 \uc2dc \uae30\uac01\ud560 \ud655\ub960 7.2 (ML ratio test): \\(P(\uae30\uae31\uc5ed|H_1 \\cup H_0)/P(\uae30\uae31\uc5ed|H_0)\\le\\) \ub85c \uc720\uc758\uc218\uc900 \uacb0\uc815 7.3: \\(P(\uae30\uae31\uc5ed(n)|H_0\\cup H_1)/P(\uae30\uae31\uc5ed(n)|H_0)\\) as \\(n\\longrightarrow\\infty\\) \ub85c \uc720\uc758\uc218\uc900 \uacb0\uc815 - Wald's \uac80\uc815\ud1b5\uacc4\ub7c9 - Rao's \uac80\uc815\ud1b5\uacc4\ub7c9 - \ubd84\ud560\ud45c","title":"Notes"},{"location":"kim/ch7/#problems","text":"7.2 7.4 (a) \\(P(X_1+..X_7\\ge c|H_0)\\le 10\\%\\) \uc560 \ub54c \\(E[sum]=3.5, V[sum]=7*0.5*0.5=1.75, \\sigma\\sim =1.322\\) , \\(\\sqrt 7((X_1+..X_7)/7-3.5)/\\sigma=((X_1+..X_7)/7-3.5)/0.5 \\sim N(0,1)\\) \\(\\Phi(1.28)\\sim=0.8997, \\Phi(1.29)\\sim=0.9015\\) \\(P(X_1+..X_7\\le (0.5*1.28+3.5)*7=28.9800)\\sim=0.8997\\) \\(P(X_1+..X_7\\le (0.5*1.29+3.5)*7=29.0150)\\sim=0.9015\\) \\(P(X_1+..X_7\\ge 28.9800)\\sim=0.1003\\) \\(P(X_1+..X_7\\ge 29.0100)\\sim=0.0885 \\Longrightarrow c\\in \\{29,30\\}\\) For \\(c=29\\) , \\(z=(29/7-3.5)/0.5=1.285714285\\) , \\(P(..>c)\\sim=0.0993\\) Hence the answer is 29. (b) c=29\uba74 \uae30\uac01, c=30\uc774\uba74 \\(\\gamma\\) \ud655\ub960\ub85c \uae30\uac01 (c) 7.6 7.8 7.10 7.12 7.14 7.16 7.18 7.20","title":"Problems"},{"location":"kim/ch8/","text":"8\uc7a5. \ucd94\uc815\ub7c9\uc758 \ube44\uad50 8.2 8.4 8.6 8.8 8.10 8.12 8.14 8.16 8.18 8.20 8.22 8.24","title":"8\uc7a5. \ucd94\uc815\ub7c9\uc758 \ube44\uad50"},{"location":"kim/ch8/#8","text":"8.2 8.4 8.6 8.8 8.10 8.12 8.14 8.16 8.18 8.20 8.22 8.24","title":"8\uc7a5. \ucd94\uc815\ub7c9\uc758 \ube44\uad50"},{"location":"kim/ch9/","text":"9\uc7a5. \uac80\uc815\uc758 \ube44\uad50 9.2 9.4 9.6 9.8 9.10 9.12 9.14","title":"9\uc7a5. \uac80\uc815\uc758 \ube44\uad50"},{"location":"kim/ch9/#9","text":"9.2 9.4 9.6 9.8 9.10 9.12 9.14","title":"9\uc7a5. \uac80\uc815\uc758 \ube44\uad50"},{"location":"kreyszig/","text":"Kreyszig Chapters Chapter 1 Chapter 2 Chapter 3","title":"Kreyszig"},{"location":"kreyszig/#kreyszig","text":"","title":"Kreyszig"},{"location":"kreyszig/#chapters","text":"Chapter 1 Chapter 2 Chapter 3","title":"Chapters"},{"location":"kreyszig/ch1/","text":"1. Metric Spaces 1.1. Metric Space \\(d(x,y)=|x-y|\\) for \\(x,y\\in \\R\\) (M1) trivial (M2) \\(|x-y|=0 \\iff x=y\\) (M3) \\(|x-y|=|y-x|\\) (M4) \\(|x-y|\\le|x-z|+|z-y|\\) \\(d(x,y)=(x-y)^2\\) , (M1)~(M3) are trivial. (M4) is false for \\(x=0, y=2, z=1, (x-y)^2\\nleq (x-z)^2+(z-y)^2\\) . \\(d(x,y)=\\sqrt{|x-y|}\\) , (M1)~(M3) are trivial. For (M4), \\(\\sqrt{|x-y|}\\le\\sqrt{|x-z|}+\\sqrt{|z-y|} \\iff |x-y| \\le |x-z|+|z-y|+2\\sqrt{...}\\) , which is true from \\(|x-y|\\le |x-z|+|z-y|\\) . For two points, \\(X=\\{a,b\\}, d(a,a)=d(b,b)=0, d(a,b)=d(b,a)=c>0\\) . For one point, \\(X={a}, d(a,a)=0\\) . \\((X,d)\\) (i) if \\(|X|>1\\) , \\(k>0\\) . If \\(|X|=1\\) , \\(k\\ge 0\\) . If \\(|X|=0\\) , \\(k\\) is any real number. \\(k\\in \\R\\) in all cases. (ii) \\((d+k)(a,a)=0=d(a,a)+k\\) . If \\(|X|\\ge 1, k=0\\) . Otherwise \\(k\\) is any real number. \\(d(x,y)=\\sup_{j\\in \\N}|x_j-y_j|\\) We have \\(\\forall j\\in\\N, |x_j-y_j|\\le|x_j-z_j|+|z_j-y_j|\\) . \\(d(x,y)=1\\) if \\(x\\ne y\\) , 0 if \\(x=y\\) . \\(\\tilde d(x,y)=\\int_a^b |x(t)-y(t)|dt\\) (M1) \\(\\forall f\\in X\\) , \\(f\\) is bounded because its domain is a closed interval. Hence \\(\\tilde d\\) is real, finite, and non-negative. (M2) \\(\\tilde d(x,y)=0 \\iff \\) \\forall t\\in[a,b], x(t)=y(t) \\( \\iff x=y\\) (M3) obvious (M4) \\(\\int_a^b |x(t)-y(t)|dt\\le \\int_a^b |x(t)-z(t)|+|z(t)-y(t)|dt = \\int_a^b |x(t)-z(t)|+\\int_a^b |z(t)-y(t)|dt\\) (M1)~(M3) are obvious. (M4) \\(d(x,y)\\le d(x,z)+d(z,y)\\) since each term is \\(0\\) or \\(1\\) , the only case (M4) is false is \\(d(x,y)=1, d(x,z)=d(z,y)=0\\) . This means \\(x\\ne y, x=z, z=y\\) , which is impossible. Hence (M4) is true. \\(d\\) is a metric. \\(X=\\{(0,0,0),...(1,1,1)\\}, |X|=2^3=8\\) . \\(d(x,y)=\\sum |x_i-y_i|\\) . (M1)~(M3) are obvious. For (M4), \\(\\sum |x_i-y_i|\\le\\sum(|x_i-z_i|+|z_i-y_i|)=\\sum|x_i-z_i|+\\sum|z_i-y_i|\\) \\[\\begin{aligned} d(x_1,x_n)\\le &d(x_1,x_2)+d(x_2,x_n)\\\\ &d(x_1,x_2)+d(x_2,x_3)+d(x_3,x_n)\\\\ &\\dots\\\\ &d(x_1,x_2)+d(x_2,x_3)+\\dots+d(x_{n-1},x_n) \\end{aligned}\\] \\(|d(x,y)-d(z,w)|\\le d(x,z)+d(y,w)\\) ? WLOG, \\(d(x,y)\\ge d(z,w)\\) , then the question becomes \\(d(x,y)\\le d(x,z)+d(z,w)+d(w,y)\\) , which is true by triangle inequality. It is enough to consider \\(d(x,z)-d(y,z)\\ge0\\) . Then the inequality is \\(d(x,z)\\le d(x,y)+d(y,z)\\) , which is the triangle inequality. \\(d(x,y)\\le d(z,x)+d(z,y)\\) and \\(d(x,y)=0 \\iff x=y\\) . (M3) With \\(z=y\\) , we have \\(d(x,y)\\le d(y,x)\\) . Swapping \\(x\\) and \\(y\\) , we have \\(d(y,x)\\le d(x,y)\\) . Hence \\(d(x,y)=d(y,x)\\) . (M4) \\(d(x,y)\\le d(z,x)+d(z,y)=d(x,z)+d(z,y)\\) . Putting \\(x=y\\) into \\(d(x,y)\\le d(x,z)+d(z,y)\\) , we have \\(0\\le d(x,z)\\) for all \\(x, z\\) . 1.2. Further Examples of Metric Spaces \\(d(x,y)=\\sum_{j=1}^\\infty \\mu_j \\frac{|x_j-y_j|}{1+|x_j-y_j|}, \\sum\\mu_j<\\infty, \\mu_j>0\\) (M1) \\(d(x,y)<\\sum \\mu_j <\\infty\\) . (M2, M3) obvious (M4) The same proof from 1.2-1 applies here too. ( \\(f(t)=\\frac{t}{1+t}, \\cdots\\) ) With \\(\\alpha=\\sqrt a, \\beta=\\sqrt b, p=2, q=2\\) , we have \\(\\alpha\\beta\\le \\frac{\\alpha^p}{p}+\\frac{\\beta^q}{q}\\Longrightarrow \\sqrt{ab}\\le\\frac{a+b}{2}\\) . Setting \\(b_i=1\\) , (11) becomes \\((\\sum|a_i|)^2\\le\\sum|a_i|^2\\) . Let \\(x_n=1/\\log n\\) . Then \\(\\lim_{n\\to\\infty} x_n=0\\) . Given \\(p\\) , there exists \\(m\\) such that \\(\\forall n\\ge m, \\log^pn<n\\) . Thus \\[\\begin{aligned} \\sum|x_n|^p =\\sum_{n=1}^\\infty \\frac{1}{\\log^p n} &> \\sum_{n=m}^\\infty \\frac{1}{\\log^p n}\\\\ &> \\sum_{n=m}^\\infty \\frac{1}{n}=\\infty \\end{aligned}\\] \\(\\therefore x\\notin l^p\\) . \\(x_n=1/n\\) , then \\(\\sum 1/n=\\infty\\Longrightarrow x\\notin l^1, \\sum1/n^p<\\infty\\Longrightarrow x\\in l^2\\) . These can be easily shown by integrals and lower, upper bounds. If \\(\\delta(A)=\\infty\\) , for any \\(\\delta_0>0, \\exists x,y\\in A, d(x,y)>\\delta_0\\) , this means \\(\\delta(B)\\ge\\delta_0\\) , hence \\(\\delta(B)=\\infty\\) . Now assume \\(\\delta(A)<\\infty\\) . Also assume \\(A\\sub B, \\delta(A)>\\delta(B)\\) . For any \\(\\epsilon>0\\) , there must be \\(x,y\\in A\\) such that \\(d(x,y)>\\delta(A)-\\epsilon\\) . Since \\(x,y\\in B\\) , \\(\\delta(B)\\ge d(x,y)>\\delta(A)-\\epsilon\\) . Hence \\(\\delta(B)\\ge \\delta(A)\\) . \\(\\delta(A)=0\\Longrightarrow d(x,y)\\le 0\\Longrightarrow x=y\\Longrightarrow |A|\\le 1\\) . If \\(|A|=0, \\delta(A)=-\\infty\\) , hence \\(|A|=1\\) . Conversely, \\(|A|=1\\Longrightarrow \\delta(A)=0\\) . For distinct \\(x,y\\in X\\) , \\(D(\\{x\\},\\{x,y\\})=0\\) but \\(\\{x\\}\\ne\\{x,y\\}, \\therefore\\) D is not a metric. \\(D\\) can be a metric if \\(A=\\varnothing\\) or \\(B=\\varnothing\\) . \\(A\\cap B\\ne \\varnothing\\Longrightarrow\\exists x\\in A\\cap B\\Longrightarrow D(A,B)=D(\\{x,\\dots\\},\\{x,\\dots\\})=0\\) . The converse is not true. Let \\(A=[0,3], B=(3,6]\\) , then \\(D(A,B)=0\\) but \\(A\\cap B=\\varnothing\\) . It is enough to prove \\(D(x,B)-D(y,B)\\le d(x,y)\\) . For \\(\\forall b\\in B\\) , \\[\\begin{aligned}&D(x,B)\\le d(x,b)\\le d(x,y)+d(y,b)\\\\ \\Longrightarrow &D(x,B)-d(x,y)\\le d(y,b) \\\\ \\Longrightarrow &D(x,B)-d(x,y) \\text{ is a lower bound of d(y,b)} \\\\ \\Longrightarrow &D(x,B)-d(x,y)\\le D(y,B) \\\\ \\Longrightarrow &D(x,B)-D(y,B)\\le d(x,y) \\end{aligned}\\] (M1)~(M3) are obvious. (M4) Let \\(f(t)=t/(1+t)\\) . It is shown in 1.2-1 that \\(f\\) is increasing. From \\(d(x,y)\\le d(x,z)+d(z,y)\\) , \\[\\begin{aligned} f(d(x,y))&\\le f(d(x,z)+d(z,y)) \\\\ \\frac{d(x,y)}{1+d(x,y)}&\\le \\frac{d(x,z)+d(z,y)}{1+d(x,z)+d(z,y)}\\\\ &=\\frac{d(x,z)}{1+d(x,z)+d(z,y)}+\\frac{d(z,y)}{1+d(x,z)+d(z,y)}\\\\ &\\le\\frac{d(x,z)}{1+d(x,z)}+\\frac{d(z,y)}{1+d(z,y)} \\end{aligned}\\] Also \\(0\\le f(t)\\le 1\\) , so \\(X\\) is bounded. Let \\(a_0\\in A, b_0\\in B\\) . For any \\(a\\in A, b\\in B\\) , \\[\\begin{aligned} d(a,b)&\\le d(a,a_0)+d(a_0,b_0)+d(b_0,b)\\\\ &\\le\\delta(A)+d(a_0,b_0)+\\delta(B)\\\\ &<\\infty \\end{aligned}\\] \\(\\therefore A\\cup B\\) is bounded. (M1)~(M3) are obvious. (M4) \\[\\begin{aligned} d(x,y)&=d_1(x_1,y_1)+d_2(x_2,y_2)\\\\ &\\le d_1(x_1,z_1)+d_1(z_1,y_1)+d_2(x_2,z_2)+d_2(z_2,y_2)\\\\ &=d(x,z)+d(z,y) \\end{aligned}\\] (M1)~(M3) are clear. (M4) \\(\\tilde d(x,y)\\le \\tilde d(x,z)+\\tilde d(z,y)\\) can be written as \\(|a+bi|\\le|c+di|+|e+fi|\\) with \\(a\\le c+e, b\\le d+f\\) . \\[\\begin{aligned} |a+bi|\\le|(c+e)+(d+f)i|&=|c+di+e+fi|\\\\ &\\le|c+di|+|e+fi| \\end{aligned}\\] the last inequality holds because \\(\\mathbb C\\) is a metric space. \\[\\begin{aligned}\\tilde{\\tilde{\\kern{-0.3ex}d}}(x,y)&=\\max(d_1(x_1,y_1),d_2(x_2,y_2))\\\\ &=\\max(xy1, xy2)\\\\ &=\\max(xz1+zy1,xz2+zy2)=\\triangle \\end{aligned}\\] ( \\(xy1\\) represents \\(d_1(x_1,y_1)\\) for convenience) We want to prove \\(\\triangle\\le \\max(xz1, xz2)+\\max(zy1,zy2)\\) . This is equivalent to show \\(\\max(a+b,c+d)\\le \\max(a,c)+\\max(b,d)\\) . \\[\\begin{aligned} \\max(a+b,c+d)&\\le\\max(\\max(a,c)+b,\\max(a,c)+d)\\\\ &\\le\\max(\\max(a,c)+\\max(b,d),\\cdots)\\\\ &\\le\\max(a,c)+\\max(b,d) \\end{aligned}\\] 1.3. Open Set, Closed Set, Neighborhood (a) For any \\(x\\in B(x_0,r)\\) , define \\(B'=\\{y|d(x,y)<r-d(x,x_0)>\\}\\) . Since \\(d(x_0,y)\\le d(x,y)+d(x,x_0)<r\\) , \\(B'\\sub B\\) . \\(\\therefore B\\) is an open set. (b) Let a closed ball \\(\\tilde B(x_0,r)\\) . Then \\(\\tilde B^c = {p|d(p,x_0)>r}. For any point \\) x\\in\\tilde B^c \\(, let \\) B_x=B(x, d(x,x_0)-r) \\(. A point \\) y\\in B_x \\( is not in \\) B \\( because \\) r<d(x,x_0)-d(x,y)\\le d(x,y)+d(y,x_0)-d(x,y)=d(x_0,y) \\(. \\) \\therefore B_x \\in \\tilde B^c \\(, so \\) x \\( is an internal point of \\) \\tilde B^c \\(, hence \\) B^c \\( is open, and \\) B$ is closed. An open ball in \\(\\R\\) is an open interval. An open ball in \\(\\mathbb C\\) is a filled circle without boundary in the complex plane. An open ball \\(B(x_0,r) \\) in \\(C[a,b]\\) is a set of functions \\(x\\) whose the value at \\(t\\in[a,b]\\) satisfies \\(|x(t)-x_0(t)|\\le r\\) . In other words, \\(x_0(t)-r\\le x(t)\\le x_0(t)+r\\) . We need to find the smallest \\(r\\) such that \\(\\forall t |\\cos t-\\sin t|\\le r\\) . Equivalently, find the maximum \\(\\cos t + \\sin t\\) where \\(t\\in [0,\\pi/4]\\) , or, \\(\\max f(x)\\) where \\(f(x)=x+\\sqrt{1-x^2}, x\\in[0,1]\\) . \\(f'(x)=1+\\frac{-2x}{2\\sqrt{1-x^2}}=0\\Longrightarrow x=\\frac{1}{\\sqrt 2}\\) . Therefore \\(t\\) is \\(0\\degree, 45\\degree, 90\\degree\\) . Trying these values, we have \\(\\max(\\cos t + \\sin t)=\\sqrt 2\\) . If a non-empty set \\(A\\) is open, each point \\(a\\in A\\) has a ball \\(B_a\\sub A\\) . Let \\(B=\\cup_a B_a\\) , then \\(B\\sub A\\) . Also \\(A\\sub B\\) because every \\(a\\in A\\) , \\(a\\in B_a\\sub B\\) . Hence \\(A=B\\) , and \\(A\\) is an union of open balls. Conversely if \\(A\\) is an union of open balls, it is open (by what we learned). (a) \\(\\varnothing\\) is open because it has no member and we can say all members are internal points. \\(X\\) is open because any neighborhood is in \\(X\\) . \\(\\varnothing, X\\) are closed because their complements are open. (b) For a subset \\(Y\\sub X\\) , \\(Y\\) is open because for \\(y\\in Y, B(y,0.5)=\\{y\\}\\sub Y\\) . Since every subset is open, \\(Y^c\\) is open, hence \\(Y\\) is closed. Suppose a neighborhood \\(N\\) of \\(x_0\\) contains finitely many points of \\(A\\) . Let \\(d_0=\\min_{a\\in N\\cap A} d(x_0, a)\\) . Then it contradicts that \\(B(x_0, d_0/2)\\) should contain at least one point of \\(A\\) . (a) \\(\\N=\\overline \\N\\) on \\(\\R\\) (b) \\(\\overline\\mathbb Q=\\R\\) on \\(\\R\\) (c) \\(\\overline{\\mathbb Q \\times \\mathbb Q}=\\R\\times\\R\\) (d) \\(\\overline{\\{z\\mid \\lvert z\\rvert<1\\}}=\\{z\\mid\\lvert z\\rvert \\le 1\\}\\) on \\(C\\) Let \\(X=\\{0,1\\}\\) . Then \\(B(0;1)=\\{0\\}, \\overline{B(0;1)}=\\{0\\}\\) , but \\(\\tilde B(0;1)=\\{0,1\\}\\) . \\(A\\sub \\overline A = A\\cup\\{\\text{accumulation points}\\}\\) \\(\\overline A=\\overline{\\overline A}\\) : We have \\(\\overline A\\sub \\overline {\\overline A}\\) . For the converse, suppose the contrary, so \\(\\exists a\\in \\overline{\\overline A}, a\\notin \\overline A\\) . Since \\(a\\) is not an accumulation point of \\(A\\) , but of \\(\\overline A\\) , \\(\\exists \\epsilon_0>0, B(a,\\epsilon_0)\\cap A-\\{a\\}=\\varnothing\\) \\(\\forall \\epsilon>0, B(a,\\epsilon)\\cap \\overline A - \\{a\\}\\neq \\varnothing\\) Let \\(a'\\in B(a,\\epsilon_0/2)\\cap \\overline A-\\{a\\}\\) , then \\(a'\\in \\overline A-A\\) so \\(a'\\) is an accumulation point of \\(A\\) . \\(\\forall \\epsilon>0, B(a', \\epsilon)\\cap A-\\{a'\\}\\neq \\varnothing\\) with \\(\\epsilon=\\epsilon_0/2\\) , \\(\\exists a''\\in B(a', \\epsilon_0/2)\\cap A-\\{a'\\}\\) \\(d(a'',a')<\\epsilon_0/2, d(a',a)<\\epsilon_0/2, d(a'',a)<\\epsilon_0/2\\) Also \\(a''\\neq a\\) because \\(a''\\in A, a\\in \\overline A\\) . This contradicts to \\(a'' \\in B(a,\\epsilon_0)\\cap A-\\{a\\}\\) . Therefore such \\(a\\) does not exist, and \\(\\overline{\\overline A}=A\\) . \\(\\overline{A\\cup B}=\\overline A\\cup \\overline B\\) : suppose \\(x\\in \\overline{A\\cup B}, x\\notin \\overline A, x\\notin \\overline B\\) . Then \\(\\exists \\epsilon>0\\) , \\(B(x,\\epsilon)\\cap A\\sub\\{x\\}\\) , \\(B(x,\\epsilon)\\cap B\\sub \\{x\\}\\) , but \\(B(x,\\epsilon)\\cap(A\\cup B)\\not\\subset \\{x\\}\\) , which contradicts. Hence \\(\\overline{A\\cup B}\\sub (\\overline A\\cup \\overline B)\\) . Now suppose \\(x\\in \\overline A\\) but \\(x\\notin \\overline{A\\cup B}\\) . \\(\\forall \\epsilon>0, B(x,\\epsilon)\\cap A-\\{x\\}\\neq\\varnothing, B(x,\\epsilon)\\cap(A\\cup B)-\\{x\\}\\neq \\varnothing\\) , \\(x\\) is an accumulation point of \\((A\\cup B)\\) . Therefore the converse is also true. \\(\\overline{A\\cap B}\\sub \\overline A\\cap \\overline B\\) if \\(x\\in A\\cap B\\) , then \\(x\\in A\\sub \\overline A, x\\in B\\sub \\overline B\\Longrightarrow x\\sub \\overline A\\cap \\overline B\\) . If \\(x\\in \\overline{A\\cap B}\\) , \\(\\forall \\epsilon>0, B(x,\\epsilon)\\cap(A\\cap B)-\\{x\\}\\neq\\varnothing, B(x,\\epsilon)\\cap A-\\{x\\}\\neq\\varnothing\\) and \\(B(x,\\epsilon)\\cap B-\\{x\\}\\neq\\varnothing\\) , hence \\(x\\) is in \\(\\overline A\\) and \\(\\overline B\\) , and \\(x\\in \\overline A\\cap \\overline B\\) . Conversely suppose \\(x\\in \\overline A\\cap \\overline B\\) . If \\(x\\in A\\cap B\\) then \\(x\\in \\overline{A\\cap B}\\) . If \\(x\\notin A, x\\in B\\) , then \\(B(x,\\epsilon)\\cap A-\\{x\\}\\neq\\varnothing, B(x,\\epsilon)\\cap B-\\{x\\}\\neq\\varnothing, B(x,\\epsilon)\\cap (A\\cap B)-\\{x\\}\\neq\\varnothing, (\\overline A\\cap \\overline B)\\not\\sub\\overline{A\\cap B}\\) . Hence \\(\\overline{A\\cap B}\\not\\sub\\overline A\\cap\\overline B\\) . \\(x\\in A \\Longrightarrow d(x,x)=0 \\Longrightarrow D(x,A)=0\\) , \\(x\\notin A\\Longrightarrow \\forall \\epsilon>0, B(x,\\epsilon)\\cap A-\\{x\\}\\neq \\varnothing\\) If \\(D(x,A)=\\epsilon_0>0\\) let \\(a\\in B(x,\\epsilon_0)\\cap A-\\{x\\}\\) , then \\(d(x,a)<D(x,A)\\) which contradicts. \\(\\therefore x\\in \\overline A \\Longrightarrow D(x,A)=0\\) . For converse, \\(D(x,A)=0\\) . Then there exists a sequence in \\(A\\) that converges to \\(x\\) , hence \\(x\\in \\overline A\\) . (a) the boundary of \\((-1,1)\\Longrightarrow\\{-1,1\\}\\) \\([-1,1)\\Longrightarrow\\{-1,1\\}\\) \\([-1,1]\\Longrightarrow\\{-1,1\\}\\) (b) \\(\\mathbb Q\\sub\\R\\) : the boundary is \\(\\R\\) because any neighborhood has a point of \\(\\mathbb Q\\) and a point of \\(\\R\\) . (c) For both disks, the boundary is \\(\\{z\\mid \\lvert z\\rvert=1\\}\\) . \\(B[a,b]\\) is not separable: Consider a subset \\(F\\) , a set of functions \\(f(x)\\) such that \\(f(x)=0\\) if \\(a\\le x<t\\) , 1 if \\(t\\le x\\le b\\) , for \\(a<t<b\\) . \\(F\\) is uncountable and \\(B(f,1/2)=\\{f\\}\\) for \\(f\\in F\\) . If \\(B[a,b]\\) has any dense subset \\(A\\) , disjoint and uncountably many neighbors \\(B(f,1/2)\\) should contain a point of \\(A\\) , which makes \\(A\\) uncountable. \\(X\\) is separable \\(\\iff\\) \\(X\\) has a countable dense subset \\(\\iff\\) \\(X\\) has a countable subset \\(Y\\) such that \\(\\forall \\epsilon>0, \\forall x\\in X, \\exists y\\in Y, d(x,y)<\\epsilon\\) . The interpretation is that for any point \\(x\\) , there exists a sequence of \\((y_n)\\) that converges to \\(x\\) . Show \u2460 \\(T:X\\Longrightarrow Y\\) is continuous \\(\\iff\\) \u2461 \\(T^{-1}(M)\\) is closed in \\(X\\) . \u2460 to \u2461: \\(T^{-1}(M^c)=(T^{-1}(M))^c\\) . If \\(M\\) is closed, \\(M^c\\) is open, and by \u2460, \\(T^{-1}(M^c)\\) is open. Since \\((T^{-1}(M))^c\\) is open, \\(T^{-1}(M)\\) is closed. \u2461 to \u2460: If \\(M\\) is open, \\(M^c\\) is closed, and by \u2461, \\(T^{-1}(M^c)=(T^{-1}(M))^c\\) is closed, so \\(T^{-1}(M)\\) is open. \\(cos(x)\\) on \\((-2\\pi,2\\pi)\\) has an open domain but the range \\([-1,1]\\) is closed. 1.4. Convergence, Cauchy Sequence, Completeness If \\((x_n)\\) converges to a limit \\(x\\) , \\(\\forall \\epsilon>0, \\exists N>0, \\forall n>N, d(x_n,x)<\\epsilon\\) , then for any \\((x_{n_k})\\) , \\(\\forall\\epsilon>0, \\exists K>0, \\forall k>K, d(x_{n_k}, x)<\\epsilon\\) , therefore \\(x_{n_k}\\longrightarrow x\\) \\((x_n)\\) is Cauchy and \\(x_{n_k}\\longrightarrow x\\) , then \\(\\forall \\epsilon>0\\) , - \\(\\exists K>0, \\forall k>K, d(x_{n_k},x)<\\epsilon/2\\) - \\(\\exists N>0, \\forall n,m>K, d(x_n,x_m)<\\epsilon/2\\) - Then \\(\\forall n>max(N,n_k), \\exists i, n_i>n\\) , and \\(d(x_n,x)\\le d(x_n,x_{n_i})+d(x_{n_i},x)<\\epsilon/2+\\epsilon/2=\\epsilon\\) . Hence \\((x_n)\\) converges to \\(x\\) . \\((x_n)\\longrightarrow x\\) is equivalent to \\(\\forall V=n(x), \\exists n_0, \\forall n>n_0, x_n\\in V\\) ( \\(\\Longrightarrow\\) ): for a neighborhood \\(V\\) , \\(\\exists r, B_r(x)\\sub V\\) , there exists \\(N\\) such that \\(\\forall n>N, d(x_n,x)<r\\) , hence \\(x_n\\in B_r(x)\\sub V\\) . ( \\(\\Longleftarrow\\) ): For any \\(\\epsilon>0\\) and \\(B_\\epsilon (x)\\) , there exists \\(n_0\\) such that \\(x_n\\in B_\\epsilon(x) \\Longrightarrow d(x_n,x)<\\epsilon\\) for all \\(n>n_0\\) . Hence \\((x_n)\\longrightarrow x\\) . \\(\\exists N, \\forall n,m\\ge N, d(x_n,x_m)<1\\Longrightarrow \\forall n\\ge N, d(x_n,x_N)<1\\) . Hence \\(x_N,x_{N+1},..\\) are bounded. Also \\(x_1, x_2, .. x_{N-1}\\) are finite, so bounded. No. A counter example is \\(x_n=\\sin n\\) . We will show that \\((a_n)\\) is Cauchy, then since \\(\\R\\) is complete, \\((a_n)\\) converges. For any \\(\\epsilon>0, \\exists N, \\forall n,m>N, d(x_n,x_m)<\\epsilon/4\\) and \\(d(y_n,y_m)<\\epsilon/4\\) . Then \\(|a_n-a_m|=|d(x_n,y_n)-d(x_m,y_m)|\\le d(x_n,x_m)+d(y_n,y_m)<\\epsilon/2\\) . Hence \\((a_n)\\) is Cauchy, thus convergent. 1.4-2 (b) has a stronger condition than Prob 6, hence 1.4-2 (b) is true. If \\((x_n)\\) is Cauchy in \\((X,d_1)\\) , for \\(\\epsilon>0\\) and large enough \\(n,m\\) , we have \\(d_1(x_n,x_m)<b\\epsilon\\) , or, \\(d_2(x_n,x_m)<\\epsilon\\) . Hence \\((x_n)\\) is Cauchy in \\((X,d_2)\\) . In the same way, a cauchy seq in \\((X,d_2)\\) is Cauchy in \\((X,d_1)\\) . It can be easily shown that \\(\\tilde{\\tilde{\\kern{-0.3ex}d}}\\le \\tilde d\\le d\\le 2*\\tilde{\\tilde{\\kern{-0.3ex}d}}\\) . Consider a Cauchy sequence \\(c_n=(a_n+i b_n)\\) in \\(\\mathbb C\\) , where \\(a_n,b_n\\in \\R\\) . Then for any \\(\\epsilon>0\\) and large enough \\(n\\) and \\(m\\) , \\(d(a_n,a_m)\\le d(c_n,c_m)<\\epsilon, d(b_n,b_m)\\le d(c_n,c_m)<\\epsilon\\) , hence \\((a_n)\\) and \\((b_n)\\) are Cauchy. Since \\(\\R\\) is complete, \\((a_n)\\longrightarrow a, (b_n)\\longrightarrow b\\) . Again, for any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(d(a_n,a)<\\epsilon/2, d(b_n,b)=d(i b_n, i b)<\\epsilon/2\\) , hence \\(d(c_n,a+bi)<\\epsilon\\) , \\((c_n)\\longrightarrow a+bi\\) , \\(\\mathbb C\\) is complete. 1.5. Examples, Completeness Proofs Since \\(\\R\\) is complete, a subset is complete iff it is complete. Hence \\((a,b)\\) is incomplete and \\([a,b]\\) is complete. Consider a Cauchy \\((x^(1),x^(2),\\dots)\\) . For any \\(\\epsilon\\) and large enough \\(n,m\\) , \\(d(x^{(n)},x^{(m)})<\\epsilon\\Longrightarrow \\forall j, |x_j^{(n)}-x_j^{(m)}|<\\epsilon\\) . For a fixed \\(j\\) , (x^{(n)}_j) is Cauchy. Since \\(\\R\\) is complete, \\(x^{(n)}_j\\) converges, and let the limit point \\(x_j\\) , and let \\(x=(x_n)\\) . Note that \\(x\\in X\\) . For any \\(\\epsilon>0\\) and large enough \\(n,m\\) , \\(\\forall j |x_j^n-x_j|\\le \\epsilon\\Longrightarrow d(x^n,x)\\le \\epsilon\\) , and \\(x^n\\) converges to \\(x\\) . Since any Cauchy converges, \\(X\\) is compelte. Let \\(x_1=(1,0,0,\\dots), x_2=(1,1/2,0,0,\\dots), x_3=(1,1/2,1/4,0,0,\\dots), \\dots\\) . The sequence \\((x_1,x_2,\\dots)\\) converges to \\((1,1/2,1/4,1/8,\\dots)\\) but this has infinitely many zeros, therefore this is not in \\(M\\) . Hence \\(M\\) is not complete. The previous example converges to a point not in \\(M\\) , hence \\(M\\) is not closed, Since \\(l^\\infty\\) is complete, \\(M\\) is not complete. Consider a Cauchy \\((x_n)\\) . For \\(\\epsilon=0.5\\) and large enough \\(n,m\\) , \\(|x_n-x_m|<1\\) , which means \\(x_n=x_m\\) and the sequence is eventually constant and convergent. Hence \\(X\\) is complete. \\((x_n=n)\\) is Cauchy. Suppose this sequence converges to \\(x\\) . For large enough \\(n\\) , \\(x_n>x\\Longrightarrow \\arctan(x_n)>\\arctan(x)\\) , so it cannot converge. Hence the space is incomplete. Similar to 6, \\((x_n=n)\\) is Cauchy but it does not converge. \\(C[a,b]\\) is complete. We will show \\(Y\\) is closed. Consider \\((y_n)\\longrightarrow y\\) and suppose \\(y\\notin Y\\) . Then \\(y(a)\\neq y(b)\\) and for any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(|y_n(a)-y(a)|<\\epsilon/2, |y_n(b)-y(b)|<\\epsilon/2, |y(a)-y(b)|<\\epsilon\\) , which implies \\(y(a)=y(b)\\) , a contradiction. Hence \\(Y\\) is closed and complete. \\((x_m)\\in C[a,b], (x_m)\\Longrightarrow x\\) . For any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(d(x_n,x)<\\epsilon\\Longrightarrow |x_n(t)-x(t)|<\\epsilon\\) . Since \\(x_n\\) is continuous, for any \\(\\epsilon_2>0\\) there exists \\(\\delta>0\\) , \\(|t_1-t_2|<\\delta\\Longrightarrow |x_n(t_1)-x_n(t_2)|<\\epsilon_2\\) . Then for \\(t_1,t_2\\in [a,b]\\) such that \\(|t_1-t_2|<\\delta, |x(t_1)-x(t_2)|\\le|x(t_1)-x_n(t_1)|+|x_n(t_1)-x_n(t_2)|+|x_n(t_2)-x(t_2)|<\\epsilon+\\epsilon_2+\\epsilon\\) . Since \\(\\epsilon\\) and \\(\\epsilon_2\\) were chosen arbitrarily, \\(x\\) is continuous. Any Cauchy sequence in a discrete metric space is eventually constant (use \\(\\epsilon=0.5\\) ), and converges to the constant. Hence discrete metric spaces are complete. Suppose \\(x_n\\longrightarrow x\\) . Then for any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(d(x_n,x)=\\sum_j \\frac{1}{2^j} \\frac{|x_j^{(n)}-x_j|}{|x_j^{(n)}-x_j|+1}<\\epsilon\\) . Since all terms are positive, \\(\\frac{|x_j^{(n)}-x_j|}{|x_j^{(n)}-x_j|+1}<2^j \\epsilon\\) . Let \\(f(t)=\\frac{t}{1+t}\\) . \\(f\\) is continuous and increasing. \\(f(|x_j^{(n)}-x_j|)<2^j\\epsilon\\) implies \\(x_j^{(n)}\\longrightarrow x_j\\) . (why?) Consider a Cauchy \\((x^{(m)})\\) . For any \\(\\epsilon>0\\) and large enough \\(n,m\\) , \\(d(x^{(n)},x^{(m)})<\\epsilon\\Longrightarrow f(|x_j^{(n)}-x_j^{(m)}|)<2^j \\epsilon\\Longrightarrow |x_j^{(n)}-x_j^{(m)}|<f^{-1}(2^j\\epsilon)\\) . For a fixed \\(j\\) and any \\(\\epsilon_2>0\\) , there exists \\(\\epsilon_0\\) such that \\(f^{-1}(2^j\\epsilon_0)<\\epsilon_2\\) . With \\(\\epsilon=\\epsilon_0\\) in the previous inequality, \\(|x_j^{(n)}-x_j^{(m)}|<f^{-1}(2^j\\epsilon_0)<\\epsilon_2\\) , hence \\(x_j^{(n)}\\) is Cauchy. This sequence converges to \\(x_j\\) because \\(\\R\\) is complete. By Problem 11, \\(x^{(n)}\\Longrightarrow x\\) . Therefore \\(s\\) is complete. With \\(n<m\\) , \\(d(x_n,x_m)=\\int_{m^{-2}}^{n^{-2}}(t^{-1/2}-t)dt=[2t^{1/2}-1/2 t^2]_{m^{-2}}^{n^{-2}}=2(n^{-1}-m^{-1})-1/2(n^{-4}-m^{-4})<2(n^{-1}-m^{-1})<2n^{-1}\\) . Thus for any \\(epsilon>0\\) , choose \\(n\\) such that \\(2n^{-1}<\\epsilon\\) , then \\(d(x_n,x_m)<\\epsilon)\\) . Hence \\((x_n)\\) is Cauchy. \\((x_n)\\) converges to \\(x(t)=t^{-1/2}\\) for \\(t>0\\) , but \\(x(0)=0\\) . Hence \\(x\\) is not continuous at \\(t=0\\) and \\(x\\) is not in the space. \\(d(x_n,x_m)=\\frac{1}{(n+1)^2}+\\frac{1}{(n+2)^2}+\\dots+\\frac{1}{m^2}\\le \\int_{n+1}^{m+1} \\frac{1}{t^2} dt = [-1/t]^{m+1}_{n+1}=\\frac{1}{n+1}-\\frac{1}{m+1}<\\frac{1}{n+1}\\) . Therefore for \\(n,m>1/\\epsilon, d(x_n,x_m)<\\frac{1}{n+1}<\\frac{1}{n}<\\epsilon\\) , Hence this is Cauchy. Suppose this converges to \\(x\\) . Let \\(k\\) the index ofo the last nonzero element of \\(x\\) . Then for \\(n>k, d(x,x_n)>\\frac{1}{(k+1)^2}+\\frac{1}{(k+2)^2}+\\dots+\\frac{1}{n^2}\\) . Hence \\(d(x,x_n)>\\frac{1}{(k+1)^2}\\) and \\((x_n)\\) does not converge to \\(x\\) . 1.6. Completion of Metric Spaces Let \\(d_m=\\min_{a,b\\in Y, a\\neq b} d(a,b)\\) . This exists because \\(Y\\) is finite. Also \\(d_m>0\\) . For any Cauchy sequence \\((x_n)\\) , with \\(\\epsilon=d_m/2\\) and large enough \\(n,m\\) , \\(d(x_n,x_m)<d_m/2\\) . The only possible distance smaller than \\(d_m\\) is \\(0\\) , hence \\(x_n=x_m\\) , therefore \\((x_n)\\) converges to a constant in \\(Y\\) . This proves \\(Y\\) is complete. The completion of \\((\\mathscr Q,d)\\) is \\((\\R, d')\\) where \\(d'(x,y)=|x-y|\\) . A discrete metric space is already complete. Let \\(T\\) a bijective isometry from \\(X_1\\) onto \\(X_2\\) . Consider a Cauchy sequence \\((y_n)\\) in \\(X_2\\) . Then \\((T^{-1} y_n)\\) is Cauchy in \\(X_1\\) because \\(d'(y_n,y_m)<\\epsilon\\longrightarrow d(T^{-1}y_n,T^{-1}y_m)<\\epsilon\\) . This converges to \\(x\\) in \\(X_1\\) because \\(X_1\\) is complete. Then \\(d(T^{-1}y_n,x)<\\epsilon\\longrightarrow d'(y_n,Ty_n)<\\epsilon\\) , hence \\(y_n\\) converges to \\(Tx\\) . This proves \\(X_2\\) is complete. 5. (a) Let \\(T\\) a bijective isometry from \\(X\\) onto \\(Y\\) . It is continuous. (for any \\(\\epsilon>0\\) , \\(\\delta=\\epsilon\\) ) The inverse is also continuous (for any \\(\\epsilon>0\\) , \\(\\delta=\\epsilon\\) ). Hence \\(T\\) is a homeomorphism. (b) \\(\\arctan\\) maps from \\((-\\infty,\\infty)\\) (complete) to \\((-\\pi/2,\\pi/2)\\) (incomplete). The function is bijective, and both the forward and inverse are continuous, hence \\(\\arctan\\) is a homeomorphism. Define \\(T:C[a,b]\\longrightarrow C[0,1], T(f)(x)=f((b-a)x+a)\\) . Then for \\(f,g\\in C[a,b]\\) , \\[\\begin{aligned} &d'(Tf,Tg) \\\\ &=\\sup |Tf(t)-Tg(t)|, t\\in[0,1] \\\\ &=\\sup |f((b-a)t+a)-g((b-a)t+a)|, t\\in[0,1] \\\\ &=\\sup |f(x)-g(x)|, x\\in[a,b] \\\\ &=d(f,g) \\end{aligned}\\] where \\(C[a,b]\\) is equipped with \\(d\\) and \\(C[a,b]\\) is equipped with \\(d'\\) . \\(T\\) is bijective, hence \\(C[a,b]\\) and \\(C[0,1]\\) are isomorphic. 7.","title":"1. Metric Spaces"},{"location":"kreyszig/ch1/#1-metric-spaces","text":"","title":"1. Metric Spaces"},{"location":"kreyszig/ch1/#11-metric-space","text":"\\(d(x,y)=|x-y|\\) for \\(x,y\\in \\R\\) (M1) trivial (M2) \\(|x-y|=0 \\iff x=y\\) (M3) \\(|x-y|=|y-x|\\) (M4) \\(|x-y|\\le|x-z|+|z-y|\\) \\(d(x,y)=(x-y)^2\\) , (M1)~(M3) are trivial. (M4) is false for \\(x=0, y=2, z=1, (x-y)^2\\nleq (x-z)^2+(z-y)^2\\) . \\(d(x,y)=\\sqrt{|x-y|}\\) , (M1)~(M3) are trivial. For (M4), \\(\\sqrt{|x-y|}\\le\\sqrt{|x-z|}+\\sqrt{|z-y|} \\iff |x-y| \\le |x-z|+|z-y|+2\\sqrt{...}\\) , which is true from \\(|x-y|\\le |x-z|+|z-y|\\) . For two points, \\(X=\\{a,b\\}, d(a,a)=d(b,b)=0, d(a,b)=d(b,a)=c>0\\) . For one point, \\(X={a}, d(a,a)=0\\) . \\((X,d)\\) (i) if \\(|X|>1\\) , \\(k>0\\) . If \\(|X|=1\\) , \\(k\\ge 0\\) . If \\(|X|=0\\) , \\(k\\) is any real number. \\(k\\in \\R\\) in all cases. (ii) \\((d+k)(a,a)=0=d(a,a)+k\\) . If \\(|X|\\ge 1, k=0\\) . Otherwise \\(k\\) is any real number. \\(d(x,y)=\\sup_{j\\in \\N}|x_j-y_j|\\) We have \\(\\forall j\\in\\N, |x_j-y_j|\\le|x_j-z_j|+|z_j-y_j|\\) . \\(d(x,y)=1\\) if \\(x\\ne y\\) , 0 if \\(x=y\\) . \\(\\tilde d(x,y)=\\int_a^b |x(t)-y(t)|dt\\) (M1) \\(\\forall f\\in X\\) , \\(f\\) is bounded because its domain is a closed interval. Hence \\(\\tilde d\\) is real, finite, and non-negative. (M2) \\(\\tilde d(x,y)=0 \\iff \\) \\forall t\\in[a,b], x(t)=y(t) \\( \\iff x=y\\) (M3) obvious (M4) \\(\\int_a^b |x(t)-y(t)|dt\\le \\int_a^b |x(t)-z(t)|+|z(t)-y(t)|dt = \\int_a^b |x(t)-z(t)|+\\int_a^b |z(t)-y(t)|dt\\) (M1)~(M3) are obvious. (M4) \\(d(x,y)\\le d(x,z)+d(z,y)\\) since each term is \\(0\\) or \\(1\\) , the only case (M4) is false is \\(d(x,y)=1, d(x,z)=d(z,y)=0\\) . This means \\(x\\ne y, x=z, z=y\\) , which is impossible. Hence (M4) is true. \\(d\\) is a metric. \\(X=\\{(0,0,0),...(1,1,1)\\}, |X|=2^3=8\\) . \\(d(x,y)=\\sum |x_i-y_i|\\) . (M1)~(M3) are obvious. For (M4), \\(\\sum |x_i-y_i|\\le\\sum(|x_i-z_i|+|z_i-y_i|)=\\sum|x_i-z_i|+\\sum|z_i-y_i|\\) \\[\\begin{aligned} d(x_1,x_n)\\le &d(x_1,x_2)+d(x_2,x_n)\\\\ &d(x_1,x_2)+d(x_2,x_3)+d(x_3,x_n)\\\\ &\\dots\\\\ &d(x_1,x_2)+d(x_2,x_3)+\\dots+d(x_{n-1},x_n) \\end{aligned}\\] \\(|d(x,y)-d(z,w)|\\le d(x,z)+d(y,w)\\) ? WLOG, \\(d(x,y)\\ge d(z,w)\\) , then the question becomes \\(d(x,y)\\le d(x,z)+d(z,w)+d(w,y)\\) , which is true by triangle inequality. It is enough to consider \\(d(x,z)-d(y,z)\\ge0\\) . Then the inequality is \\(d(x,z)\\le d(x,y)+d(y,z)\\) , which is the triangle inequality. \\(d(x,y)\\le d(z,x)+d(z,y)\\) and \\(d(x,y)=0 \\iff x=y\\) . (M3) With \\(z=y\\) , we have \\(d(x,y)\\le d(y,x)\\) . Swapping \\(x\\) and \\(y\\) , we have \\(d(y,x)\\le d(x,y)\\) . Hence \\(d(x,y)=d(y,x)\\) . (M4) \\(d(x,y)\\le d(z,x)+d(z,y)=d(x,z)+d(z,y)\\) . Putting \\(x=y\\) into \\(d(x,y)\\le d(x,z)+d(z,y)\\) , we have \\(0\\le d(x,z)\\) for all \\(x, z\\) .","title":"1.1. Metric Space"},{"location":"kreyszig/ch1/#12-further-examples-of-metric-spaces","text":"\\(d(x,y)=\\sum_{j=1}^\\infty \\mu_j \\frac{|x_j-y_j|}{1+|x_j-y_j|}, \\sum\\mu_j<\\infty, \\mu_j>0\\) (M1) \\(d(x,y)<\\sum \\mu_j <\\infty\\) . (M2, M3) obvious (M4) The same proof from 1.2-1 applies here too. ( \\(f(t)=\\frac{t}{1+t}, \\cdots\\) ) With \\(\\alpha=\\sqrt a, \\beta=\\sqrt b, p=2, q=2\\) , we have \\(\\alpha\\beta\\le \\frac{\\alpha^p}{p}+\\frac{\\beta^q}{q}\\Longrightarrow \\sqrt{ab}\\le\\frac{a+b}{2}\\) . Setting \\(b_i=1\\) , (11) becomes \\((\\sum|a_i|)^2\\le\\sum|a_i|^2\\) . Let \\(x_n=1/\\log n\\) . Then \\(\\lim_{n\\to\\infty} x_n=0\\) . Given \\(p\\) , there exists \\(m\\) such that \\(\\forall n\\ge m, \\log^pn<n\\) . Thus \\[\\begin{aligned} \\sum|x_n|^p =\\sum_{n=1}^\\infty \\frac{1}{\\log^p n} &> \\sum_{n=m}^\\infty \\frac{1}{\\log^p n}\\\\ &> \\sum_{n=m}^\\infty \\frac{1}{n}=\\infty \\end{aligned}\\] \\(\\therefore x\\notin l^p\\) . \\(x_n=1/n\\) , then \\(\\sum 1/n=\\infty\\Longrightarrow x\\notin l^1, \\sum1/n^p<\\infty\\Longrightarrow x\\in l^2\\) . These can be easily shown by integrals and lower, upper bounds. If \\(\\delta(A)=\\infty\\) , for any \\(\\delta_0>0, \\exists x,y\\in A, d(x,y)>\\delta_0\\) , this means \\(\\delta(B)\\ge\\delta_0\\) , hence \\(\\delta(B)=\\infty\\) . Now assume \\(\\delta(A)<\\infty\\) . Also assume \\(A\\sub B, \\delta(A)>\\delta(B)\\) . For any \\(\\epsilon>0\\) , there must be \\(x,y\\in A\\) such that \\(d(x,y)>\\delta(A)-\\epsilon\\) . Since \\(x,y\\in B\\) , \\(\\delta(B)\\ge d(x,y)>\\delta(A)-\\epsilon\\) . Hence \\(\\delta(B)\\ge \\delta(A)\\) . \\(\\delta(A)=0\\Longrightarrow d(x,y)\\le 0\\Longrightarrow x=y\\Longrightarrow |A|\\le 1\\) . If \\(|A|=0, \\delta(A)=-\\infty\\) , hence \\(|A|=1\\) . Conversely, \\(|A|=1\\Longrightarrow \\delta(A)=0\\) . For distinct \\(x,y\\in X\\) , \\(D(\\{x\\},\\{x,y\\})=0\\) but \\(\\{x\\}\\ne\\{x,y\\}, \\therefore\\) D is not a metric. \\(D\\) can be a metric if \\(A=\\varnothing\\) or \\(B=\\varnothing\\) . \\(A\\cap B\\ne \\varnothing\\Longrightarrow\\exists x\\in A\\cap B\\Longrightarrow D(A,B)=D(\\{x,\\dots\\},\\{x,\\dots\\})=0\\) . The converse is not true. Let \\(A=[0,3], B=(3,6]\\) , then \\(D(A,B)=0\\) but \\(A\\cap B=\\varnothing\\) . It is enough to prove \\(D(x,B)-D(y,B)\\le d(x,y)\\) . For \\(\\forall b\\in B\\) , \\[\\begin{aligned}&D(x,B)\\le d(x,b)\\le d(x,y)+d(y,b)\\\\ \\Longrightarrow &D(x,B)-d(x,y)\\le d(y,b) \\\\ \\Longrightarrow &D(x,B)-d(x,y) \\text{ is a lower bound of d(y,b)} \\\\ \\Longrightarrow &D(x,B)-d(x,y)\\le D(y,B) \\\\ \\Longrightarrow &D(x,B)-D(y,B)\\le d(x,y) \\end{aligned}\\] (M1)~(M3) are obvious. (M4) Let \\(f(t)=t/(1+t)\\) . It is shown in 1.2-1 that \\(f\\) is increasing. From \\(d(x,y)\\le d(x,z)+d(z,y)\\) , \\[\\begin{aligned} f(d(x,y))&\\le f(d(x,z)+d(z,y)) \\\\ \\frac{d(x,y)}{1+d(x,y)}&\\le \\frac{d(x,z)+d(z,y)}{1+d(x,z)+d(z,y)}\\\\ &=\\frac{d(x,z)}{1+d(x,z)+d(z,y)}+\\frac{d(z,y)}{1+d(x,z)+d(z,y)}\\\\ &\\le\\frac{d(x,z)}{1+d(x,z)}+\\frac{d(z,y)}{1+d(z,y)} \\end{aligned}\\] Also \\(0\\le f(t)\\le 1\\) , so \\(X\\) is bounded. Let \\(a_0\\in A, b_0\\in B\\) . For any \\(a\\in A, b\\in B\\) , \\[\\begin{aligned} d(a,b)&\\le d(a,a_0)+d(a_0,b_0)+d(b_0,b)\\\\ &\\le\\delta(A)+d(a_0,b_0)+\\delta(B)\\\\ &<\\infty \\end{aligned}\\] \\(\\therefore A\\cup B\\) is bounded. (M1)~(M3) are obvious. (M4) \\[\\begin{aligned} d(x,y)&=d_1(x_1,y_1)+d_2(x_2,y_2)\\\\ &\\le d_1(x_1,z_1)+d_1(z_1,y_1)+d_2(x_2,z_2)+d_2(z_2,y_2)\\\\ &=d(x,z)+d(z,y) \\end{aligned}\\] (M1)~(M3) are clear. (M4) \\(\\tilde d(x,y)\\le \\tilde d(x,z)+\\tilde d(z,y)\\) can be written as \\(|a+bi|\\le|c+di|+|e+fi|\\) with \\(a\\le c+e, b\\le d+f\\) . \\[\\begin{aligned} |a+bi|\\le|(c+e)+(d+f)i|&=|c+di+e+fi|\\\\ &\\le|c+di|+|e+fi| \\end{aligned}\\] the last inequality holds because \\(\\mathbb C\\) is a metric space. \\[\\begin{aligned}\\tilde{\\tilde{\\kern{-0.3ex}d}}(x,y)&=\\max(d_1(x_1,y_1),d_2(x_2,y_2))\\\\ &=\\max(xy1, xy2)\\\\ &=\\max(xz1+zy1,xz2+zy2)=\\triangle \\end{aligned}\\] ( \\(xy1\\) represents \\(d_1(x_1,y_1)\\) for convenience) We want to prove \\(\\triangle\\le \\max(xz1, xz2)+\\max(zy1,zy2)\\) . This is equivalent to show \\(\\max(a+b,c+d)\\le \\max(a,c)+\\max(b,d)\\) . \\[\\begin{aligned} \\max(a+b,c+d)&\\le\\max(\\max(a,c)+b,\\max(a,c)+d)\\\\ &\\le\\max(\\max(a,c)+\\max(b,d),\\cdots)\\\\ &\\le\\max(a,c)+\\max(b,d) \\end{aligned}\\]","title":"1.2. Further Examples of Metric Spaces"},{"location":"kreyszig/ch1/#13-open-set-closed-set-neighborhood","text":"(a) For any \\(x\\in B(x_0,r)\\) , define \\(B'=\\{y|d(x,y)<r-d(x,x_0)>\\}\\) . Since \\(d(x_0,y)\\le d(x,y)+d(x,x_0)<r\\) , \\(B'\\sub B\\) . \\(\\therefore B\\) is an open set. (b) Let a closed ball \\(\\tilde B(x_0,r)\\) . Then \\(\\tilde B^c = {p|d(p,x_0)>r}. For any point \\) x\\in\\tilde B^c \\(, let \\) B_x=B(x, d(x,x_0)-r) \\(. A point \\) y\\in B_x \\( is not in \\) B \\( because \\) r<d(x,x_0)-d(x,y)\\le d(x,y)+d(y,x_0)-d(x,y)=d(x_0,y) \\(. \\) \\therefore B_x \\in \\tilde B^c \\(, so \\) x \\( is an internal point of \\) \\tilde B^c \\(, hence \\) B^c \\( is open, and \\) B$ is closed. An open ball in \\(\\R\\) is an open interval. An open ball in \\(\\mathbb C\\) is a filled circle without boundary in the complex plane. An open ball \\(B(x_0,r) \\) in \\(C[a,b]\\) is a set of functions \\(x\\) whose the value at \\(t\\in[a,b]\\) satisfies \\(|x(t)-x_0(t)|\\le r\\) . In other words, \\(x_0(t)-r\\le x(t)\\le x_0(t)+r\\) . We need to find the smallest \\(r\\) such that \\(\\forall t |\\cos t-\\sin t|\\le r\\) . Equivalently, find the maximum \\(\\cos t + \\sin t\\) where \\(t\\in [0,\\pi/4]\\) , or, \\(\\max f(x)\\) where \\(f(x)=x+\\sqrt{1-x^2}, x\\in[0,1]\\) . \\(f'(x)=1+\\frac{-2x}{2\\sqrt{1-x^2}}=0\\Longrightarrow x=\\frac{1}{\\sqrt 2}\\) . Therefore \\(t\\) is \\(0\\degree, 45\\degree, 90\\degree\\) . Trying these values, we have \\(\\max(\\cos t + \\sin t)=\\sqrt 2\\) . If a non-empty set \\(A\\) is open, each point \\(a\\in A\\) has a ball \\(B_a\\sub A\\) . Let \\(B=\\cup_a B_a\\) , then \\(B\\sub A\\) . Also \\(A\\sub B\\) because every \\(a\\in A\\) , \\(a\\in B_a\\sub B\\) . Hence \\(A=B\\) , and \\(A\\) is an union of open balls. Conversely if \\(A\\) is an union of open balls, it is open (by what we learned). (a) \\(\\varnothing\\) is open because it has no member and we can say all members are internal points. \\(X\\) is open because any neighborhood is in \\(X\\) . \\(\\varnothing, X\\) are closed because their complements are open. (b) For a subset \\(Y\\sub X\\) , \\(Y\\) is open because for \\(y\\in Y, B(y,0.5)=\\{y\\}\\sub Y\\) . Since every subset is open, \\(Y^c\\) is open, hence \\(Y\\) is closed. Suppose a neighborhood \\(N\\) of \\(x_0\\) contains finitely many points of \\(A\\) . Let \\(d_0=\\min_{a\\in N\\cap A} d(x_0, a)\\) . Then it contradicts that \\(B(x_0, d_0/2)\\) should contain at least one point of \\(A\\) . (a) \\(\\N=\\overline \\N\\) on \\(\\R\\) (b) \\(\\overline\\mathbb Q=\\R\\) on \\(\\R\\) (c) \\(\\overline{\\mathbb Q \\times \\mathbb Q}=\\R\\times\\R\\) (d) \\(\\overline{\\{z\\mid \\lvert z\\rvert<1\\}}=\\{z\\mid\\lvert z\\rvert \\le 1\\}\\) on \\(C\\) Let \\(X=\\{0,1\\}\\) . Then \\(B(0;1)=\\{0\\}, \\overline{B(0;1)}=\\{0\\}\\) , but \\(\\tilde B(0;1)=\\{0,1\\}\\) . \\(A\\sub \\overline A = A\\cup\\{\\text{accumulation points}\\}\\) \\(\\overline A=\\overline{\\overline A}\\) : We have \\(\\overline A\\sub \\overline {\\overline A}\\) . For the converse, suppose the contrary, so \\(\\exists a\\in \\overline{\\overline A}, a\\notin \\overline A\\) . Since \\(a\\) is not an accumulation point of \\(A\\) , but of \\(\\overline A\\) , \\(\\exists \\epsilon_0>0, B(a,\\epsilon_0)\\cap A-\\{a\\}=\\varnothing\\) \\(\\forall \\epsilon>0, B(a,\\epsilon)\\cap \\overline A - \\{a\\}\\neq \\varnothing\\) Let \\(a'\\in B(a,\\epsilon_0/2)\\cap \\overline A-\\{a\\}\\) , then \\(a'\\in \\overline A-A\\) so \\(a'\\) is an accumulation point of \\(A\\) . \\(\\forall \\epsilon>0, B(a', \\epsilon)\\cap A-\\{a'\\}\\neq \\varnothing\\) with \\(\\epsilon=\\epsilon_0/2\\) , \\(\\exists a''\\in B(a', \\epsilon_0/2)\\cap A-\\{a'\\}\\) \\(d(a'',a')<\\epsilon_0/2, d(a',a)<\\epsilon_0/2, d(a'',a)<\\epsilon_0/2\\) Also \\(a''\\neq a\\) because \\(a''\\in A, a\\in \\overline A\\) . This contradicts to \\(a'' \\in B(a,\\epsilon_0)\\cap A-\\{a\\}\\) . Therefore such \\(a\\) does not exist, and \\(\\overline{\\overline A}=A\\) . \\(\\overline{A\\cup B}=\\overline A\\cup \\overline B\\) : suppose \\(x\\in \\overline{A\\cup B}, x\\notin \\overline A, x\\notin \\overline B\\) . Then \\(\\exists \\epsilon>0\\) , \\(B(x,\\epsilon)\\cap A\\sub\\{x\\}\\) , \\(B(x,\\epsilon)\\cap B\\sub \\{x\\}\\) , but \\(B(x,\\epsilon)\\cap(A\\cup B)\\not\\subset \\{x\\}\\) , which contradicts. Hence \\(\\overline{A\\cup B}\\sub (\\overline A\\cup \\overline B)\\) . Now suppose \\(x\\in \\overline A\\) but \\(x\\notin \\overline{A\\cup B}\\) . \\(\\forall \\epsilon>0, B(x,\\epsilon)\\cap A-\\{x\\}\\neq\\varnothing, B(x,\\epsilon)\\cap(A\\cup B)-\\{x\\}\\neq \\varnothing\\) , \\(x\\) is an accumulation point of \\((A\\cup B)\\) . Therefore the converse is also true. \\(\\overline{A\\cap B}\\sub \\overline A\\cap \\overline B\\) if \\(x\\in A\\cap B\\) , then \\(x\\in A\\sub \\overline A, x\\in B\\sub \\overline B\\Longrightarrow x\\sub \\overline A\\cap \\overline B\\) . If \\(x\\in \\overline{A\\cap B}\\) , \\(\\forall \\epsilon>0, B(x,\\epsilon)\\cap(A\\cap B)-\\{x\\}\\neq\\varnothing, B(x,\\epsilon)\\cap A-\\{x\\}\\neq\\varnothing\\) and \\(B(x,\\epsilon)\\cap B-\\{x\\}\\neq\\varnothing\\) , hence \\(x\\) is in \\(\\overline A\\) and \\(\\overline B\\) , and \\(x\\in \\overline A\\cap \\overline B\\) . Conversely suppose \\(x\\in \\overline A\\cap \\overline B\\) . If \\(x\\in A\\cap B\\) then \\(x\\in \\overline{A\\cap B}\\) . If \\(x\\notin A, x\\in B\\) , then \\(B(x,\\epsilon)\\cap A-\\{x\\}\\neq\\varnothing, B(x,\\epsilon)\\cap B-\\{x\\}\\neq\\varnothing, B(x,\\epsilon)\\cap (A\\cap B)-\\{x\\}\\neq\\varnothing, (\\overline A\\cap \\overline B)\\not\\sub\\overline{A\\cap B}\\) . Hence \\(\\overline{A\\cap B}\\not\\sub\\overline A\\cap\\overline B\\) . \\(x\\in A \\Longrightarrow d(x,x)=0 \\Longrightarrow D(x,A)=0\\) , \\(x\\notin A\\Longrightarrow \\forall \\epsilon>0, B(x,\\epsilon)\\cap A-\\{x\\}\\neq \\varnothing\\) If \\(D(x,A)=\\epsilon_0>0\\) let \\(a\\in B(x,\\epsilon_0)\\cap A-\\{x\\}\\) , then \\(d(x,a)<D(x,A)\\) which contradicts. \\(\\therefore x\\in \\overline A \\Longrightarrow D(x,A)=0\\) . For converse, \\(D(x,A)=0\\) . Then there exists a sequence in \\(A\\) that converges to \\(x\\) , hence \\(x\\in \\overline A\\) . (a) the boundary of \\((-1,1)\\Longrightarrow\\{-1,1\\}\\) \\([-1,1)\\Longrightarrow\\{-1,1\\}\\) \\([-1,1]\\Longrightarrow\\{-1,1\\}\\) (b) \\(\\mathbb Q\\sub\\R\\) : the boundary is \\(\\R\\) because any neighborhood has a point of \\(\\mathbb Q\\) and a point of \\(\\R\\) . (c) For both disks, the boundary is \\(\\{z\\mid \\lvert z\\rvert=1\\}\\) . \\(B[a,b]\\) is not separable: Consider a subset \\(F\\) , a set of functions \\(f(x)\\) such that \\(f(x)=0\\) if \\(a\\le x<t\\) , 1 if \\(t\\le x\\le b\\) , for \\(a<t<b\\) . \\(F\\) is uncountable and \\(B(f,1/2)=\\{f\\}\\) for \\(f\\in F\\) . If \\(B[a,b]\\) has any dense subset \\(A\\) , disjoint and uncountably many neighbors \\(B(f,1/2)\\) should contain a point of \\(A\\) , which makes \\(A\\) uncountable. \\(X\\) is separable \\(\\iff\\) \\(X\\) has a countable dense subset \\(\\iff\\) \\(X\\) has a countable subset \\(Y\\) such that \\(\\forall \\epsilon>0, \\forall x\\in X, \\exists y\\in Y, d(x,y)<\\epsilon\\) . The interpretation is that for any point \\(x\\) , there exists a sequence of \\((y_n)\\) that converges to \\(x\\) . Show \u2460 \\(T:X\\Longrightarrow Y\\) is continuous \\(\\iff\\) \u2461 \\(T^{-1}(M)\\) is closed in \\(X\\) . \u2460 to \u2461: \\(T^{-1}(M^c)=(T^{-1}(M))^c\\) . If \\(M\\) is closed, \\(M^c\\) is open, and by \u2460, \\(T^{-1}(M^c)\\) is open. Since \\((T^{-1}(M))^c\\) is open, \\(T^{-1}(M)\\) is closed. \u2461 to \u2460: If \\(M\\) is open, \\(M^c\\) is closed, and by \u2461, \\(T^{-1}(M^c)=(T^{-1}(M))^c\\) is closed, so \\(T^{-1}(M)\\) is open. \\(cos(x)\\) on \\((-2\\pi,2\\pi)\\) has an open domain but the range \\([-1,1]\\) is closed.","title":"1.3. Open Set, Closed Set, Neighborhood"},{"location":"kreyszig/ch1/#14-convergence-cauchy-sequence-completeness","text":"If \\((x_n)\\) converges to a limit \\(x\\) , \\(\\forall \\epsilon>0, \\exists N>0, \\forall n>N, d(x_n,x)<\\epsilon\\) , then for any \\((x_{n_k})\\) , \\(\\forall\\epsilon>0, \\exists K>0, \\forall k>K, d(x_{n_k}, x)<\\epsilon\\) , therefore \\(x_{n_k}\\longrightarrow x\\) \\((x_n)\\) is Cauchy and \\(x_{n_k}\\longrightarrow x\\) , then \\(\\forall \\epsilon>0\\) , - \\(\\exists K>0, \\forall k>K, d(x_{n_k},x)<\\epsilon/2\\) - \\(\\exists N>0, \\forall n,m>K, d(x_n,x_m)<\\epsilon/2\\) - Then \\(\\forall n>max(N,n_k), \\exists i, n_i>n\\) , and \\(d(x_n,x)\\le d(x_n,x_{n_i})+d(x_{n_i},x)<\\epsilon/2+\\epsilon/2=\\epsilon\\) . Hence \\((x_n)\\) converges to \\(x\\) . \\((x_n)\\longrightarrow x\\) is equivalent to \\(\\forall V=n(x), \\exists n_0, \\forall n>n_0, x_n\\in V\\) ( \\(\\Longrightarrow\\) ): for a neighborhood \\(V\\) , \\(\\exists r, B_r(x)\\sub V\\) , there exists \\(N\\) such that \\(\\forall n>N, d(x_n,x)<r\\) , hence \\(x_n\\in B_r(x)\\sub V\\) . ( \\(\\Longleftarrow\\) ): For any \\(\\epsilon>0\\) and \\(B_\\epsilon (x)\\) , there exists \\(n_0\\) such that \\(x_n\\in B_\\epsilon(x) \\Longrightarrow d(x_n,x)<\\epsilon\\) for all \\(n>n_0\\) . Hence \\((x_n)\\longrightarrow x\\) . \\(\\exists N, \\forall n,m\\ge N, d(x_n,x_m)<1\\Longrightarrow \\forall n\\ge N, d(x_n,x_N)<1\\) . Hence \\(x_N,x_{N+1},..\\) are bounded. Also \\(x_1, x_2, .. x_{N-1}\\) are finite, so bounded. No. A counter example is \\(x_n=\\sin n\\) . We will show that \\((a_n)\\) is Cauchy, then since \\(\\R\\) is complete, \\((a_n)\\) converges. For any \\(\\epsilon>0, \\exists N, \\forall n,m>N, d(x_n,x_m)<\\epsilon/4\\) and \\(d(y_n,y_m)<\\epsilon/4\\) . Then \\(|a_n-a_m|=|d(x_n,y_n)-d(x_m,y_m)|\\le d(x_n,x_m)+d(y_n,y_m)<\\epsilon/2\\) . Hence \\((a_n)\\) is Cauchy, thus convergent. 1.4-2 (b) has a stronger condition than Prob 6, hence 1.4-2 (b) is true. If \\((x_n)\\) is Cauchy in \\((X,d_1)\\) , for \\(\\epsilon>0\\) and large enough \\(n,m\\) , we have \\(d_1(x_n,x_m)<b\\epsilon\\) , or, \\(d_2(x_n,x_m)<\\epsilon\\) . Hence \\((x_n)\\) is Cauchy in \\((X,d_2)\\) . In the same way, a cauchy seq in \\((X,d_2)\\) is Cauchy in \\((X,d_1)\\) . It can be easily shown that \\(\\tilde{\\tilde{\\kern{-0.3ex}d}}\\le \\tilde d\\le d\\le 2*\\tilde{\\tilde{\\kern{-0.3ex}d}}\\) . Consider a Cauchy sequence \\(c_n=(a_n+i b_n)\\) in \\(\\mathbb C\\) , where \\(a_n,b_n\\in \\R\\) . Then for any \\(\\epsilon>0\\) and large enough \\(n\\) and \\(m\\) , \\(d(a_n,a_m)\\le d(c_n,c_m)<\\epsilon, d(b_n,b_m)\\le d(c_n,c_m)<\\epsilon\\) , hence \\((a_n)\\) and \\((b_n)\\) are Cauchy. Since \\(\\R\\) is complete, \\((a_n)\\longrightarrow a, (b_n)\\longrightarrow b\\) . Again, for any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(d(a_n,a)<\\epsilon/2, d(b_n,b)=d(i b_n, i b)<\\epsilon/2\\) , hence \\(d(c_n,a+bi)<\\epsilon\\) , \\((c_n)\\longrightarrow a+bi\\) , \\(\\mathbb C\\) is complete.","title":"1.4. Convergence, Cauchy Sequence, Completeness"},{"location":"kreyszig/ch1/#15-examples-completeness-proofs","text":"Since \\(\\R\\) is complete, a subset is complete iff it is complete. Hence \\((a,b)\\) is incomplete and \\([a,b]\\) is complete. Consider a Cauchy \\((x^(1),x^(2),\\dots)\\) . For any \\(\\epsilon\\) and large enough \\(n,m\\) , \\(d(x^{(n)},x^{(m)})<\\epsilon\\Longrightarrow \\forall j, |x_j^{(n)}-x_j^{(m)}|<\\epsilon\\) . For a fixed \\(j\\) , (x^{(n)}_j) is Cauchy. Since \\(\\R\\) is complete, \\(x^{(n)}_j\\) converges, and let the limit point \\(x_j\\) , and let \\(x=(x_n)\\) . Note that \\(x\\in X\\) . For any \\(\\epsilon>0\\) and large enough \\(n,m\\) , \\(\\forall j |x_j^n-x_j|\\le \\epsilon\\Longrightarrow d(x^n,x)\\le \\epsilon\\) , and \\(x^n\\) converges to \\(x\\) . Since any Cauchy converges, \\(X\\) is compelte. Let \\(x_1=(1,0,0,\\dots), x_2=(1,1/2,0,0,\\dots), x_3=(1,1/2,1/4,0,0,\\dots), \\dots\\) . The sequence \\((x_1,x_2,\\dots)\\) converges to \\((1,1/2,1/4,1/8,\\dots)\\) but this has infinitely many zeros, therefore this is not in \\(M\\) . Hence \\(M\\) is not complete. The previous example converges to a point not in \\(M\\) , hence \\(M\\) is not closed, Since \\(l^\\infty\\) is complete, \\(M\\) is not complete. Consider a Cauchy \\((x_n)\\) . For \\(\\epsilon=0.5\\) and large enough \\(n,m\\) , \\(|x_n-x_m|<1\\) , which means \\(x_n=x_m\\) and the sequence is eventually constant and convergent. Hence \\(X\\) is complete. \\((x_n=n)\\) is Cauchy. Suppose this sequence converges to \\(x\\) . For large enough \\(n\\) , \\(x_n>x\\Longrightarrow \\arctan(x_n)>\\arctan(x)\\) , so it cannot converge. Hence the space is incomplete. Similar to 6, \\((x_n=n)\\) is Cauchy but it does not converge. \\(C[a,b]\\) is complete. We will show \\(Y\\) is closed. Consider \\((y_n)\\longrightarrow y\\) and suppose \\(y\\notin Y\\) . Then \\(y(a)\\neq y(b)\\) and for any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(|y_n(a)-y(a)|<\\epsilon/2, |y_n(b)-y(b)|<\\epsilon/2, |y(a)-y(b)|<\\epsilon\\) , which implies \\(y(a)=y(b)\\) , a contradiction. Hence \\(Y\\) is closed and complete. \\((x_m)\\in C[a,b], (x_m)\\Longrightarrow x\\) . For any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(d(x_n,x)<\\epsilon\\Longrightarrow |x_n(t)-x(t)|<\\epsilon\\) . Since \\(x_n\\) is continuous, for any \\(\\epsilon_2>0\\) there exists \\(\\delta>0\\) , \\(|t_1-t_2|<\\delta\\Longrightarrow |x_n(t_1)-x_n(t_2)|<\\epsilon_2\\) . Then for \\(t_1,t_2\\in [a,b]\\) such that \\(|t_1-t_2|<\\delta, |x(t_1)-x(t_2)|\\le|x(t_1)-x_n(t_1)|+|x_n(t_1)-x_n(t_2)|+|x_n(t_2)-x(t_2)|<\\epsilon+\\epsilon_2+\\epsilon\\) . Since \\(\\epsilon\\) and \\(\\epsilon_2\\) were chosen arbitrarily, \\(x\\) is continuous. Any Cauchy sequence in a discrete metric space is eventually constant (use \\(\\epsilon=0.5\\) ), and converges to the constant. Hence discrete metric spaces are complete. Suppose \\(x_n\\longrightarrow x\\) . Then for any \\(\\epsilon>0\\) and large enough \\(n\\) , \\(d(x_n,x)=\\sum_j \\frac{1}{2^j} \\frac{|x_j^{(n)}-x_j|}{|x_j^{(n)}-x_j|+1}<\\epsilon\\) . Since all terms are positive, \\(\\frac{|x_j^{(n)}-x_j|}{|x_j^{(n)}-x_j|+1}<2^j \\epsilon\\) . Let \\(f(t)=\\frac{t}{1+t}\\) . \\(f\\) is continuous and increasing. \\(f(|x_j^{(n)}-x_j|)<2^j\\epsilon\\) implies \\(x_j^{(n)}\\longrightarrow x_j\\) . (why?) Consider a Cauchy \\((x^{(m)})\\) . For any \\(\\epsilon>0\\) and large enough \\(n,m\\) , \\(d(x^{(n)},x^{(m)})<\\epsilon\\Longrightarrow f(|x_j^{(n)}-x_j^{(m)}|)<2^j \\epsilon\\Longrightarrow |x_j^{(n)}-x_j^{(m)}|<f^{-1}(2^j\\epsilon)\\) . For a fixed \\(j\\) and any \\(\\epsilon_2>0\\) , there exists \\(\\epsilon_0\\) such that \\(f^{-1}(2^j\\epsilon_0)<\\epsilon_2\\) . With \\(\\epsilon=\\epsilon_0\\) in the previous inequality, \\(|x_j^{(n)}-x_j^{(m)}|<f^{-1}(2^j\\epsilon_0)<\\epsilon_2\\) , hence \\(x_j^{(n)}\\) is Cauchy. This sequence converges to \\(x_j\\) because \\(\\R\\) is complete. By Problem 11, \\(x^{(n)}\\Longrightarrow x\\) . Therefore \\(s\\) is complete. With \\(n<m\\) , \\(d(x_n,x_m)=\\int_{m^{-2}}^{n^{-2}}(t^{-1/2}-t)dt=[2t^{1/2}-1/2 t^2]_{m^{-2}}^{n^{-2}}=2(n^{-1}-m^{-1})-1/2(n^{-4}-m^{-4})<2(n^{-1}-m^{-1})<2n^{-1}\\) . Thus for any \\(epsilon>0\\) , choose \\(n\\) such that \\(2n^{-1}<\\epsilon\\) , then \\(d(x_n,x_m)<\\epsilon)\\) . Hence \\((x_n)\\) is Cauchy. \\((x_n)\\) converges to \\(x(t)=t^{-1/2}\\) for \\(t>0\\) , but \\(x(0)=0\\) . Hence \\(x\\) is not continuous at \\(t=0\\) and \\(x\\) is not in the space. \\(d(x_n,x_m)=\\frac{1}{(n+1)^2}+\\frac{1}{(n+2)^2}+\\dots+\\frac{1}{m^2}\\le \\int_{n+1}^{m+1} \\frac{1}{t^2} dt = [-1/t]^{m+1}_{n+1}=\\frac{1}{n+1}-\\frac{1}{m+1}<\\frac{1}{n+1}\\) . Therefore for \\(n,m>1/\\epsilon, d(x_n,x_m)<\\frac{1}{n+1}<\\frac{1}{n}<\\epsilon\\) , Hence this is Cauchy. Suppose this converges to \\(x\\) . Let \\(k\\) the index ofo the last nonzero element of \\(x\\) . Then for \\(n>k, d(x,x_n)>\\frac{1}{(k+1)^2}+\\frac{1}{(k+2)^2}+\\dots+\\frac{1}{n^2}\\) . Hence \\(d(x,x_n)>\\frac{1}{(k+1)^2}\\) and \\((x_n)\\) does not converge to \\(x\\) .","title":"1.5. Examples, Completeness Proofs"},{"location":"kreyszig/ch1/#16-completion-of-metric-spaces","text":"Let \\(d_m=\\min_{a,b\\in Y, a\\neq b} d(a,b)\\) . This exists because \\(Y\\) is finite. Also \\(d_m>0\\) . For any Cauchy sequence \\((x_n)\\) , with \\(\\epsilon=d_m/2\\) and large enough \\(n,m\\) , \\(d(x_n,x_m)<d_m/2\\) . The only possible distance smaller than \\(d_m\\) is \\(0\\) , hence \\(x_n=x_m\\) , therefore \\((x_n)\\) converges to a constant in \\(Y\\) . This proves \\(Y\\) is complete. The completion of \\((\\mathscr Q,d)\\) is \\((\\R, d')\\) where \\(d'(x,y)=|x-y|\\) . A discrete metric space is already complete. Let \\(T\\) a bijective isometry from \\(X_1\\) onto \\(X_2\\) . Consider a Cauchy sequence \\((y_n)\\) in \\(X_2\\) . Then \\((T^{-1} y_n)\\) is Cauchy in \\(X_1\\) because \\(d'(y_n,y_m)<\\epsilon\\longrightarrow d(T^{-1}y_n,T^{-1}y_m)<\\epsilon\\) . This converges to \\(x\\) in \\(X_1\\) because \\(X_1\\) is complete. Then \\(d(T^{-1}y_n,x)<\\epsilon\\longrightarrow d'(y_n,Ty_n)<\\epsilon\\) , hence \\(y_n\\) converges to \\(Tx\\) . This proves \\(X_2\\) is complete. 5. (a) Let \\(T\\) a bijective isometry from \\(X\\) onto \\(Y\\) . It is continuous. (for any \\(\\epsilon>0\\) , \\(\\delta=\\epsilon\\) ) The inverse is also continuous (for any \\(\\epsilon>0\\) , \\(\\delta=\\epsilon\\) ). Hence \\(T\\) is a homeomorphism. (b) \\(\\arctan\\) maps from \\((-\\infty,\\infty)\\) (complete) to \\((-\\pi/2,\\pi/2)\\) (incomplete). The function is bijective, and both the forward and inverse are continuous, hence \\(\\arctan\\) is a homeomorphism. Define \\(T:C[a,b]\\longrightarrow C[0,1], T(f)(x)=f((b-a)x+a)\\) . Then for \\(f,g\\in C[a,b]\\) , \\[\\begin{aligned} &d'(Tf,Tg) \\\\ &=\\sup |Tf(t)-Tg(t)|, t\\in[0,1] \\\\ &=\\sup |f((b-a)t+a)-g((b-a)t+a)|, t\\in[0,1] \\\\ &=\\sup |f(x)-g(x)|, x\\in[a,b] \\\\ &=d(f,g) \\end{aligned}\\] where \\(C[a,b]\\) is equipped with \\(d\\) and \\(C[a,b]\\) is equipped with \\(d'\\) . \\(T\\) is bijective, hence \\(C[a,b]\\) and \\(C[0,1]\\) are isomorphic. 7.","title":"1.6. Completion of Metric Spaces"},{"location":"kreyszig/ch2/","text":"2. Normed Spaces. Banach Spaces 2.1. Vector Space 2.2. Normed Space. Banach Space 2.3. Further Properties of Normed Spaces 2.4. Finite Dimensional Normed Spaces and Subspaces 2.5. Compactness and Finite Dimension 2.6. Linear Operators 2.7. Bounded and Continuous Linear Operators 2.8. Linear Functionals 2.9. Linear Operators and Functionals on Finite Dimensional Spaces 2.10. Normed Spaces of Operators. Dual Space","title":"2. Normed Spaces. Banach Spaces"},{"location":"kreyszig/ch2/#2-normed-spaces-banach-spaces","text":"","title":"2. Normed Spaces. Banach Spaces"},{"location":"kreyszig/ch2/#21-vector-space","text":"","title":"2.1. Vector Space"},{"location":"kreyszig/ch2/#22-normed-space-banach-space","text":"","title":"2.2. Normed Space. Banach Space"},{"location":"kreyszig/ch2/#23-further-properties-of-normed-spaces","text":"","title":"2.3. Further Properties of Normed Spaces"},{"location":"kreyszig/ch2/#24-finite-dimensional-normed-spaces-and-subspaces","text":"","title":"2.4. Finite Dimensional Normed Spaces and Subspaces"},{"location":"kreyszig/ch2/#25-compactness-and-finite-dimension","text":"","title":"2.5. Compactness and Finite Dimension"},{"location":"kreyszig/ch2/#26-linear-operators","text":"","title":"2.6. Linear Operators"},{"location":"kreyszig/ch2/#27-bounded-and-continuous-linear-operators","text":"","title":"2.7. Bounded and Continuous Linear Operators"},{"location":"kreyszig/ch2/#28-linear-functionals","text":"","title":"2.8. Linear Functionals"},{"location":"kreyszig/ch2/#29-linear-operators-and-functionals-on-finite-dimensional-spaces","text":"","title":"2.9. Linear Operators and Functionals on Finite Dimensional Spaces"},{"location":"kreyszig/ch2/#210-normed-spaces-of-operators-dual-space","text":"","title":"2.10. Normed Spaces of Operators. Dual Space"},{"location":"kreyszig/ch3/","text":"3. Inner Product Spaces. Hilbert Spaces 3.1. Inner Product Space. Hilbert Space 3.2. Further Properties of Inner Product Spaces 3.3. Orthogonal Complements and Direct Sums 3.4. Orthonormal Sets and Sequences 3.5. Series Related to Orthonormal Sequences and Sets 3.6. Total Orthonormal Sets and Sequences 3.7. Legendre, Hermite and Laguerre Polynomials 3.8. Representation of Functionals on Hilbert Spaces 3.9. Hilbert-Adjoint Operator 3.10. Self-Adjoint, Unitary and Normal Operators","title":"3. Inner Product Spaces. Hilbert Spaces"},{"location":"kreyszig/ch3/#3-inner-product-spaces-hilbert-spaces","text":"","title":"3. Inner Product Spaces. Hilbert Spaces"},{"location":"kreyszig/ch3/#31-inner-product-space-hilbert-space","text":"","title":"3.1. Inner Product Space. Hilbert Space"},{"location":"kreyszig/ch3/#32-further-properties-of-inner-product-spaces","text":"","title":"3.2. Further Properties of Inner Product Spaces"},{"location":"kreyszig/ch3/#33-orthogonal-complements-and-direct-sums","text":"","title":"3.3. Orthogonal Complements and Direct Sums"},{"location":"kreyszig/ch3/#34-orthonormal-sets-and-sequences","text":"","title":"3.4. Orthonormal Sets and Sequences"},{"location":"kreyszig/ch3/#35-series-related-to-orthonormal-sequences-and-sets","text":"","title":"3.5. Series Related to Orthonormal Sequences and Sets"},{"location":"kreyszig/ch3/#36-total-orthonormal-sets-and-sequences","text":"","title":"3.6. Total Orthonormal Sets and Sequences"},{"location":"kreyszig/ch3/#37-legendre-hermite-and-laguerre-polynomials","text":"","title":"3.7. Legendre, Hermite and Laguerre Polynomials"},{"location":"kreyszig/ch3/#38-representation-of-functionals-on-hilbert-spaces","text":"","title":"3.8. Representation of Functionals on Hilbert Spaces"},{"location":"kreyszig/ch3/#39-hilbert-adjoint-operator","text":"","title":"3.9. Hilbert-Adjoint Operator"},{"location":"kreyszig/ch3/#310-self-adjoint-unitary-and-normal-operators","text":"","title":"3.10. Self-Adjoint, Unitary and Normal Operators"},{"location":"lee/","text":"Lee Chapters Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Chapter 10 Chapter 11 Chapter 12 Chapter 13","title":"Lee"},{"location":"lee/#lee","text":"","title":"Lee"},{"location":"lee/#chapters","text":"Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Chapter 10 Chapter 11 Chapter 12 Chapter 13","title":"Chapters"},{"location":"lee/ch10/","text":"10. The Seifert-Van Kampen Theorem Statement of the Theorem Applications Fundamental Groups of Compact Surfaces Proof of the Seifert-Van Kampen Theorem Problems","title":"10. The Seifert-Van Kampen Theorem"},{"location":"lee/ch10/#10-the-seifert-van-kampen-theorem","text":"","title":"10. The Seifert-Van Kampen Theorem"},{"location":"lee/ch10/#statement-of-the-theorem","text":"","title":"Statement of the Theorem"},{"location":"lee/ch10/#applications","text":"","title":"Applications"},{"location":"lee/ch10/#fundamental-groups-of-compact-surfaces","text":"","title":"Fundamental Groups of Compact Surfaces"},{"location":"lee/ch10/#proof-of-the-seifert-van-kampen-theorem","text":"","title":"Proof of the Seifert-Van Kampen Theorem"},{"location":"lee/ch10/#problems","text":"","title":"Problems"},{"location":"lee/ch11/","text":"11. Covering Maps Definitions and Basic Properties The General Lifting Problem The Monodromy Action Covering Homomorphisms The Universal Covering Space Problemse","title":"11. Covering Maps"},{"location":"lee/ch11/#11-covering-maps","text":"","title":"11. Covering Maps"},{"location":"lee/ch11/#definitions-and-basic-properties","text":"","title":"Definitions and Basic Properties"},{"location":"lee/ch11/#the-general-lifting-problem","text":"","title":"The General Lifting Problem"},{"location":"lee/ch11/#the-monodromy-action","text":"","title":"The Monodromy Action"},{"location":"lee/ch11/#covering-homomorphisms","text":"","title":"Covering Homomorphisms"},{"location":"lee/ch11/#the-universal-covering-space","text":"","title":"The Universal Covering Space"},{"location":"lee/ch11/#problemse","text":"","title":"Problemse"},{"location":"lee/ch12/","text":"12. Group Actions and Covering Maps The Automorphism Group of a Covering Quotients by Group Actions The Classification Theorem Proper Group Actions Problems","title":"12. Group Actions and Covering Maps"},{"location":"lee/ch12/#12-group-actions-and-covering-maps","text":"","title":"12. Group Actions and Covering Maps"},{"location":"lee/ch12/#the-automorphism-group-of-a-covering","text":"","title":"The Automorphism Group of a Covering"},{"location":"lee/ch12/#quotients-by-group-actions","text":"","title":"Quotients by Group Actions"},{"location":"lee/ch12/#the-classification-theorem","text":"","title":"The Classification Theorem"},{"location":"lee/ch12/#proper-group-actions","text":"","title":"Proper Group Actions"},{"location":"lee/ch12/#problems","text":"","title":"Problems"},{"location":"lee/ch13/","text":"13. Homology Singular Homology Groups Homotopy Invariance Homology and the Fundamental Groups## The Mayer-Vietoris Theorem Homologyt of Spheres Homology of CW Complexes Cohomology Problems","title":"13. Homology"},{"location":"lee/ch13/#13-homology","text":"","title":"13. Homology"},{"location":"lee/ch13/#singular-homology-groups","text":"","title":"Singular Homology Groups"},{"location":"lee/ch13/#homotopy-invariance","text":"","title":"Homotopy Invariance"},{"location":"lee/ch13/#homology-and-the-fundamental-groups-the-mayer-vietoris-theorem","text":"","title":"Homology and the Fundamental Groups## The Mayer-Vietoris Theorem"},{"location":"lee/ch13/#homologyt-of-spheres","text":"","title":"Homologyt of Spheres"},{"location":"lee/ch13/#homology-of-cw-complexes","text":"","title":"Homology of CW Complexes"},{"location":"lee/ch13/#cohomology","text":"","title":"Cohomology"},{"location":"lee/ch13/#problems","text":"","title":"Problems"},{"location":"lee/ch2/","text":"2. Topological Spaces \\(\\gdef\\Int{\\operatorname{Int}}\\) \\(\\gdef\\Ext{\\operatorname{Ext}}\\) Note \\(A = \\Int A+ \\partial A + \\Ext A \\\\ = (\\text{limit point} + \\text{isolated point}) + \\Ext A\\) where \\(+\\) is a disjoint partition op boundary -> limit point, not isolated isolated -> int Topologies Ex 2.2 It can be easily seen that all examples satisfy (i)~(iii) in page 20. Ex 2.4 (a) For \"only if\", any open ball w.r.t \\(d\\) is an open set w.r.t \\(d'\\) , and any open set contains an open ball, hence there exists \\(r_1\\) . The same for \\(r_2\\) . For \"if\", Suppose a set \\(A\\) is open in \\((M,d)\\) . Any point \\(x\\in A\\) is internal point in \\((M,d)\\) and there exists \\(r\\) such that \\(B_r^{(d)}(x)\\sub A\\) . Since \\(B_{r_1}^{(d')}(x)\\sub A\\) , \\(x\\) is an internal point of \\(A\\) in \\((M,d')\\) . Hence \\(A\\) is open in \\((M,d')\\) . Conversely, any open set in \\((M,d')\\) is open in \\((M,d)\\) . Therefore two topologies are the same. (b) \\(B_r^{(d)}=B_{cr}^{(d')}\\) , so their open sets are the same, and generated topologies are the same. (c) \\(d'\\le d\\le nd'\\) . It can be proved using (a) that \\(d\\) and \\(d'\\) generate the same topology. (d) With the discrete metric, \\(B_{0.5}(x)=\\{x\\}\\) . These generate all possible subsets of \\(X\\) . (e) With the Euclidean metric, \\(B_{0.5}(x)=\\{x\\}\\) . These generate all possible subsets of \\(\\Z\\) . Ex 2.5 (1) \\(\\varnothing \\sub Y, Y \\sub Y\\) . (2) The set is closed under finite intersection because they were closed in \\(X\\) . (3) The set is closed under any union of arbitrarily many elements because they were closed in \\(X\\) . Ex 2.6 (1) All topologies have \\(\\varnothing\\) and \\(X\\) , hence \\({\\varnothing,X}\\sub \\mathscr T\\) . (2) \\(\\mathscr T\\) is closed under finite intersection, since its elements were the elements of \\(T_{\\alpha_0}\\) for some \\(\\alpha_0\\) , and their intersection existed in \\(T_{\\alpha_0}\\) . (3) The same as (2). Ex 2.9 TODO: Ex 2.10 By Proposition 2.8, a boundary point is a limit point. If a set contains all of its limit points, the set contains all boundary points, hence closed. Now suppose a set is closed. Any limit point of the set \\(A\\) is in \\(\\Int A\\) , \\(\\Ext A\\) , or \\(\\partial A\\) . The limit points in \\(\\Int A\\) are obviously in \\(A\\) . The limit points which are boundary points are in \\(A\\) because \\(A\\) is closed. \\(\\Ext A\\) cannot have a limit point because a point \\(x\\) in \\(\\Ext A\\) has a neighborhood in \\(X\\setminus A\\) , and the neighborhood has no point of \\(A\\) other than \\(x\\) , so \\(x\\) is not a limit point. Therefore \\(A\\) contains all of its limit points. Ex 2.11 Suppose \\(A\\) is dense in \\(X\\) and there is an non-empty open subset \\(B\\) of \\(X\\) that contains no point of \\(A\\) . \\(B\\) has at least one element, say \\(b\\) . Then \\(B\\) is a neighborhood of \\(b\\) and \\(B\\sub X\\setminus A\\) . By Proposition 2.8 (b), \\(b\\) is in \\(\\Ext A\\) . However, \\(\\Ext A\\) = \\(X\\setminus \\overline A = \\varnothing\\) , contradicts. Hence the statement is true. Conversely, suppose every non-empty open subset of \\(X\\) contains a point of \\(A\\) . Then by definition any point of \\(X\\) is a limit point of \\(A\\) . Since \\(\\overline A\\) is closed, using Exercise 2.10, \\(\\overline A\\) contains all of its limit points, \\(X\\) . Hence \\(\\overline A=X\\) . Convergence and Continuity Ex 2.12 An open ball is a neighborhood, so the definition in topology space implies that a sequence converges if given \\(\\epsilon>0\\) its tail is contained in some open ball of size \\(\\epsilon\\) . Conversely any non-empty neighborhood of a point \\(x\\) has an open ball centered at \\(x\\) , and since the definition in metric space implies the sequence tail is contained in the open ball, it is contained in the neighborhood as well. Ex 2.13 If a sequence is eventually constant, the sequence after some point is in a neighborhood of the constant, so it is convergent. If a sequence converges to \\(x\\) in a discrete topological space, \\(\\{x\\}\\in \\mathscr T\\) , so there exists \\(N\\) such that \\(\\forall n>N, x_n\\in \\{x\\}\\) . Hence the sequence is eventually constant. Ex 2.14 If \\(x\\in A\\) , then \\(x\\in \\overline A\\) . If not, \\(x\\) is either in \\(\\partial A\\) or \\(\\Ext A\\) . Any sequence in \\(A\\) cannot converge to a point of \\(\\Ext A\\) because there is a neighborhood of the point in \\(\\Ext A\\) that has no point of \\(A\\) . Therefore \\(x\\) is in \\(\\partial A\\) , hence \\(x\\in \\overline A\\) . Ex 2.16 From Exercise A.4 (e), \\(f^{-1}(E^c)=f^{-1}(Y\\setminus E)=f^{-1}(Y)\\setminus f^{-1}(E)=f^{-1}(Y)\\cap (f^{-1}(E))^c=X\\cap (f^{-1}(E))^c\\) . If \\(f\\) is continuous and \\(E^c\\) is closed in \\(Y\\) , \\(E\\) is open, \\(f^{-1}(E)\\) is open, \\((f^{-1}(E))^c\\) is closed, and \\(X\\) is closed, so their intersection \\(X\\cap (f^{-1}(E))^c=f^{-1}(E^c)\\) is closed. With \\(E^c=F\\) , we showed that \\(f^{-1}(F)\\) is closed for any closed \\(F\\) . Conversely, if the preimage \\(f^{-1}(E^c)\\) of any closed set \\(E^c\\) in \\(Y\\) is closed in \\(X\\) , \\(f^{-1}(E)\\) is open, hence \\(f\\) is continuous. Ex 2.18 (a) A constant map is continuous because the preimage is either \\(\\varnothing\\) or \\(X\\) . (b) The identity map is continuous because the preimage of an open set \\(E\\) in \\(X\\) is \\(X\\) . (c) Let \\(g\\) be a restriction of \\(f\\) to an open subset \\(Z\\) of \\(X\\) . The preimage \\(f^{-1}(E)\\) of an open set \\(E\\) is open, and \\(g^{-1}(E)=f^{-1}\\cap Z\\) is the intersection of two open sets, hence open. Therefore \\(g\\) is continuous. Ex 2.20 The continuity of a composotion of two continuous mapping implies the equivalence relation. Ex 2.21 if \\(f\\) is homeomorphism, for any \\(U\\in\\mathscr T_2, f^{-1}(U)\\in \\mathscr T_1\\) because \\(f\\) is continuous. The converse is true in the same way. Therefore \\(f(\\mathscr T_1) = \\mathscr T_2\\) . Now conversely if for any \\(U\\in\\mathscr T_1\\) it is true that \\(f(U)\\in\\mathscr T_2\\) , then \\(f^{-1}\\) is continuous. Symmetrically we can show \\(f\\) is continuous. Therefore \\(f\\) is homeomorphism. Ex 2.22 Since \\(f^{-1}\\) is continuous and \\(U\\) is open, \\(f(U)\\) is open. A restriction of continuous \\(f\\) to \\(U\\) is continuous, and at the same time \\(f^{-1}\\) is restricted to \\(f(U)\\) which is open, hence both \\(f|_U\\) and \\(f|_U^{-1}\\) are continuous, and is homeomorphism \\(U\\longrightarrow f(U)\\) . Ex 2.23 TODO Ex 2.27 TODO Ex 2.28 TODO Ex 2.29 (a)->(b): Since \\(f^{-1}\\) is continuous, \\(f\\) maps any open set in \\(x\\) to an open set in \\(Y\\) . (b)->(c): For a closed set \\(E\\sub X\\) , \\(f(E^c)\\) is open. Since \\(f\\) is bijective, \\(f(E^c)=f(E)^c\\) . Hence \\(f(E)\\) is closed. (b)->(a): Since (b) imlies that \\(f^{-1}\\) is continuous, and \\(f\\) is continuous by asumption, \\(f\\) is homeomorphic. Ex 2.32 (a) Already proved in Exercise 2.22. (b\u2605) Using Proposition 2.19, local homeomorphism implies the continuity. To show \\(f\\) is open, consider any open set \\(E\\) . For each \\(x\\in E\\) , we have an open set \\(U_x\\) such that \\(f|_{U_x}\\) is homeomorphism, and since \\(U_x\\cap E\\) is open, \\(f|_{U_x}(U_x\\cap E)\\) is open. Then \\(f(E)=\\cup_{x\\in E}f(U_x\\cap E)\\) is the union of open sets, which is open. Hence \\(f\\) is open. link (c) By Exercise 2.29, if \\(f\\) is bijective, continuous and open (from (b)) then \\(f\\) is homeomorphism. Hausdorff Spaces Ex 2.33 Any sequence converges to any element \\(y\\in Y\\) because the only neighborhood of \\(y\\) is \\(Y\\) in the trivial topology and the sequence is in this neighborhood. Ex 2.35 (\u2605) For two distinct points \\(p,q\\in X\\) , there exists \\(f\\) such that \\(f^{-1}(0)=\\{p\\}\\) . Let \\(\\epsilon=f(q)/2\\) . Wlog, assume \\(\\epsilon>0\\) . Since \\(\\epsilon\\neq 0\\) , two intervals \\((-\\epsilon,\\epsilon)\\) and \\((\\epsilon, 3\\epsilon)\\) are open and disjoint, and so are their mapping by \\(f^{-1}\\) . Since \\(p\\in f^{-1}(-\\epsilon,\\epsilon), q\\in f^{-1}(\\epsilon,3\\epsilon)\\) , these two are disjoint neighborhoods of \\(p\\) and \\(q\\) . Hence \\(X\\) is Hausdorff. Ex 2.38 The discrete topology is obviously Hausdorff topology. A Hausdorff topology on a finite set has \\(\\{p\\}\\) for all \\(p\\) , so these generate all possible subsets, which is the discrete topology. Bases and Countability Ex 2.40 If \\(U\\) is open, it is the union of some collection of elements of \\(\\mathscr B\\) . Therefore each element of \\(U\\) belongs to some \\(B_\\alpha\\sub U\\) . Conversely, if such \\(B\\) exists for each \\(p\\in U\\) , denote \\(B\\) as \\(B_p\\) . Then \\(U=\\cup B_p\\) , hence \\(U\\) is open. Ex 2.42 (a) Each point of \\(C_s(x)\\) is internal so \\(C_s(x)\\) is open. For an open ball \\(B\\) , it contains an open ball \\(V_{r_x}(x)\\) for each element \\(x\\) . Then \\(V_{r_x}(x)\\) contains an open cube \\(C(x)\\) which includes \\(x\\) . Then \\(\\cup_{x\\in B} C(x) = B\\) . Since open cubes can generate open balls, open cubes are a basis for \\(R^n\\) . (b) Similar to (a), each point \\(x\\) of an open ball \\(B\\) has an open ball \\(V_x\\) in \\(B\\) , and \\(V_x\\) contains a 'rational ball' \\(R_x\\) that includes \\(x\\) . Therefore \\(\\cup_{x\\in B}R_x=B\\) . Since rational balls generate open balls, \\(\\mathscr B_2\\) is a basis for \\(R^n\\) . Ex 2.45 A topology should have \\(X\\) itself as an open set. If (i) is false, the basis cannot generate \\(X\\) . So (i) is true. For (ii), given \\(B_1,B_2\\in \\mathscr B\\) , their intersection is open, so there should exist a subset of \\(B_1\\cap B_2\\) in \\(\\mathscr B\\) , otherwise it cannot generate \\(B_1\\cap B_2\\) . Ex 2.51 A second countable space \\(X\\) has a countable basis \\((B_n)\\) . Pick any element \\(x_n\\) from each \\(B_n\\) , and denote the set as \\(D\\) . \\(D\\) is clearly countable. From Exercise 2.11, \\(D\\) is dense because every non-empty open subset of \\(X\\) is an union of \\((B_{i_n})\\) and contains a point of \\(D\\) , for example, \\(x_{i_1}\\) . link Manifolds Ex 2.54 If a topological space is a 0-manifold, for any element \\(x\\) , it has a neighborhood homeomorphic to \\(R^0={0}\\) . So the neighborhood of \\(x\\) is \\(\\{x\\}\\) . Since the topology has the smallest unit of open sets, they generate the discrete topology. A manifold is second countable, hence countable. If a set \\(E\\) is countable discrete space, it is a Hausdorff space and it has a basis that consists of single-element sets. This basis is countable, so \\(E\\) is second-countable. For a point \\(x\\in E\\) , it has a neighborhood \\(\\{x\\}\\) which is homeomorphic to \\(R^0\\) . Hence \\(E\\) is a 0-manifold. Problems 2-1. (a) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_1\\) , \\(X\\setminus(\\cup U_k)\\sub X\\setminus U_1\\) is finite, \\(X\\setminus (\\cap^n U_k)=\\cup_1^n(X\\setminus U_k)\\) is finite, hence \\(\\mathscr T_1\\) is a topology. (b) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_2\\) , \\(X\\setminus(\\cup U_k)\\sub X\\setminus U_1\\) is \bcountable, \\(X\\setminus (\\cap^n U_k)=\\cup_1^n(X\\setminus U_k)\\) is countable, hence \\(\\mathscr T_2\\) is a topology. (c) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_3\\) , \\(p\\in\\cup U_k\\) , \\(p\\in\\cap U_k\\) , hence \\(\\mathscr T_3\\) is a topology. (d) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_4\\) , \\(p\\notin\\cup U_k\\) , \\(p\\notin\\cap U_k\\) , hence \\(\\mathscr T_4\\) is a topology. (e) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_5\\) because \\(X\\) is infinite.\u001d \\(X\\setminus(\\cap^n U_k)\\supset X\\setminus U_1\\) is infinite, but \\(X\\setminus (\\cup U_k)=\\cap(X\\setminus U_k)\\) may be finite. An example is \\(X=\\Z\\) and \\(U_1=\\{\\text{even integers}\\}, U_2=\\{\\text{odd integers}\\}\\) , then \\(U_1,U_2\\in \\mathscr T_5\\) but \\(X\\setminus(U_1\\cap U_2)=\\varnothing\\) . 2-2. - \\(\\{ \\text{discrete topology} \\}\\) , \\(\\{\\text{trivial topology}\\}\\) , \\(\\{ \\varnothing, \\{1\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{2,3\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{1,2\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{1,2\\}, \\{1,3\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{1,2\\}, \\{2,3\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{2\\}, \\{1,2\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{2\\}, \\{1,2\\}, \\{1,3\\}, X \\}\\) . 2-3. (a) Taking the complement on both sides, the equation reduces to \\(\\Ext (X\\setminus B)=\\Int B\\) , which is true by definition because LHS represents the points with some neighborhood in \\((X\\setminus B)^c=X\\) , and RHS represents the same. (b) \\(\\Int (X\\setminus B) = X\\setminus \\overline B=\\Ext B\\) , which is the same as (a) with replacing \\(B\\) with \\(X\\setminus B\\) . 2-4. (a) LHS is the minimal closed set including \\(\\cap A\\) . RHS is closed and includes \\(\\cap A\\) . Hence LHS \\(\\sub\\) RHS. (b) Any element \\(x\\) of RHS belongs to some \\(\\overline {A_\\alpha}\\) . Since \\(x \\in \\overline {A_\\alpha} \\sub \\overline{\\cup A}\\) , RHS is a subset of LHS. (c) Any point \\(x\\) of LHS has a neighborhood \\(V\\) in \\(\\cap A_\\alpha\\) . Then \\(\\forall\\alpha, V\\sub A_\\alpha\\) , hence \\(x\\) is in \\(\\Int A_\\alpha\\) for all \\(\\alpha\\) , and \\(x\\) is an element of RHS. (d) Any point \\(x\\) of RHS has a neighborhood \\(V\\) in some \\(A_0\\) . Since \\(V\\sub \\cup A_\\alpha\\) , \\(x\\) has a neighborhood in \\(\\cup A_\\alpha\\) , and \\(x\\in \\Int(\\cup A_\\alpha)\\) . equality: (a) An example with strict inequality is \\(A_1=\\mathbb Q, A_2=\\R\\setminus\\mathbb Q\\) . (b) We show a boundary point \\(p\\) of \\(\\cup A\\) is in \\(\\cup\\overline A\\) . Since \\(\\mathscr A\\) is finite, the smallest neighborhood \\(V\\) of \\(p\\) exists, and is the intersection of all neighborhoods of \\(p\\) . \\(V\\) has a point \\(q\\) other than \\(p\\) in \\(A_i\\) for some \\(i\\) . Then \\(p\\in \\overline A_i\\) because any neighborhood of \\(p\\) contains \\(V\\) and \\(V\\) contains \\(q\\) , so \\(p\\) is a limit point of \\(A_i\\) . We proved \\(\\partial (\\cup A)\\sub \\cup\\overline A\\) , and clearly \\(\\Int (\\cup A ) \\sub \\cup \\overline A\\) , hence \\(\\overline{\\cup A}\\sub \\cup\\overline A\\) . (c) Any point of \\(\\cap \\Int A\\) has a neighborhood in each \\(A_i\\) . The finite intersection \\(V\\) of them is also a neighborhood. \\(\\forall i, V\\sub A_i\\Longrightarrow V\\sub \\cap A\\) . Hence the point is interior of \\(\\cap A\\) . (d) An example with strict inequality is that \\(A\\) is indexed by a real number \\(\\alpha\\) and \\(A_\\alpha=\\{\\alpha\\}\\) , then \\(\\Int(\\cup A_\\alpha)=\\Int \\R = \\R \\supset \\cup \\varnothing\\) . 2-5. 2-6. (a) Suppose \\(f\\) is continuous. \\(A\\sub f^{-1}(f(A))\\sub f^{-1}(\\overline{f(A)})\\) and \\(f^{-1}(\\overline{f(A)})\\) is closed. Since \\(\\overline A\\) is the smallest closed set containing \\(A\\) , we have \\(\\overline A\\sub f^{-1}(\\overline{f(A)})\\Longrightarrow f(\\overline A)\\sub \\overline{f(A)}\\) . Conversely suppose \\(f(\\overline A)\\sub \\overline{f(A)}\\) for all \\(A\\sub X\\) . (b) (c) (d) 2-7. Suppose a neighborhood \\(V\\) of \\(p\\) contains finitely many points of \\(A\\) . Since \\(p\\) is a limit point of \\(A\\) , \\(V\\) has another point \\(q\\in A, q\\neq p\\) . \\(X\\) is Hausdorff so there are two disjoint neighborhoods \\(V_p, V_q\\) such that \\(p\\in V_p, q\\in V_q\\) . Then \\(V\\cap V_p\\) is also a neighborhood of \\(p\\) and does not contain \\(q\\) . If we repeat the above with \\(V\\cap V_p\\) as new \\(V\\) , then at each step the size of \\(V\\cap A\\) decreases by at least one, and since \\(V\\cap A\\) is finite by assumption, the process cannot continue, which contradicts. Therefore \\(V\\cap A\\) is infinite. 2-25.","title":"2. Topological Spaces"},{"location":"lee/ch2/#2-topological-spaces","text":"\\(\\gdef\\Int{\\operatorname{Int}}\\) \\(\\gdef\\Ext{\\operatorname{Ext}}\\)","title":"2. Topological Spaces"},{"location":"lee/ch2/#note","text":"\\(A = \\Int A+ \\partial A + \\Ext A \\\\ = (\\text{limit point} + \\text{isolated point}) + \\Ext A\\) where \\(+\\) is a disjoint partition op boundary -> limit point, not isolated isolated -> int","title":"Note"},{"location":"lee/ch2/#topologies","text":"Ex 2.2 It can be easily seen that all examples satisfy (i)~(iii) in page 20. Ex 2.4 (a) For \"only if\", any open ball w.r.t \\(d\\) is an open set w.r.t \\(d'\\) , and any open set contains an open ball, hence there exists \\(r_1\\) . The same for \\(r_2\\) . For \"if\", Suppose a set \\(A\\) is open in \\((M,d)\\) . Any point \\(x\\in A\\) is internal point in \\((M,d)\\) and there exists \\(r\\) such that \\(B_r^{(d)}(x)\\sub A\\) . Since \\(B_{r_1}^{(d')}(x)\\sub A\\) , \\(x\\) is an internal point of \\(A\\) in \\((M,d')\\) . Hence \\(A\\) is open in \\((M,d')\\) . Conversely, any open set in \\((M,d')\\) is open in \\((M,d)\\) . Therefore two topologies are the same. (b) \\(B_r^{(d)}=B_{cr}^{(d')}\\) , so their open sets are the same, and generated topologies are the same. (c) \\(d'\\le d\\le nd'\\) . It can be proved using (a) that \\(d\\) and \\(d'\\) generate the same topology. (d) With the discrete metric, \\(B_{0.5}(x)=\\{x\\}\\) . These generate all possible subsets of \\(X\\) . (e) With the Euclidean metric, \\(B_{0.5}(x)=\\{x\\}\\) . These generate all possible subsets of \\(\\Z\\) . Ex 2.5 (1) \\(\\varnothing \\sub Y, Y \\sub Y\\) . (2) The set is closed under finite intersection because they were closed in \\(X\\) . (3) The set is closed under any union of arbitrarily many elements because they were closed in \\(X\\) . Ex 2.6 (1) All topologies have \\(\\varnothing\\) and \\(X\\) , hence \\({\\varnothing,X}\\sub \\mathscr T\\) . (2) \\(\\mathscr T\\) is closed under finite intersection, since its elements were the elements of \\(T_{\\alpha_0}\\) for some \\(\\alpha_0\\) , and their intersection existed in \\(T_{\\alpha_0}\\) . (3) The same as (2). Ex 2.9 TODO: Ex 2.10 By Proposition 2.8, a boundary point is a limit point. If a set contains all of its limit points, the set contains all boundary points, hence closed. Now suppose a set is closed. Any limit point of the set \\(A\\) is in \\(\\Int A\\) , \\(\\Ext A\\) , or \\(\\partial A\\) . The limit points in \\(\\Int A\\) are obviously in \\(A\\) . The limit points which are boundary points are in \\(A\\) because \\(A\\) is closed. \\(\\Ext A\\) cannot have a limit point because a point \\(x\\) in \\(\\Ext A\\) has a neighborhood in \\(X\\setminus A\\) , and the neighborhood has no point of \\(A\\) other than \\(x\\) , so \\(x\\) is not a limit point. Therefore \\(A\\) contains all of its limit points. Ex 2.11 Suppose \\(A\\) is dense in \\(X\\) and there is an non-empty open subset \\(B\\) of \\(X\\) that contains no point of \\(A\\) . \\(B\\) has at least one element, say \\(b\\) . Then \\(B\\) is a neighborhood of \\(b\\) and \\(B\\sub X\\setminus A\\) . By Proposition 2.8 (b), \\(b\\) is in \\(\\Ext A\\) . However, \\(\\Ext A\\) = \\(X\\setminus \\overline A = \\varnothing\\) , contradicts. Hence the statement is true. Conversely, suppose every non-empty open subset of \\(X\\) contains a point of \\(A\\) . Then by definition any point of \\(X\\) is a limit point of \\(A\\) . Since \\(\\overline A\\) is closed, using Exercise 2.10, \\(\\overline A\\) contains all of its limit points, \\(X\\) . Hence \\(\\overline A=X\\) .","title":"Topologies"},{"location":"lee/ch2/#convergence-and-continuity","text":"Ex 2.12 An open ball is a neighborhood, so the definition in topology space implies that a sequence converges if given \\(\\epsilon>0\\) its tail is contained in some open ball of size \\(\\epsilon\\) . Conversely any non-empty neighborhood of a point \\(x\\) has an open ball centered at \\(x\\) , and since the definition in metric space implies the sequence tail is contained in the open ball, it is contained in the neighborhood as well. Ex 2.13 If a sequence is eventually constant, the sequence after some point is in a neighborhood of the constant, so it is convergent. If a sequence converges to \\(x\\) in a discrete topological space, \\(\\{x\\}\\in \\mathscr T\\) , so there exists \\(N\\) such that \\(\\forall n>N, x_n\\in \\{x\\}\\) . Hence the sequence is eventually constant. Ex 2.14 If \\(x\\in A\\) , then \\(x\\in \\overline A\\) . If not, \\(x\\) is either in \\(\\partial A\\) or \\(\\Ext A\\) . Any sequence in \\(A\\) cannot converge to a point of \\(\\Ext A\\) because there is a neighborhood of the point in \\(\\Ext A\\) that has no point of \\(A\\) . Therefore \\(x\\) is in \\(\\partial A\\) , hence \\(x\\in \\overline A\\) . Ex 2.16 From Exercise A.4 (e), \\(f^{-1}(E^c)=f^{-1}(Y\\setminus E)=f^{-1}(Y)\\setminus f^{-1}(E)=f^{-1}(Y)\\cap (f^{-1}(E))^c=X\\cap (f^{-1}(E))^c\\) . If \\(f\\) is continuous and \\(E^c\\) is closed in \\(Y\\) , \\(E\\) is open, \\(f^{-1}(E)\\) is open, \\((f^{-1}(E))^c\\) is closed, and \\(X\\) is closed, so their intersection \\(X\\cap (f^{-1}(E))^c=f^{-1}(E^c)\\) is closed. With \\(E^c=F\\) , we showed that \\(f^{-1}(F)\\) is closed for any closed \\(F\\) . Conversely, if the preimage \\(f^{-1}(E^c)\\) of any closed set \\(E^c\\) in \\(Y\\) is closed in \\(X\\) , \\(f^{-1}(E)\\) is open, hence \\(f\\) is continuous. Ex 2.18 (a) A constant map is continuous because the preimage is either \\(\\varnothing\\) or \\(X\\) . (b) The identity map is continuous because the preimage of an open set \\(E\\) in \\(X\\) is \\(X\\) . (c) Let \\(g\\) be a restriction of \\(f\\) to an open subset \\(Z\\) of \\(X\\) . The preimage \\(f^{-1}(E)\\) of an open set \\(E\\) is open, and \\(g^{-1}(E)=f^{-1}\\cap Z\\) is the intersection of two open sets, hence open. Therefore \\(g\\) is continuous. Ex 2.20 The continuity of a composotion of two continuous mapping implies the equivalence relation. Ex 2.21 if \\(f\\) is homeomorphism, for any \\(U\\in\\mathscr T_2, f^{-1}(U)\\in \\mathscr T_1\\) because \\(f\\) is continuous. The converse is true in the same way. Therefore \\(f(\\mathscr T_1) = \\mathscr T_2\\) . Now conversely if for any \\(U\\in\\mathscr T_1\\) it is true that \\(f(U)\\in\\mathscr T_2\\) , then \\(f^{-1}\\) is continuous. Symmetrically we can show \\(f\\) is continuous. Therefore \\(f\\) is homeomorphism. Ex 2.22 Since \\(f^{-1}\\) is continuous and \\(U\\) is open, \\(f(U)\\) is open. A restriction of continuous \\(f\\) to \\(U\\) is continuous, and at the same time \\(f^{-1}\\) is restricted to \\(f(U)\\) which is open, hence both \\(f|_U\\) and \\(f|_U^{-1}\\) are continuous, and is homeomorphism \\(U\\longrightarrow f(U)\\) . Ex 2.23 TODO Ex 2.27 TODO Ex 2.28 TODO Ex 2.29 (a)->(b): Since \\(f^{-1}\\) is continuous, \\(f\\) maps any open set in \\(x\\) to an open set in \\(Y\\) . (b)->(c): For a closed set \\(E\\sub X\\) , \\(f(E^c)\\) is open. Since \\(f\\) is bijective, \\(f(E^c)=f(E)^c\\) . Hence \\(f(E)\\) is closed. (b)->(a): Since (b) imlies that \\(f^{-1}\\) is continuous, and \\(f\\) is continuous by asumption, \\(f\\) is homeomorphic. Ex 2.32 (a) Already proved in Exercise 2.22. (b\u2605) Using Proposition 2.19, local homeomorphism implies the continuity. To show \\(f\\) is open, consider any open set \\(E\\) . For each \\(x\\in E\\) , we have an open set \\(U_x\\) such that \\(f|_{U_x}\\) is homeomorphism, and since \\(U_x\\cap E\\) is open, \\(f|_{U_x}(U_x\\cap E)\\) is open. Then \\(f(E)=\\cup_{x\\in E}f(U_x\\cap E)\\) is the union of open sets, which is open. Hence \\(f\\) is open. link (c) By Exercise 2.29, if \\(f\\) is bijective, continuous and open (from (b)) then \\(f\\) is homeomorphism.","title":"Convergence and Continuity"},{"location":"lee/ch2/#hausdorff-spaces","text":"Ex 2.33 Any sequence converges to any element \\(y\\in Y\\) because the only neighborhood of \\(y\\) is \\(Y\\) in the trivial topology and the sequence is in this neighborhood. Ex 2.35 (\u2605) For two distinct points \\(p,q\\in X\\) , there exists \\(f\\) such that \\(f^{-1}(0)=\\{p\\}\\) . Let \\(\\epsilon=f(q)/2\\) . Wlog, assume \\(\\epsilon>0\\) . Since \\(\\epsilon\\neq 0\\) , two intervals \\((-\\epsilon,\\epsilon)\\) and \\((\\epsilon, 3\\epsilon)\\) are open and disjoint, and so are their mapping by \\(f^{-1}\\) . Since \\(p\\in f^{-1}(-\\epsilon,\\epsilon), q\\in f^{-1}(\\epsilon,3\\epsilon)\\) , these two are disjoint neighborhoods of \\(p\\) and \\(q\\) . Hence \\(X\\) is Hausdorff. Ex 2.38 The discrete topology is obviously Hausdorff topology. A Hausdorff topology on a finite set has \\(\\{p\\}\\) for all \\(p\\) , so these generate all possible subsets, which is the discrete topology.","title":"Hausdorff Spaces"},{"location":"lee/ch2/#bases-and-countability","text":"Ex 2.40 If \\(U\\) is open, it is the union of some collection of elements of \\(\\mathscr B\\) . Therefore each element of \\(U\\) belongs to some \\(B_\\alpha\\sub U\\) . Conversely, if such \\(B\\) exists for each \\(p\\in U\\) , denote \\(B\\) as \\(B_p\\) . Then \\(U=\\cup B_p\\) , hence \\(U\\) is open. Ex 2.42 (a) Each point of \\(C_s(x)\\) is internal so \\(C_s(x)\\) is open. For an open ball \\(B\\) , it contains an open ball \\(V_{r_x}(x)\\) for each element \\(x\\) . Then \\(V_{r_x}(x)\\) contains an open cube \\(C(x)\\) which includes \\(x\\) . Then \\(\\cup_{x\\in B} C(x) = B\\) . Since open cubes can generate open balls, open cubes are a basis for \\(R^n\\) . (b) Similar to (a), each point \\(x\\) of an open ball \\(B\\) has an open ball \\(V_x\\) in \\(B\\) , and \\(V_x\\) contains a 'rational ball' \\(R_x\\) that includes \\(x\\) . Therefore \\(\\cup_{x\\in B}R_x=B\\) . Since rational balls generate open balls, \\(\\mathscr B_2\\) is a basis for \\(R^n\\) . Ex 2.45 A topology should have \\(X\\) itself as an open set. If (i) is false, the basis cannot generate \\(X\\) . So (i) is true. For (ii), given \\(B_1,B_2\\in \\mathscr B\\) , their intersection is open, so there should exist a subset of \\(B_1\\cap B_2\\) in \\(\\mathscr B\\) , otherwise it cannot generate \\(B_1\\cap B_2\\) . Ex 2.51 A second countable space \\(X\\) has a countable basis \\((B_n)\\) . Pick any element \\(x_n\\) from each \\(B_n\\) , and denote the set as \\(D\\) . \\(D\\) is clearly countable. From Exercise 2.11, \\(D\\) is dense because every non-empty open subset of \\(X\\) is an union of \\((B_{i_n})\\) and contains a point of \\(D\\) , for example, \\(x_{i_1}\\) . link","title":"Bases and Countability"},{"location":"lee/ch2/#manifolds","text":"Ex 2.54 If a topological space is a 0-manifold, for any element \\(x\\) , it has a neighborhood homeomorphic to \\(R^0={0}\\) . So the neighborhood of \\(x\\) is \\(\\{x\\}\\) . Since the topology has the smallest unit of open sets, they generate the discrete topology. A manifold is second countable, hence countable. If a set \\(E\\) is countable discrete space, it is a Hausdorff space and it has a basis that consists of single-element sets. This basis is countable, so \\(E\\) is second-countable. For a point \\(x\\in E\\) , it has a neighborhood \\(\\{x\\}\\) which is homeomorphic to \\(R^0\\) . Hence \\(E\\) is a 0-manifold.","title":"Manifolds"},{"location":"lee/ch2/#problems","text":"2-1. (a) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_1\\) , \\(X\\setminus(\\cup U_k)\\sub X\\setminus U_1\\) is finite, \\(X\\setminus (\\cap^n U_k)=\\cup_1^n(X\\setminus U_k)\\) is finite, hence \\(\\mathscr T_1\\) is a topology. (b) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_2\\) , \\(X\\setminus(\\cup U_k)\\sub X\\setminus U_1\\) is \bcountable, \\(X\\setminus (\\cap^n U_k)=\\cup_1^n(X\\setminus U_k)\\) is countable, hence \\(\\mathscr T_2\\) is a topology. (c) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_3\\) , \\(p\\in\\cup U_k\\) , \\(p\\in\\cap U_k\\) , hence \\(\\mathscr T_3\\) is a topology. (d) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_4\\) , \\(p\\notin\\cup U_k\\) , \\(p\\notin\\cap U_k\\) , hence \\(\\mathscr T_4\\) is a topology. (e) \\(\\{\\varnothing,X\\}\\sub \\mathscr T_5\\) because \\(X\\) is infinite.\u001d \\(X\\setminus(\\cap^n U_k)\\supset X\\setminus U_1\\) is infinite, but \\(X\\setminus (\\cup U_k)=\\cap(X\\setminus U_k)\\) may be finite. An example is \\(X=\\Z\\) and \\(U_1=\\{\\text{even integers}\\}, U_2=\\{\\text{odd integers}\\}\\) , then \\(U_1,U_2\\in \\mathscr T_5\\) but \\(X\\setminus(U_1\\cap U_2)=\\varnothing\\) . 2-2. - \\(\\{ \\text{discrete topology} \\}\\) , \\(\\{\\text{trivial topology}\\}\\) , \\(\\{ \\varnothing, \\{1\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{2,3\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{1,2\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{1,2\\}, \\{1,3\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{1,2\\}, \\{2,3\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{2\\}, \\{1,2\\}, X \\}\\) , \\(\\{ \\varnothing, \\{1\\}, \\{2\\}, \\{1,2\\}, \\{1,3\\}, X \\}\\) . 2-3. (a) Taking the complement on both sides, the equation reduces to \\(\\Ext (X\\setminus B)=\\Int B\\) , which is true by definition because LHS represents the points with some neighborhood in \\((X\\setminus B)^c=X\\) , and RHS represents the same. (b) \\(\\Int (X\\setminus B) = X\\setminus \\overline B=\\Ext B\\) , which is the same as (a) with replacing \\(B\\) with \\(X\\setminus B\\) . 2-4. (a) LHS is the minimal closed set including \\(\\cap A\\) . RHS is closed and includes \\(\\cap A\\) . Hence LHS \\(\\sub\\) RHS. (b) Any element \\(x\\) of RHS belongs to some \\(\\overline {A_\\alpha}\\) . Since \\(x \\in \\overline {A_\\alpha} \\sub \\overline{\\cup A}\\) , RHS is a subset of LHS. (c) Any point \\(x\\) of LHS has a neighborhood \\(V\\) in \\(\\cap A_\\alpha\\) . Then \\(\\forall\\alpha, V\\sub A_\\alpha\\) , hence \\(x\\) is in \\(\\Int A_\\alpha\\) for all \\(\\alpha\\) , and \\(x\\) is an element of RHS. (d) Any point \\(x\\) of RHS has a neighborhood \\(V\\) in some \\(A_0\\) . Since \\(V\\sub \\cup A_\\alpha\\) , \\(x\\) has a neighborhood in \\(\\cup A_\\alpha\\) , and \\(x\\in \\Int(\\cup A_\\alpha)\\) . equality: (a) An example with strict inequality is \\(A_1=\\mathbb Q, A_2=\\R\\setminus\\mathbb Q\\) . (b) We show a boundary point \\(p\\) of \\(\\cup A\\) is in \\(\\cup\\overline A\\) . Since \\(\\mathscr A\\) is finite, the smallest neighborhood \\(V\\) of \\(p\\) exists, and is the intersection of all neighborhoods of \\(p\\) . \\(V\\) has a point \\(q\\) other than \\(p\\) in \\(A_i\\) for some \\(i\\) . Then \\(p\\in \\overline A_i\\) because any neighborhood of \\(p\\) contains \\(V\\) and \\(V\\) contains \\(q\\) , so \\(p\\) is a limit point of \\(A_i\\) . We proved \\(\\partial (\\cup A)\\sub \\cup\\overline A\\) , and clearly \\(\\Int (\\cup A ) \\sub \\cup \\overline A\\) , hence \\(\\overline{\\cup A}\\sub \\cup\\overline A\\) . (c) Any point of \\(\\cap \\Int A\\) has a neighborhood in each \\(A_i\\) . The finite intersection \\(V\\) of them is also a neighborhood. \\(\\forall i, V\\sub A_i\\Longrightarrow V\\sub \\cap A\\) . Hence the point is interior of \\(\\cap A\\) . (d) An example with strict inequality is that \\(A\\) is indexed by a real number \\(\\alpha\\) and \\(A_\\alpha=\\{\\alpha\\}\\) , then \\(\\Int(\\cup A_\\alpha)=\\Int \\R = \\R \\supset \\cup \\varnothing\\) . 2-5. 2-6. (a) Suppose \\(f\\) is continuous. \\(A\\sub f^{-1}(f(A))\\sub f^{-1}(\\overline{f(A)})\\) and \\(f^{-1}(\\overline{f(A)})\\) is closed. Since \\(\\overline A\\) is the smallest closed set containing \\(A\\) , we have \\(\\overline A\\sub f^{-1}(\\overline{f(A)})\\Longrightarrow f(\\overline A)\\sub \\overline{f(A)}\\) . Conversely suppose \\(f(\\overline A)\\sub \\overline{f(A)}\\) for all \\(A\\sub X\\) . (b) (c) (d) 2-7. Suppose a neighborhood \\(V\\) of \\(p\\) contains finitely many points of \\(A\\) . Since \\(p\\) is a limit point of \\(A\\) , \\(V\\) has another point \\(q\\in A, q\\neq p\\) . \\(X\\) is Hausdorff so there are two disjoint neighborhoods \\(V_p, V_q\\) such that \\(p\\in V_p, q\\in V_q\\) . Then \\(V\\cap V_p\\) is also a neighborhood of \\(p\\) and does not contain \\(q\\) . If we repeat the above with \\(V\\cap V_p\\) as new \\(V\\) , then at each step the size of \\(V\\cap A\\) decreases by at least one, and since \\(V\\cap A\\) is finite by assumption, the process cannot continue, which contradicts. Therefore \\(V\\cap A\\) is infinite. 2-25.","title":"Problems"},{"location":"lee/ch3/","text":"3. New Spaces from Old Subspaces Ex 3.1. \\(\\varnothing, S\\in \\mathscr T_S\\) and \\(\\{U_\\alpha\\}\\in\\mathscr T_S\\Longrightarrow \\cup U_\\alpha=\\cup (S\\cap V_\\alpha)=S\\cap(\\cup V_\\alpha)\\) . Since \\(\\cup V_\\alpha\\in \\mathscr T\\) , \\(S\\cap(\\cup V_\\alpha)\\in \\mathscr T_S\\) . Also \\(\\cap^\\infty U_n=\\cap^\\infty (S\\cap V_n)=S\\cap(\\cap^\\infty V_n), \\cap^\\infty V_n\\in \\mathscr T\\) , hence \\(\\cap^\\infty U_n \\in \\mathscr T_S\\) . Ex 3.2. If \\(V\\) is closed in \\(X\\) , \\(X\\setminus V\\in\\mathscr T\\Longrightarrow S\\cap (X\\setminus V)=S\\setminus V\\in\\mathscr T_S\\) , hence \\(S\\setminus V\\) is open and \\(S\\setminus (S\\setminus V)=S\\cap V\\) is closd. Conversely if \\(B\\) is closed in \\(S\\) , \\(S\\setminus B\\in\\mathscr T_S\\) , there exists \\(V\\in\\mathscr T\\) such that \\(S\\setminus B=S\\cap V\\) , then \\(S\\setminus (S\\setminus B)=S\\setminus (S\\cap V)\\Longrightarrow B=S\\setminus V=S\\cap (X\\setminus V)\\) as desired. Ex 3.3. Ex 3.6. (a) For openness, if \\(U\\in\\mathscr T_S, S\\in\\mathscr T\\) , then \\(U=S\\cap V\\) for some \\(V\\in\\mathscr T\\) , and since both \\(S\\) and \\(V\\) are open, \\(U=S\\cap V\\in \\mathscr T\\) . For closedness, if \\(S\\setminus U\\in\\mathscr T_S, X\\setminus S\\in\\mathscr T\\) , then \\(S\\setminus U=S\\cap V\\) for some \\(V\\in\\mathscr T\\) , and since both \\(X\\setminus S\\) and \\(V\\) are open, \\(X\\setminus U=(X\\setminus S)\\cup V\\in \\mathscr T\\) , and \\(U\\) is closed in \\(X\\) . (equalities verifiable with diagram) (b) If \\(U\\in\\mathscr T\\) , then \\(S\\cap U=U\\in \\mathscr T_S\\) , so \\(U\\) is relatively open in \\(S\\) . If \\(X\\setminus U\\in\\mathscr T\\) , then \\(S\\cap (X\\setminus U)=S\\setminus U\\in \\mathscr T_S\\) , so \\(U\\) is relatively closed in \\(S\\) . Ex 3.7. Ex 3.12. (c) (d) (e) (f) Ex 3.13. The inclusion map in the subspace topology of the image is the identity, which is a homeomorphism from \\(S\\) onto its image \\(S\\) , hence a topological embedding. Ex 3.17 Ex 3.19 A surjective topological embedding has its codomain as the range. Hence it is a homeomorphism. Product Spaces Ex. Disjoint Union Spaces Quotient Spaces Adjunction Spaces Topological Groups and Group Actions Problems 3-1. 3-2.","title":"3. New Spaces from Old"},{"location":"lee/ch3/#3-new-spaces-from-old","text":"","title":"3. New Spaces from Old"},{"location":"lee/ch3/#subspaces","text":"Ex 3.1. \\(\\varnothing, S\\in \\mathscr T_S\\) and \\(\\{U_\\alpha\\}\\in\\mathscr T_S\\Longrightarrow \\cup U_\\alpha=\\cup (S\\cap V_\\alpha)=S\\cap(\\cup V_\\alpha)\\) . Since \\(\\cup V_\\alpha\\in \\mathscr T\\) , \\(S\\cap(\\cup V_\\alpha)\\in \\mathscr T_S\\) . Also \\(\\cap^\\infty U_n=\\cap^\\infty (S\\cap V_n)=S\\cap(\\cap^\\infty V_n), \\cap^\\infty V_n\\in \\mathscr T\\) , hence \\(\\cap^\\infty U_n \\in \\mathscr T_S\\) . Ex 3.2. If \\(V\\) is closed in \\(X\\) , \\(X\\setminus V\\in\\mathscr T\\Longrightarrow S\\cap (X\\setminus V)=S\\setminus V\\in\\mathscr T_S\\) , hence \\(S\\setminus V\\) is open and \\(S\\setminus (S\\setminus V)=S\\cap V\\) is closd. Conversely if \\(B\\) is closed in \\(S\\) , \\(S\\setminus B\\in\\mathscr T_S\\) , there exists \\(V\\in\\mathscr T\\) such that \\(S\\setminus B=S\\cap V\\) , then \\(S\\setminus (S\\setminus B)=S\\setminus (S\\cap V)\\Longrightarrow B=S\\setminus V=S\\cap (X\\setminus V)\\) as desired. Ex 3.3. Ex 3.6. (a) For openness, if \\(U\\in\\mathscr T_S, S\\in\\mathscr T\\) , then \\(U=S\\cap V\\) for some \\(V\\in\\mathscr T\\) , and since both \\(S\\) and \\(V\\) are open, \\(U=S\\cap V\\in \\mathscr T\\) . For closedness, if \\(S\\setminus U\\in\\mathscr T_S, X\\setminus S\\in\\mathscr T\\) , then \\(S\\setminus U=S\\cap V\\) for some \\(V\\in\\mathscr T\\) , and since both \\(X\\setminus S\\) and \\(V\\) are open, \\(X\\setminus U=(X\\setminus S)\\cup V\\in \\mathscr T\\) , and \\(U\\) is closed in \\(X\\) . (equalities verifiable with diagram) (b) If \\(U\\in\\mathscr T\\) , then \\(S\\cap U=U\\in \\mathscr T_S\\) , so \\(U\\) is relatively open in \\(S\\) . If \\(X\\setminus U\\in\\mathscr T\\) , then \\(S\\cap (X\\setminus U)=S\\setminus U\\in \\mathscr T_S\\) , so \\(U\\) is relatively closed in \\(S\\) . Ex 3.7. Ex 3.12. (c) (d) (e) (f) Ex 3.13. The inclusion map in the subspace topology of the image is the identity, which is a homeomorphism from \\(S\\) onto its image \\(S\\) , hence a topological embedding. Ex 3.17 Ex 3.19 A surjective topological embedding has its codomain as the range. Hence it is a homeomorphism.","title":"Subspaces"},{"location":"lee/ch3/#product-spaces","text":"Ex.","title":"Product Spaces"},{"location":"lee/ch3/#disjoint-union-spaces","text":"","title":"Disjoint Union Spaces"},{"location":"lee/ch3/#quotient-spaces","text":"","title":"Quotient Spaces"},{"location":"lee/ch3/#adjunction-spaces","text":"","title":"Adjunction Spaces"},{"location":"lee/ch3/#topological-groups-and-group-actions","text":"","title":"Topological Groups and Group Actions"},{"location":"lee/ch3/#problems","text":"3-1. 3-2.","title":"Problems"},{"location":"lee/ch4/","text":"4. Connectedness and Compactness Connectedness Ex 4.3. If \\(X\\) is empty, the statement is true. Otherwise choose any \\(x\\in X\\) and let \\(c\\) the equivalence class of \\(x\\) . Then \\(c\\) is open and the union of all other equivalence classes is open, and these two subsets are the partition of \\(X\\) . If \\(c\\neq X\\) , then \\(X\\) is disconnected, which contradicts the assumption. Therefore \\(c=X\\) . Ex 4.4. Suppose \\(X\\) is disconnected, \\(X=A\\cup B\\) for two disjoint open sets \\(A, B\\) . Define a map \\(f\\) that \\(f(A)=0, f(B)=1\\) . Then \\(f\\) is continuous and non-constant. Conversely, if there is \\(f\\) that is nonconstant and continuous from \\(X\\) to the discrete space, then by Proposition 4.2, \\(X\\) is empty or disconnected. If \\(X\\) is empty, \\(f\\) is constant. Hence \\(X\\) is disconnected. Ex 4.5. (Disjoint union of spaces here refers to one in Chapter 3.) Suppose \\(X\\) is disconnected by two open subsets. Let the subspaces for these open subsets \\(A\\) and \\(B\\) . We will prove \\(X\\) is homeomorphic to a disjoint union topology \\(A^*\\cup B^*\\) by a mapping \\(f, \\forall a\\in A,f(a)=(a,A),\\forall b\\in B,f(b)=(b,B)\\) . \\(f\\) is continuous because for any open subset \\(E\\sub A^*\\cup B^*, E=(E\\cap A^*)\\cup (E\\cap B^*), f^{-1}(E)=f^{-1}(E\\cap A^*)\\cup f^{-1}(E\\cap B^*)\\) , and \\(f^{-1}(E\\cap A^*), f^{-1}(E\\cap B^*)\\) are open by definition of disjoint union topology, hence \\(f^{-1}(E)\\) is open. \\(f^{-1}\\) is continuous because for any open subset \\(E\\sub X, f(E)=f(E\\cap A)\\cup f(E\\y cap B)\\) , and \\(f(E\\cap A)\\) is open in \\(A^*\\) , \\(f(E\\cap B)\\) is open in \\(B^*\\) , \\(f(E)\\) is open. Conversely, if \\(X\\) is homeomorphic to a disjoint union \\(\\cup X_k\\) with at least two spaces, then by Proposition 4.2, \\(X\\) is not a nonempty connected space. \\(X\\) is not empty, hence \\(X\\) is disconnected. Ex 4.10. Ex 4.14. (a) Let \\(f:X\\longrightarrow f(X)\\) is continuous, and \\(X\\) is path-connected. Then for any two points \\(a,b\\in f(X)\\) , there is a path \\(g\\) from \\(f^{-1}(a)\\) to \\(f^{-1}(b)\\) in \\(X\\) . Then \\(f\\circ g:I\\longrightarrow f(X)\\) is continuous and from \\(a\\) to \\(b\\) . hence a path. Therefore \\(f(X)\\) is path-connected. (b) Let \\(p\\) a point in common. Then for any two points \\(a,b\\in \\cup B_\\alpha\\) , there exists \\(B_a\\) that contains \\(a\\) and \\(B_b\\) that contains \\(b\\) . \\(B_a\\) has a path \\(f\\) from \\(a\\) to \\(p\\) , and \\(B_b\\) has a path \\(g\\) from \\(p\\) to \\(b\\) . Define \\(f':[0,0.5]\\longrightarrow \\R,f'(x)=f(x*2), g':[0.5,1]\\longrightarrow \\R, g'(x)=f(x*2-1)\\) . Both \\(f', g'\\) are continous. We can use the gluing lemma (pasting lemma) to define \\(h:[0,1]\\longrightarrow \\R\\) from \\(f'\\) and \\(g'\\) . Then \\(h\\) is a path from \\(a\\) to \\(b\\) . Hence cup B_\\alpha \\( is path-connected. (c) Let \\) S_1,\\dots,S_n \\( path-connected spaces and \\) S=\\prod S_n \\(. For any two points \\) a,b\\in S \\(, \\) a=(a_1,\\dots,a_n),b=(b_1,\\dots,b_n) \\(. For each index \\) k\\in[1,n] \\(, there exists a path \\) f_k \\( from \\) a_k \\( to \\) b_k \\( in \\) S_k \\(. Define \\) f:I\\rightarrow S, f(x)=(f_1(x),\\dots,f_n(x)) \\(. Then by characteristic property of the product topology, \\) f \\( is continous from that each \\) f_k \\( is continous. Hence \\) f \\( is a path from \\) a \\( to \\) b \\( in \\) S \\(, and \\) S$ is path-connected. (d) A quotient map is continuous, hence by (a) every quotient space of a path-connected space is path-connected. Ex 4.22. (a) Suppose two path components of \\(X\\) are not disjoint. They have a common point, so the union of two is also path-connected, which contradicts that path components were maximal. Therefore path components are all disjoint, and form a partition of \\(X\\) . (b) A path component is connected, so by Proposition 4.20 (a), the path component is in a single component. Path components are disjoint and each element belongs to one path component, hence each component is a disjoint union of path components. (c) For an nonempty path-connected subset \\(E\\) of \\(X\\) , \\(E\\) , there exists a path component \\(P\\) that shares a point with \\(E\\) . Then \\(E\\cup P\\) is also path-connected. Since \\(P\\) is a maximal path-connected subset, \\(E\\cup P\\sub P\\Longrightarrow E\\sub P\\) . Ex 4.24. Let \\(M\\) a manifold and consider \\(p\\in M\\) . Since \\(M\\) is locally Euclidean, \\(p\\) has a neighborhood \\(U\\) that is homeomorphic to an open ball in \\(R^n\\) by a homeomorphism \\(\\phi\\) . An open ball in \\(R^n\\) is path-connected. For any neighborhood \\(V\\) of \\(p\\) , \\(\\phi(U\\cap V)\\) is open and contains \\(\\phi(p)\\) . Since \\(\\phi(U)\\) is locally path-connected, \\(\\phi(U\\cap V)\\) has a path-connected subset \\(W\\) . \\(\\phi^{-1}(W)\\) is path-connected and a subset of \\(U\\cap V\\) . We showed any neighborhood of \\(p\\) has a path-connected subset, hence \\(M\\) is locally path-connected. Since a path-connected subset is connected subset, \\(M\\) is also locally connected. Compactness Ex 4.28. Suppose \\(A\\) is compact. For any open cover \\(\\cup_\\alpha E_\\alpha\\) of \\(A\\) by open sets of \\(X\\) , \\(\\cup_\\alpha (E_\\alpha \\cap A)\\) is an open cover of \\(A\\) by open sets in \\(A\\) . Since \\(A\\) is compact, it has a finite subcover \\(\\cup_1^N (E_{\\alpha_n}\\cap A)\\) . For every open set \\(E\\) in \\(A\\) , there exists an open set \\(F\\) in \\(X\\) such that \\(F\\cap A=E\\) . Define \\(\\phi(E)=F\\) . Then \\(A=\\cup_1^n (E_{\\alpha_n}\\cap A)\\Longrightarrow A\\sub\\cup_1^n \\phi(E_{\\alpha_n}\\cap A)\\) , where the last union is a finite subcover by open sets in \\(X\\) . This proves the forward direction of the lemma. Conversely suppose every open cover of \\(A\\) by open sets in \\(X\\) has a finite subcover by open sets in \\(X\\) . Then for any open cover \\(\\cup E_\\alpha\\) of \\(A\\) by open sets in \\(A\\) , \\(\\cup_\\alpha \\phi(E_\\alpha)\\) is an open cover of \\(A\\) by open sets in \\(X\\) , hence it has a finite subcover \\(\\cup_1^N \\phi(E_{\\alpha_n})\\) . Then \\(\\cup_1^N (\\phi(E_{\\alpha_n})\\cap A)\\) is a finite cover of \\(A\\) by open sets in \\(A\\) . Hence \\(A\\) is compact. Ex 4.29. For compact subsets \\(A_1,\\dots,A_n\\) , consider an open cover \\(\\cup E_i\\) of \\(\\cup A_k\\) by open sets of \\(X\\) . For each \\(k\\) , \\(A_k\\cap (\\cup E_i)=\\cup (A_k\\cap E_i)=A_k\\) , and \\(\\cup(A_k\\cap E_i)\\) is an open cover of \\(A_k\\) because \\(A_k\\cap E_i\\) is open in \\(A_k\\) . Since \\(A_k\\) is compact, there is a finite subcover \\(\\cup_n B_{kn}\\) of \\(A_k\\) . Collecting all finite subcovers for each \\(k\\) , \\(\\cup_k \\cup_n B_{kn}=\\cup A_k\\) , and \\(\\cup B_{kn}\\) is a finite subcover of \\(\\cup A_k\\) . Ex 4.37. Ex 4.38. Ex 4.49. - Theorem 4.46: \\(\\R^n\\) is compact, and by Heine-Borel, Local Compactness Paracompactness Proper Maps Problems","title":"4. Connectedness and Compactness"},{"location":"lee/ch4/#4-connectedness-and-compactness","text":"","title":"4. Connectedness and Compactness"},{"location":"lee/ch4/#connectedness","text":"Ex 4.3. If \\(X\\) is empty, the statement is true. Otherwise choose any \\(x\\in X\\) and let \\(c\\) the equivalence class of \\(x\\) . Then \\(c\\) is open and the union of all other equivalence classes is open, and these two subsets are the partition of \\(X\\) . If \\(c\\neq X\\) , then \\(X\\) is disconnected, which contradicts the assumption. Therefore \\(c=X\\) . Ex 4.4. Suppose \\(X\\) is disconnected, \\(X=A\\cup B\\) for two disjoint open sets \\(A, B\\) . Define a map \\(f\\) that \\(f(A)=0, f(B)=1\\) . Then \\(f\\) is continuous and non-constant. Conversely, if there is \\(f\\) that is nonconstant and continuous from \\(X\\) to the discrete space, then by Proposition 4.2, \\(X\\) is empty or disconnected. If \\(X\\) is empty, \\(f\\) is constant. Hence \\(X\\) is disconnected. Ex 4.5. (Disjoint union of spaces here refers to one in Chapter 3.) Suppose \\(X\\) is disconnected by two open subsets. Let the subspaces for these open subsets \\(A\\) and \\(B\\) . We will prove \\(X\\) is homeomorphic to a disjoint union topology \\(A^*\\cup B^*\\) by a mapping \\(f, \\forall a\\in A,f(a)=(a,A),\\forall b\\in B,f(b)=(b,B)\\) . \\(f\\) is continuous because for any open subset \\(E\\sub A^*\\cup B^*, E=(E\\cap A^*)\\cup (E\\cap B^*), f^{-1}(E)=f^{-1}(E\\cap A^*)\\cup f^{-1}(E\\cap B^*)\\) , and \\(f^{-1}(E\\cap A^*), f^{-1}(E\\cap B^*)\\) are open by definition of disjoint union topology, hence \\(f^{-1}(E)\\) is open. \\(f^{-1}\\) is continuous because for any open subset \\(E\\sub X, f(E)=f(E\\cap A)\\cup f(E\\y cap B)\\) , and \\(f(E\\cap A)\\) is open in \\(A^*\\) , \\(f(E\\cap B)\\) is open in \\(B^*\\) , \\(f(E)\\) is open. Conversely, if \\(X\\) is homeomorphic to a disjoint union \\(\\cup X_k\\) with at least two spaces, then by Proposition 4.2, \\(X\\) is not a nonempty connected space. \\(X\\) is not empty, hence \\(X\\) is disconnected. Ex 4.10. Ex 4.14. (a) Let \\(f:X\\longrightarrow f(X)\\) is continuous, and \\(X\\) is path-connected. Then for any two points \\(a,b\\in f(X)\\) , there is a path \\(g\\) from \\(f^{-1}(a)\\) to \\(f^{-1}(b)\\) in \\(X\\) . Then \\(f\\circ g:I\\longrightarrow f(X)\\) is continuous and from \\(a\\) to \\(b\\) . hence a path. Therefore \\(f(X)\\) is path-connected. (b) Let \\(p\\) a point in common. Then for any two points \\(a,b\\in \\cup B_\\alpha\\) , there exists \\(B_a\\) that contains \\(a\\) and \\(B_b\\) that contains \\(b\\) . \\(B_a\\) has a path \\(f\\) from \\(a\\) to \\(p\\) , and \\(B_b\\) has a path \\(g\\) from \\(p\\) to \\(b\\) . Define \\(f':[0,0.5]\\longrightarrow \\R,f'(x)=f(x*2), g':[0.5,1]\\longrightarrow \\R, g'(x)=f(x*2-1)\\) . Both \\(f', g'\\) are continous. We can use the gluing lemma (pasting lemma) to define \\(h:[0,1]\\longrightarrow \\R\\) from \\(f'\\) and \\(g'\\) . Then \\(h\\) is a path from \\(a\\) to \\(b\\) . Hence cup B_\\alpha \\( is path-connected. (c) Let \\) S_1,\\dots,S_n \\( path-connected spaces and \\) S=\\prod S_n \\(. For any two points \\) a,b\\in S \\(, \\) a=(a_1,\\dots,a_n),b=(b_1,\\dots,b_n) \\(. For each index \\) k\\in[1,n] \\(, there exists a path \\) f_k \\( from \\) a_k \\( to \\) b_k \\( in \\) S_k \\(. Define \\) f:I\\rightarrow S, f(x)=(f_1(x),\\dots,f_n(x)) \\(. Then by characteristic property of the product topology, \\) f \\( is continous from that each \\) f_k \\( is continous. Hence \\) f \\( is a path from \\) a \\( to \\) b \\( in \\) S \\(, and \\) S$ is path-connected. (d) A quotient map is continuous, hence by (a) every quotient space of a path-connected space is path-connected. Ex 4.22. (a) Suppose two path components of \\(X\\) are not disjoint. They have a common point, so the union of two is also path-connected, which contradicts that path components were maximal. Therefore path components are all disjoint, and form a partition of \\(X\\) . (b) A path component is connected, so by Proposition 4.20 (a), the path component is in a single component. Path components are disjoint and each element belongs to one path component, hence each component is a disjoint union of path components. (c) For an nonempty path-connected subset \\(E\\) of \\(X\\) , \\(E\\) , there exists a path component \\(P\\) that shares a point with \\(E\\) . Then \\(E\\cup P\\) is also path-connected. Since \\(P\\) is a maximal path-connected subset, \\(E\\cup P\\sub P\\Longrightarrow E\\sub P\\) . Ex 4.24. Let \\(M\\) a manifold and consider \\(p\\in M\\) . Since \\(M\\) is locally Euclidean, \\(p\\) has a neighborhood \\(U\\) that is homeomorphic to an open ball in \\(R^n\\) by a homeomorphism \\(\\phi\\) . An open ball in \\(R^n\\) is path-connected. For any neighborhood \\(V\\) of \\(p\\) , \\(\\phi(U\\cap V)\\) is open and contains \\(\\phi(p)\\) . Since \\(\\phi(U)\\) is locally path-connected, \\(\\phi(U\\cap V)\\) has a path-connected subset \\(W\\) . \\(\\phi^{-1}(W)\\) is path-connected and a subset of \\(U\\cap V\\) . We showed any neighborhood of \\(p\\) has a path-connected subset, hence \\(M\\) is locally path-connected. Since a path-connected subset is connected subset, \\(M\\) is also locally connected.","title":"Connectedness"},{"location":"lee/ch4/#compactness","text":"Ex 4.28. Suppose \\(A\\) is compact. For any open cover \\(\\cup_\\alpha E_\\alpha\\) of \\(A\\) by open sets of \\(X\\) , \\(\\cup_\\alpha (E_\\alpha \\cap A)\\) is an open cover of \\(A\\) by open sets in \\(A\\) . Since \\(A\\) is compact, it has a finite subcover \\(\\cup_1^N (E_{\\alpha_n}\\cap A)\\) . For every open set \\(E\\) in \\(A\\) , there exists an open set \\(F\\) in \\(X\\) such that \\(F\\cap A=E\\) . Define \\(\\phi(E)=F\\) . Then \\(A=\\cup_1^n (E_{\\alpha_n}\\cap A)\\Longrightarrow A\\sub\\cup_1^n \\phi(E_{\\alpha_n}\\cap A)\\) , where the last union is a finite subcover by open sets in \\(X\\) . This proves the forward direction of the lemma. Conversely suppose every open cover of \\(A\\) by open sets in \\(X\\) has a finite subcover by open sets in \\(X\\) . Then for any open cover \\(\\cup E_\\alpha\\) of \\(A\\) by open sets in \\(A\\) , \\(\\cup_\\alpha \\phi(E_\\alpha)\\) is an open cover of \\(A\\) by open sets in \\(X\\) , hence it has a finite subcover \\(\\cup_1^N \\phi(E_{\\alpha_n})\\) . Then \\(\\cup_1^N (\\phi(E_{\\alpha_n})\\cap A)\\) is a finite cover of \\(A\\) by open sets in \\(A\\) . Hence \\(A\\) is compact. Ex 4.29. For compact subsets \\(A_1,\\dots,A_n\\) , consider an open cover \\(\\cup E_i\\) of \\(\\cup A_k\\) by open sets of \\(X\\) . For each \\(k\\) , \\(A_k\\cap (\\cup E_i)=\\cup (A_k\\cap E_i)=A_k\\) , and \\(\\cup(A_k\\cap E_i)\\) is an open cover of \\(A_k\\) because \\(A_k\\cap E_i\\) is open in \\(A_k\\) . Since \\(A_k\\) is compact, there is a finite subcover \\(\\cup_n B_{kn}\\) of \\(A_k\\) . Collecting all finite subcovers for each \\(k\\) , \\(\\cup_k \\cup_n B_{kn}=\\cup A_k\\) , and \\(\\cup B_{kn}\\) is a finite subcover of \\(\\cup A_k\\) . Ex 4.37. Ex 4.38. Ex 4.49. - Theorem 4.46: \\(\\R^n\\) is compact, and by Heine-Borel,","title":"Compactness"},{"location":"lee/ch4/#local-compactness","text":"","title":"Local Compactness"},{"location":"lee/ch4/#paracompactness","text":"","title":"Paracompactness"},{"location":"lee/ch4/#proper-maps","text":"","title":"Proper Maps"},{"location":"lee/ch4/#problems","text":"","title":"Problems"},{"location":"lee/ch5/","text":"5. Cell Complexes Cell Complexes and CW Complexes Topological Properties of CW Complexes Classification of 1-Dimensional Manifolds Simplicial Complexes Problems","title":"5. Cell Complexes"},{"location":"lee/ch5/#5-cell-complexes","text":"","title":"5. Cell Complexes"},{"location":"lee/ch5/#cell-complexes-and-cw-complexes","text":"","title":"Cell Complexes and CW Complexes"},{"location":"lee/ch5/#topological-properties-of-cw-complexes","text":"","title":"Topological Properties of CW Complexes"},{"location":"lee/ch5/#classification-of-1-dimensional-manifolds","text":"","title":"Classification of 1-Dimensional Manifolds"},{"location":"lee/ch5/#simplicial-complexes","text":"","title":"Simplicial Complexes"},{"location":"lee/ch5/#problems","text":"","title":"Problems"},{"location":"lee/ch6/","text":"6. Compact Surfaces Surfaces Connected Sums of Surfaces Polygonal Presentations of Surfaces The Classification Theorem The Euler Characteristic Orientability Problems","title":"6. Compact Surfaces"},{"location":"lee/ch6/#6-compact-surfaces","text":"","title":"6. Compact Surfaces"},{"location":"lee/ch6/#surfaces","text":"","title":"Surfaces"},{"location":"lee/ch6/#connected-sums-of-surfaces","text":"","title":"Connected Sums of Surfaces"},{"location":"lee/ch6/#polygonal-presentations-of-surfaces","text":"","title":"Polygonal Presentations of Surfaces"},{"location":"lee/ch6/#the-classification-theorem","text":"","title":"The Classification Theorem"},{"location":"lee/ch6/#the-euler-characteristic","text":"","title":"The Euler Characteristic"},{"location":"lee/ch6/#orientability","text":"","title":"Orientability"},{"location":"lee/ch6/#problems","text":"","title":"Problems"},{"location":"lee/ch7/","text":"7. Homotopy and the Fundamental Group Homotopy The Fundamental Group Homomorphisms Induced by Continuous Maps Homotopy Equivalence Higher Homotopy Groups Categories and Functors Problems","title":"7. Homotopy and the Fundamental Group"},{"location":"lee/ch7/#7-homotopy-and-the-fundamental-group","text":"","title":"7. Homotopy and the Fundamental Group"},{"location":"lee/ch7/#homotopy","text":"","title":"Homotopy"},{"location":"lee/ch7/#the-fundamental-group","text":"","title":"The Fundamental Group"},{"location":"lee/ch7/#homomorphisms-induced-by-continuous-maps","text":"","title":"Homomorphisms Induced by Continuous Maps"},{"location":"lee/ch7/#homotopy-equivalence","text":"","title":"Homotopy Equivalence"},{"location":"lee/ch7/#higher-homotopy-groups","text":"","title":"Higher Homotopy Groups"},{"location":"lee/ch7/#categories-and-functors","text":"","title":"Categories and Functors"},{"location":"lee/ch7/#problems","text":"","title":"Problems"},{"location":"lee/ch8/","text":"8. The Circle Lifting Properties of the Circle The Fundamental Group of the Circle Degree Theory for the Circle Problems","title":"8. The Circle"},{"location":"lee/ch8/#8-the-circle","text":"","title":"8. The Circle"},{"location":"lee/ch8/#lifting-properties-of-the-circle","text":"","title":"Lifting Properties of the Circle"},{"location":"lee/ch8/#the-fundamental-group-of-the-circle","text":"","title":"The Fundamental Group of the Circle"},{"location":"lee/ch8/#degree-theory-for-the-circle","text":"","title":"Degree Theory for the Circle"},{"location":"lee/ch8/#problems","text":"","title":"Problems"},{"location":"lee/ch9/","text":"9. Some Group Theory Free Products Free Groups Presentations of Groups Free Abelian Groups Problems","title":"9. Some Group Theory"},{"location":"lee/ch9/#9-some-group-theory","text":"","title":"9. Some Group Theory"},{"location":"lee/ch9/#free-products","text":"","title":"Free Products"},{"location":"lee/ch9/#free-groups","text":"","title":"Free Groups"},{"location":"lee/ch9/#presentations-of-groups","text":"","title":"Presentations of Groups"},{"location":"lee/ch9/#free-abelian-groups","text":"","title":"Free Abelian Groups"},{"location":"lee/ch9/#problems","text":"","title":"Problems"},{"location":"stein/","text":"Stein overview Chapters","title":"Stein"},{"location":"stein/#stein","text":"overview","title":"Stein"},{"location":"stein/#chapters","text":"","title":"Chapters"},{"location":"stein/overview/","text":"review My study group finds Folland's a little difficult to self-study, so chose Stein's as study material for basic differentiation/integration/measure theory. Easy to read: an integration is well presented, split in four stages. I find that some other books choose this style of presentation of integration as well. Not easy to read: a section is long and hard to get the structure if you don't focus. For example, for differentiation, the book nicely presents two questions about whether a differentiation is integrable and whether an integration is differentiable. However, going through a lot of propositions and properties with some important findings hidden in them, I lost my way to two questions in the beginning. Imprecise definitions: There is only one imprecise definition I found in the book. Hilbert space is defined to be separable. However the author is aware that Hilbert space generally does not need to be separable, since some exercise problems explicitly state 'separable Hilbert space'. Maybe it is defined in this way for convinience because most interesting applications are separable cases, but the issue is the book does not make it explicit, and hence all propositions in this book involving Hilbert space may represent 'separable Hilbert spaces' or sometimes general Hilbert spaces. challenging problems: in constrast to that Stein's is known for being easier than Folland's, there are a lot of problems and they are all difficult.","title":"Overview"},{"location":"stein/overview/#review","text":"My study group finds Folland's a little difficult to self-study, so chose Stein's as study material for basic differentiation/integration/measure theory. Easy to read: an integration is well presented, split in four stages. I find that some other books choose this style of presentation of integration as well. Not easy to read: a section is long and hard to get the structure if you don't focus. For example, for differentiation, the book nicely presents two questions about whether a differentiation is integrable and whether an integration is differentiable. However, going through a lot of propositions and properties with some important findings hidden in them, I lost my way to two questions in the beginning. Imprecise definitions: There is only one imprecise definition I found in the book. Hilbert space is defined to be separable. However the author is aware that Hilbert space generally does not need to be separable, since some exercise problems explicitly state 'separable Hilbert space'. Maybe it is defined in this way for convinience because most interesting applications are separable cases, but the issue is the book does not make it explicit, and hence all propositions in this book involving Hilbert space may represent 'separable Hilbert spaces' or sometimes general Hilbert spaces. challenging problems: in constrast to that Stein's is known for being easier than Folland's, there are a lot of problems and they are all difficult.","title":"review"},{"location":"tu/","text":"Tu Chapters Chapter 1 Chapter 2","title":"Tu"},{"location":"tu/#tu","text":"","title":"Tu"},{"location":"tu/#chapters","text":"Chapter 1 Chapter 2","title":"Chapters"},{"location":"tu/ch1/","text":"Chapter 1. Euclidean Spaces 1 Smooth Functions on a Euclidean Space summary. \\(C^k, C^\\infty\\) , smooth, real-analytic, star-shaped, taylor theoerem, diffeomorphism 1.1. (???) negative^fraction is not defined in R->R 1.2. (a) Suppose \\(f^{(k)}(x)\\) is continuous and of the form \\(p_{2k}(1/x)e^{-1/x}\\) for some \\(k\\le 0, x>0\\) . Then \\(\\frac{dp_{2k}(1/x)}{dx}=p_{2k-1}(1/x)*(-1/x^2)\\) which is a \\(2k+1\\) degree polynomial of \\(1/x\\) , and \\(\\frac{de^{-1/x}}{dx}=e^{-1/x}*(1/x^2)\\) , hence \\(f^{(k)}(x)\\) is of degree \\(2(k+1)\\) . Since it can be easily shown that the statement is true for \\(k=0\\) , it is true by induction. (b) Suppose \\(f^{(k)}(0)=0\\) and \\(f^{(k)}\\) is continus for some \\(k\\) . Then \\(f^{(k+1)}(0)=\\lim_{x\\longrightarrow 0} \\frac{f^{(k)}(x)-f^{(k)}(0)}{x}=\\lim_{x\\longrightarrow 0} \\frac{f^{(k)}(x)}{x}\\) . The limit from left is \\(0\\) since it is obvious that \\(f^{(k)}(x)=0\\) for \\(x<0\\) . The limit from right is, by L'Hopital's rule, \\(\\lim_{x\\longrightarrow 0+} \\frac{f^{(k+1)}(x)}{1}\\) if this limit exists. This limit is zero because \\(\\lim_{x\\longrightarrow 0+} f^{(k+1)}(x)=\\lim_{x\\longrightarrow 0+} p_{2k+1}(1/x) e^{-1/x}=\\lim_{y\\longrightarrow \\infty} p_{2k+1}(y)/e^y=0\\) , from that \\(e^y\\) grows much faster than the polynomial \\(p_{2k+1}(y)\\) . Both left limit and right limit are zero, therefore \\(f^{(k+1)}(0)\\) exists and is zero. Also \\(f^{(k+1)}\\) is continuous since its limit from right at \\(x=0\\) is zero. For \\(k=0\\) , \\(f^{(0)}(0)=0\\) and \\(f^{(0)}\\) is continus. By induction, the statement is true. - 1.3. (a) - \\(\\tan x\\) is smooth because \\(\\tan^{(k)}\\) is a polynomial of \\(\\tan\\) and \\(\\sec\\) which is continuous. - \\(\\arctan x\\) is smooth because \\(\\arctan^{(k)} x = \\frac{P(x)}{(1+x^2)^k}\\) where \\(P(x)\\) is a polynomial of \\(x\\) and this is continuous for all \\(k\\ge 0\\) . - \\(\\tan x\\) is strictly increasing, and it is easy to show that \\(\\tan\\) is bijective from \\((-\\pi/2,\\pi/2)\\) to \\((-\\infty,\\infty)\\) . Hence \\(\\tan\\) is diffeomorphism. (b) Given \\(a,b\\) , we can scale and shift \\(\\arctan\\) to get \\(h\\) . Precisely, \\(\\arctan\\) maps an interval \\((a,b)\\) to \\((\\arctan a, \\arctan b)\\) , therefore let \\(h(x)=\\arctan(x-(a+b)/2)/\\arctan ((b-a)/2)\\) , then \\(h\\) maps from \\((a,b)\\) to \\((-1,1)\\) . This proves \\((a,b)\\) and \\((-1,1)\\) are diffeomorphic, and it it clear that the inverse is also a diffeomorphism from \\((-1,1)\\) to \\((a,b)\\) . Hence arbitrary two intervals \\((a,b)\\) and \\((c,d)\\) are diffeomorphic by transitivity. (c) ?? \\(-e^x\\) is a diffeomorphism from \\(\\R\\) to \\(()\\) 1.4. **1.5. 1.6. 1.7. 1.8. 2 Tangent Vectors in \\(\\R^n\\) as Derivations summary. \\(T_p(\\R^n), D_v f\\) , relation, germ of \\(f\\) at \\(p\\) , \\(C_p^\\infty(\\R^n)=C_p^\\infty\\) , \\(\\R\\) -linear, Leibniz rule, a point derivation of \\(C_p^\\infty\\) , \\(D_p(\\R^n)\\) , kronecker delta, 3 The Exterior Algebra of Multicovectors 4 Differential Forms on \\(\\R^n\\)","title":"Chapter 1. Euclidean Spaces"},{"location":"tu/ch1/#chapter-1-euclidean-spaces","text":"","title":"Chapter 1. Euclidean Spaces"},{"location":"tu/ch1/#1-smooth-functions-on-a-euclidean-space","text":"summary. \\(C^k, C^\\infty\\) , smooth, real-analytic, star-shaped, taylor theoerem, diffeomorphism 1.1. (???) negative^fraction is not defined in R->R 1.2. (a) Suppose \\(f^{(k)}(x)\\) is continuous and of the form \\(p_{2k}(1/x)e^{-1/x}\\) for some \\(k\\le 0, x>0\\) . Then \\(\\frac{dp_{2k}(1/x)}{dx}=p_{2k-1}(1/x)*(-1/x^2)\\) which is a \\(2k+1\\) degree polynomial of \\(1/x\\) , and \\(\\frac{de^{-1/x}}{dx}=e^{-1/x}*(1/x^2)\\) , hence \\(f^{(k)}(x)\\) is of degree \\(2(k+1)\\) . Since it can be easily shown that the statement is true for \\(k=0\\) , it is true by induction. (b) Suppose \\(f^{(k)}(0)=0\\) and \\(f^{(k)}\\) is continus for some \\(k\\) . Then \\(f^{(k+1)}(0)=\\lim_{x\\longrightarrow 0} \\frac{f^{(k)}(x)-f^{(k)}(0)}{x}=\\lim_{x\\longrightarrow 0} \\frac{f^{(k)}(x)}{x}\\) . The limit from left is \\(0\\) since it is obvious that \\(f^{(k)}(x)=0\\) for \\(x<0\\) . The limit from right is, by L'Hopital's rule, \\(\\lim_{x\\longrightarrow 0+} \\frac{f^{(k+1)}(x)}{1}\\) if this limit exists. This limit is zero because \\(\\lim_{x\\longrightarrow 0+} f^{(k+1)}(x)=\\lim_{x\\longrightarrow 0+} p_{2k+1}(1/x) e^{-1/x}=\\lim_{y\\longrightarrow \\infty} p_{2k+1}(y)/e^y=0\\) , from that \\(e^y\\) grows much faster than the polynomial \\(p_{2k+1}(y)\\) . Both left limit and right limit are zero, therefore \\(f^{(k+1)}(0)\\) exists and is zero. Also \\(f^{(k+1)}\\) is continuous since its limit from right at \\(x=0\\) is zero. For \\(k=0\\) , \\(f^{(0)}(0)=0\\) and \\(f^{(0)}\\) is continus. By induction, the statement is true. - 1.3. (a) - \\(\\tan x\\) is smooth because \\(\\tan^{(k)}\\) is a polynomial of \\(\\tan\\) and \\(\\sec\\) which is continuous. - \\(\\arctan x\\) is smooth because \\(\\arctan^{(k)} x = \\frac{P(x)}{(1+x^2)^k}\\) where \\(P(x)\\) is a polynomial of \\(x\\) and this is continuous for all \\(k\\ge 0\\) . - \\(\\tan x\\) is strictly increasing, and it is easy to show that \\(\\tan\\) is bijective from \\((-\\pi/2,\\pi/2)\\) to \\((-\\infty,\\infty)\\) . Hence \\(\\tan\\) is diffeomorphism. (b) Given \\(a,b\\) , we can scale and shift \\(\\arctan\\) to get \\(h\\) . Precisely, \\(\\arctan\\) maps an interval \\((a,b)\\) to \\((\\arctan a, \\arctan b)\\) , therefore let \\(h(x)=\\arctan(x-(a+b)/2)/\\arctan ((b-a)/2)\\) , then \\(h\\) maps from \\((a,b)\\) to \\((-1,1)\\) . This proves \\((a,b)\\) and \\((-1,1)\\) are diffeomorphic, and it it clear that the inverse is also a diffeomorphism from \\((-1,1)\\) to \\((a,b)\\) . Hence arbitrary two intervals \\((a,b)\\) and \\((c,d)\\) are diffeomorphic by transitivity. (c) ?? \\(-e^x\\) is a diffeomorphism from \\(\\R\\) to \\(()\\) 1.4. **1.5. 1.6. 1.7. 1.8.","title":"1 Smooth Functions on a Euclidean Space"},{"location":"tu/ch1/#2-tangent-vectors-in-rn-as-derivations","text":"summary. \\(T_p(\\R^n), D_v f\\) , relation, germ of \\(f\\) at \\(p\\) , \\(C_p^\\infty(\\R^n)=C_p^\\infty\\) , \\(\\R\\) -linear, Leibniz rule, a point derivation of \\(C_p^\\infty\\) , \\(D_p(\\R^n)\\) , kronecker delta,","title":"2 Tangent Vectors in \\(\\R^n\\) as Derivations"},{"location":"tu/ch1/#3-the-exterior-algebra-of-multicovectors","text":"","title":"3 The Exterior Algebra of Multicovectors"},{"location":"tu/ch1/#4-differential-forms-on-rn","text":"","title":"4 Differential Forms on \\(\\R^n\\)"},{"location":"tu/ch2/","text":"Chapter 2. Manifolds 5 Manifolds 5.1. 5.2. 5.3. 5.4. 5.5. 6 Smooth Maps on a Manifold Exercises 6.14. Problems 6.1. 6.2. 6.3. 6.4. 7 Quotients 7.1. \\(f^{-1}(B)\\sub X \\Longrightarrow f(f^{-1}(B))\\sub f(X), f(f^{-1}(B))\\sub B\\) , hence \\(f(f^{-1}(B))\\sub B\\cap f(X)\\) . Conversely, consider any \\(b\\in B\\cap f(X)\\) . \\(b\\in f(X)\\) implies \\(f(x)=b\\) for some \\(x\\in X\\) . Then \\(x\\in f^{-1}(B), f(x)\\in f(f^{-1}(B))\\) , hence \\(B\\cap f(X)\\sub f(f^{-1}(B))\\) . Therefore two sets are equivalent. If \\(f\\) is surjective, \\(f(X)=Y, f(f^{-1}(B))=B\\cap f(X)=B\\cap Y=B\\) . 7.2. 7.3. 7.4. 7.5. 7.6. 7.7. 7.8. 7.9.","title":"Chapter 2. Manifolds"},{"location":"tu/ch2/#chapter-2-manifolds","text":"","title":"Chapter 2. Manifolds"},{"location":"tu/ch2/#5-manifolds","text":"5.1. 5.2. 5.3. 5.4. 5.5.","title":"5 Manifolds"},{"location":"tu/ch2/#6-smooth-maps-on-a-manifold","text":"","title":"6 Smooth Maps on a Manifold"},{"location":"tu/ch2/#exercises","text":"6.14.","title":"Exercises"},{"location":"tu/ch2/#problems","text":"6.1. 6.2. 6.3. 6.4.","title":"Problems"},{"location":"tu/ch2/#7-quotients","text":"7.1. \\(f^{-1}(B)\\sub X \\Longrightarrow f(f^{-1}(B))\\sub f(X), f(f^{-1}(B))\\sub B\\) , hence \\(f(f^{-1}(B))\\sub B\\cap f(X)\\) . Conversely, consider any \\(b\\in B\\cap f(X)\\) . \\(b\\in f(X)\\) implies \\(f(x)=b\\) for some \\(x\\in X\\) . Then \\(x\\in f^{-1}(B), f(x)\\in f(f^{-1}(B))\\) , hence \\(B\\cap f(X)\\sub f(f^{-1}(B))\\) . Therefore two sets are equivalent. If \\(f\\) is surjective, \\(f(X)=Y, f(f^{-1}(B))=B\\cap f(X)=B\\cap Y=B\\) . 7.2. 7.3. 7.4. 7.5. 7.6. 7.7. 7.8. 7.9.","title":"7 Quotients"}]}