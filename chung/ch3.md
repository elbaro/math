# 3. Random Variable. Expectation. Independence

## 3.1. General Definitions


1. f

2. d

3. Define r.v. X as the identity, so $X(B)=B$ for $B\in\mathscr B_1$. Then $\mu(X^{-1}(B))=\mu(B)$. An identity mapping may be not continuous in some spaces, which means there exists an open set $B$ such that $X^{-1}(B)$ is not open, thus $\mu\circ X^{-1}$ is not defined at $B$.

4. We need to show $\mathscr P\{G(\theta)\le x\}=F(x)$ for all $x\in\R$. This is equivalent to $\mathscr P\{\sup\{y;F(y)\le\theta(\omega)\}\le x\}=F(x)$ for all $x$. $\sup\{y;F(y)\le\theta\}\le x \iff F(x)\ge \theta$, and $\mathscr P\{F(x)\ge\theta(\omega)\}=P\{\theta(\omega)\le F(x)\}=D(F(x))=F(x)$ where $D$ is a d.f. of uniform distribution on $[0,1]$. Hence it is proved.

5. Let $G$ the d.f. of of $F(X)$. Then for $k\in[0,1]$, $G(k)=\mathscr P\{F(x)\le k\}=\mathscr P\{x\le F^{-1}(k)\}=F(F^{-1}(k))=k$ where $x\le F^{-1}(k)$ means $x$ is equal to or smaller than any element of $F^{-1}(\{k\})$. Hence $F(X)$ has the uniform distribution on $[0,1]$. The continuity is used for $F^{-1}(k)\neq\varnothing$. If $F$ is not continuous, for example $F$ jumps from $0.2$ to $0.3$ at $x_0$, $G(k)$ is not defined on $(0.2,0.3)$. Clearly this is not uniform distribution.

6..

7..

8..

9..

10..

11. ($X$ is r.v.) Since $X$ is measurable, $X^{-1}(B)\in \mathscr F\{X\}$. Conversely, $\mathscr F\{X\}$ is generated by a collection of $X^{-1}(B)$ for $B\in\mathscr B^1$. Any element of $\mathscr F\{X\}$ is made of complement/union/intersection of basis elements, and the inverse is commutative with complement/union/intersection, hence $\Lambda\in\mathscr F\{X\}\Longrightarrow \Lambda=X^
{-1}(B)$ for some $B$.  $B$ is not unique if $x$ is not surjective.

## 3.2. Properties of mathematical expectation

1..

2. (The statement is wrong in a case of direc-delta function?) [WIP] In particular, suppose $\lim_{n\Longrightarrow\infty}\mathscr P(|X|>n)=k>0$. Then it is a contradiction that $\int_X Xd\mathscr P\ge nk$ for all $n$ and thus $\int_X Xd\mathscr P=\infty$. Therefore $\lim_{n\Longrightarrow\infty}\mathscr P(|X|>n)=0$. (Or, more easily, use Theorem 3.2.1) Using the first statement in the problem,  $\lim_{n\longrightarrow\infty}\int_{|X|>n}Xd\mathscr P=0$.

3..

4..

5..

6..

7..

8..

9..

10..

11..

12..

13..

14..

15..

16.(*) [WIP] (if F is strictly increasing between 0 and 1) $\int_{-\infty}^{\infty}[F(x+a)-F(x)]dx=\int_0^1 m(F_a^{-1}(x)\setminus F^{-1}(x)) dy = a$. (Use lebesgue?)

17..

18..
19..
20..

## 3.3. Independence
